<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  排查cpu使用率过高 linux
  #

排查 CPU 使用率过高时，通常可以从以下几个方面入手：

  1. 查看当前 CPU 使用情况
  #

使用 top 或 htop 命令查看系统当前的 CPU 使用情况，找到占用 CPU 资源较高的进程。
top
或者如果你有 htop，可以提供更直观的界面：
htop
这些工具可以显示进程的 CPU 使用率，并且帮助你找到哪个进程占用了过多的 CPU。

  2. 使用 ps 查看具体进程
  #

使用 ps 命令来列出所有进程并按 CPU 使用率排序：
ps aux --sort=-%cpu | head -n 10
这条命令会列出 CPU 使用率最高的前 10 个进程。

  3. 检查系统负载
  #

使用 uptime 或 top 可以查看系统的负载情况。如果负载过高，可能是 CPU 资源被占用过多，导致系统过载。
uptime
或者
top
系统负载（load average）越高，表示系统的负载越重。通常负载值大于 CPU 核数时，表示系统处于过载状态。"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://qq547475331.github.io/docs/2025-2-19-%E9%9D%A2%E8%AF%950219/"><meta property="og:site_name" content="Guichen's Blog"><meta property="og:title" content="2025-2-19 面试0219"><meta property="og:description" content="排查cpu使用率过高 linux # 排查 CPU 使用率过高时，通常可以从以下几个方面入手：
1. 查看当前 CPU 使用情况 # 使用 top 或 htop 命令查看系统当前的 CPU 使用情况，找到占用 CPU 资源较高的进程。
top 或者如果你有 htop，可以提供更直观的界面：
htop 这些工具可以显示进程的 CPU 使用率，并且帮助你找到哪个进程占用了过多的 CPU。
2. 使用 ps 查看具体进程 # 使用 ps 命令来列出所有进程并按 CPU 使用率排序：
ps aux --sort=-%cpu | head -n 10 这条命令会列出 CPU 使用率最高的前 10 个进程。
3. 检查系统负载 # 使用 uptime 或 top 可以查看系统的负载情况。如果负载过高，可能是 CPU 资源被占用过多，导致系统过载。
uptime 或者
top 系统负载（load average）越高，表示系统的负载越重。通常负载值大于 CPU 核数时，表示系统处于过载状态。"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><title>2025-2-19 面试0219 | Guichen's Blog</title>
<link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://qq547475331.github.io/docs/2025-2-19-%E9%9D%A2%E8%AF%950219/><link rel=stylesheet href=/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.5ca1226ca4bc0dd491aaddf630a81bb0a439286466552751289bc0088fe6ae58.js integrity="sha256-XKEibKS8DdSRqt32MKgbsKQ5KGRmVSdRKJvACI/mrlg=" crossorigin=anonymous></script></head><script src=https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.2.3/mermaid.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){mermaid.initialize({startOnLoad:!0});let e=document.querySelectorAll("pre > code.language-mermaid");e.forEach(e=>{let t=document.createElement("div");t.classList.add("mermaid"),t.innerHTML=e.innerText,e.parentNode.replaceWith(t)}),mermaid.init(void 0,document.querySelectorAll(".mermaid"))})</script><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>Guichen's Blog</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><a href=/docs/2025-5-7-%E6%8E%A5%E5%8D%95app/>2025-5-7 接单app设计</a></li><li><a href=/docs/2025-5-7-%E5%A5%BD%E5%BF%83%E6%80%81-app/>2025-5-7 好心态 app</a></li><li><a href=/docs/2025-5-29-%E9%94%99%E9%A2%98%E5%88%86%E6%9E%902/>2025-5-29 错题分析2</a></li><li><a href=/docs/2025-5-29-%E9%94%99%E9%A2%98%E5%88%86%E6%9E%901/>2025-5-29 错题分析1</a></li><li><a href=/docs/2025-5-21-ingress%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90/>2025-5-29 主Ingress副本变为0后报503问题分析</a></li><li><a href=/docs/2025-4-28-cursor-agent-%E6%8F%90%E7%A4%BA%E5%99%A8/>2025-4-28 cursor agent 提示器</a></li><li><a href=/docs/2025-4-16-%E8%87%AA%E7%A0%94k8s%E5%B9%B3%E5%8F%B0/>2025-4-16 自研k8s平台</a></li><li><a href=/docs/2025-4-16-sleep%E7%9D%A1%E7%9C%A0%E5%BA%94%E7%94%A8/>2025-4-16 sleep睡眠应用</a></li><li><a href=/docs/2025-4-16-paas%E8%AE%BE%E8%AE%A1/>2025-4-16 paas开发记录</a></li><li><a href=/docs/2025-4-16-cursoe-free-vip/>2025-4-16 Cursor Free VIP</a></li><li><a href=/docs/2025-4-16-boss%E7%9B%B4%E8%81%98%E8%87%AA%E5%8A%A8%E6%8A%95%E9%80%92/>2025-4-16 BOSS直聘自动投递</a></li><li><a href=/docs/2025-4-14-github%E6%8E%A8%E9%80%81/>2025-4-14 github推送</a></li><li><a href=/docs/2025-3-30-metallb/>2025-3-30 metallb</a></li><li><a href=/docs/2025-3-24-%E8%87%AA%E6%88%91%E4%BB%8B%E7%BB%8D/>2025-3-24 自我介绍</a></li><li><a href=/docs/2025-3-20-victoriametrics-%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84/>2025-3-20 victoriametrics高可用架构</a></li><li><a href=/docs/2025-3-20-victoriametrics%E6%9E%B6%E6%9E%84/>2025-3-20 victoriametrics 架构</a></li><li><a href=/docs/2025-3-20-victoriametrics%E5%92%8Cthanos%E5%AF%B9%E6%AF%94/>2025-3-20 VictoriaMetrics 和 Thanos 对比</a></li><li><a href=/docs/2025-3-20-thanos%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84/>2025-3-20 thanos高可用架构</a></li><li><a href=/docs/2025-3-20-thanos%E6%9E%B6%E6%9E%84/>2025-3-20 thanos架构</a></li><li><a href=/docs/2025-3-18-5w-pod%E5%8E%8B%E6%B5%8B%E5%A4%8D%E7%9B%98/>2025-3-18 5w pod压测复盘</a></li><li><a href=/docs/2025-3-14-%E7%81%AB%E5%B1%B1%E4%BA%91%E8%BF%81%E7%A7%BB%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/>2025-3-14 火山云迁移工程师面试记录</a></li><li><a href=/docs/2025-3-14-vivo%E9%9D%A2%E8%AF%95/>2025-3-14 vivo面试</a></li><li><a href=/docs/2025-3-13-istio%E6%B5%81%E9%87%8F%E5%88%86%E6%9E%90/>2025-3-13 istio流量分析</a></li><li><a href=/docs/2025-3-13-calico%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F%E4%B8%8B%E6%B5%81%E9%87%8F%E4%BC%A0%E8%BE%93%E8%B7%AF%E5%BE%84%E5%88%86%E6%9E%90/>2025-3-13 calico三种模式下流量传输</a></li><li><a href=/docs/2025-3-12-%E5%A1%94%E8%B5%9E%E9%9D%A2%E8%AF%95/>2025-3-12 塔赞面试</a></li><li><a href=/docs/2025-3-12-%E8%BF%BD%E8%A7%85%E9%9D%A2%E8%AF%95/>2025-3-12 追觅面试</a></li><li><a href=/docs/2025-3-8-k8s%E5%88%A0%E9%99%A4pod-deployment%E7%9A%84%E6%B5%81%E7%A8%8B%E5%9B%BE%E8%AF%A6%E8%A7%A3/>2025-3-08 k8s删除pod或deployment的流程图详解</a></li><li><a href=/docs/2025-3-8-k8s%E5%88%9B%E5%BB%BApod-deployment%E6%B5%81%E7%A8%8B%E5%9B%BE%E8%AF%A6%E8%A7%A3/>2025-3-08 k8s创建pod流程图详解</a></li><li><a href=/docs/2025-2-28-prometheus%E9%A2%98%E7%9B%AE/>2025-2-28 prometheus面试题</a></li><li><a href=/docs/2025-2-26-%E9%9D%A2%E8%AF%950225/>2025-2-25 面试0225</a></li><li><a href=/docs/2025-2-24-%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4%E9%9D%A2%E8%AF%95%E9%A2%98_ai_linux%E9%83%A8%E5%88%86/>2025-2-24 高级运维面试题-linux部分</a></li><li><a href=/docs/2025-2-24-%E4%B8%AD%E7%BA%A7%E8%BF%90%E7%BB%B4%E9%9D%A2%E8%AF%95%E9%A2%98_%E9%A2%98%E7%9B%AE/>2025-2-24 中级运维面试题</a></li><li><a href=/docs/2025-2-24-%E9%9D%A2%E8%AF%950224/>2025-2-24 0224面试</a></li><li><a href=/docs/2025-2-20-%E9%9D%A2%E8%AF%950220/>2025-2-20 面试0220</a></li><li><a href=/docs/2025-2-19-%E9%9D%A2%E8%AF%950219/ class=active>2025-2-19 面试0219</a></li><li><a href=/docs/2025-2-18-%E9%9D%A2%E8%AF%95/>2025-2-18 面试2025-0218</a></li><li><a href=/docs/2025-2-26-k8s%E7%9B%B8%E5%85%B3/>2025-2-16 k8s题目</a></li><li><a href=/docs/2025-2-12-%E9%9D%A2%E8%AF%950212/>2025-2-12 面试0212</a></li><li><a href=/docs/2025-2-11-%E9%9D%A2%E8%AF%950211/>2025-2-11 面试2025-02-11</a></li><li><a href=/docs/2025-2-7-%E8%AE%A1%E5%88%922/>2025-2-07 美国码农计划</a></li><li><a href=/docs/2025-2-7-%E8%AE%A1%E5%88%92/>2025-2-07 美国码农薪酬</a></li><li><a href=/docs/2025-2-7-k8s%E7%BB%84%E4%BB%B6/>2025-2-07 k8s组件</a></li><li><a href=/docs/2025-1-16-k8s%E5%B8%B8%E8%A7%81%E6%95%85%E9%9A%9C%E6%8C%87%E5%8D%97/>2025-1-16 k8s常见故障指南</a></li><li><a href=/docs/2025-1-1-%E8%A6%81%E4%B8%8D%E8%A6%81%E5%88%9B%E4%B8%9A/>2025-1-1 要不要创业</a></li><li><a href=/docs/2025-1-1-%E6%97%A9%E6%9C%9F%E6%A8%A1%E5%BC%8F/>2025-1-1 早期模式</a></li><li><a href=/docs/2025-1-1-%E5%A4%A7%E5%A0%B0%E6%B2%B3-%E6%88%91%E7%9A%84%E4%BF%9D%E5%A7%86/>2025-1-1 大堰河-我的保姆</a></li><li><a href=/docs/2025-1-1-%E5%88%9D%E5%88%9B%E5%85%AC%E5%8F%B8/>2025-1-1 初创公司</a></li><li><a href=/docs/2025-1-1-%E5%88%9B%E4%B8%9A%E8%80%85%E4%BA%A4%E6%B5%81/>2025-1-1 创业者交流</a></li><li><a href=/docs/2025-1-1-%E5%88%9B%E4%B8%9A%E7%82%B9%E5%AD%90/>2025-1-1 创业点子</a></li><li><a href=/docs/2025-1-1-sealos%E8%8E%B7%E6%8A%95/>2025-1-1 sealos获投</a></li><li><a href=/docs/2024-12-10-docker-registrry/>2024-12-10 docker registrry</a></li><li><a href=/docs/2024-12-09-openstack-ssh%E8%BF%9E%E6%8E%A5/>2024-12-09 openstack ssh连接</a></li><li><a href=/docs/2024-12-08-mutilpass%E9%83%A8%E7%BD%B2openstack/>2024-12-09 mutilpass部署openstack devstack形式</a></li><li><a href=/docs/2024-12-09-helmchart-%E9%83%A8%E7%BD%B2flask%E5%BA%94%E7%94%A8/>2024-12-09 helmchart 部署flask应用</a></li><li><a href=/docs/2024-12-09-docker-daemon.json/>2024-12-09 docker daemon.json</a></li><li><a href=/docs/2024-12-08-%E5%9D%97%E5%AD%98%E5%82%A8%E5%92%8C%E5%AF%B9%E8%B1%A1%E5%82%A8%E5%AD%98%E5%8C%BA%E5%88%AB/>2024-12-08 块存储和对象储存区别</a></li><li><a href=/docs/2024-12-08-openstack%E9%9C%80%E8%A6%81%E5%87%A0%E5%8F%B0%E8%99%9A%E6%8B%9F%E6%9C%BA/>2024-12-08 openstack需要几台虚拟机</a></li><li><a href=/docs/2024-12-08-openstack%E5%92%8Ckubernetes%E5%8C%BA%E5%88%AB/>2024-12-08 openstack和kubernetes区别</a></li><li><a href=/docs/2024-12-08-nano%E6%93%8D%E4%BD%9C/>2024-12-08 nano操作</a></li><li><a href=/docs/2024-12-08-mutilpass%E6%93%8D%E4%BD%9C/>2024-12-08 mutilpass操作</a></li><li><a href=/docs/2024-12-08-devstack/>2024-12-08 devstack</a></li><li><a href=/docs/2024-12-07-microk8s/>2024-12-07 microk8s</a></li><li><a href=/docs/2024-12-05-kubeasz%E9%83%A8%E7%BD%B2k8s/>2024-12-05 kubeasz部署k8s</a></li><li><a href=/docs/2024-10-20-%E5%88%9B%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/>2024-10-20 使用 Keepalived 和 HAproxy 创建高可用 Kubernetes 集群</a></li><li><a href=/docs/%E9%A1%B6%E7%BA%A7devops%E5%B7%A5%E5%85%B7%E5%A4%A7%E7%9B%98%E7%82%B9-ding-ji-devops-gong-ju-da-pan-dian/>2024-08-02 顶级devops工具大盘点</a></li><li><a href=/docs/%E6%B8%85%E7%90%86docker%E9%95%9C%E5%83%8F-qing-li-docker-jing-xiang/>2024-08-02 清理docker镜像</a></li><li><a href=/docs/%E6%9E%84%E5%BB%BA%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E5%88%A9%E5%99%A8buildkit-gou-jian-rong-qi-jing-xiang-li-qi-buildkit/>2024-08-02 构建容器镜像利器buildkit</a></li><li><a href=/docs/%E6%98%AF%E6%8A%80%E6%9C%AF%E5%A4%A7%E7%A5%9E%E8%BF%98%E6%98%AF%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E9%83%A8%E7%9A%84%E7%A5%B8%E5%AE%B3-shi-ji-shu-da-shen-hai-shi-ji-chu-jia-gou-bu-de-huo-hai/>2024-08-02 是技术大神还是基础架构部的祸害</a></li><li><a href=/docs/%E6%90%AD%E4%B8%AA%E6%97%A5%E5%BF%97%E6%89%8B%E6%9C%BA%E7%B3%BB%E7%BB%9F%E4%B8%8D%E9%A6%99%E5%90%97-da-ge-ri-zhi-shou-ji-xi-tong-bu-xiang-ma/>2024-08-02 搭个日志手机系统不香吗</a></li><li><a href=/docs/%E6%88%91%E5%8F%AA%E6%83%B3%E5%81%9A%E6%8A%80%E6%9C%AF-%E8%B5%B0%E6%8A%80%E6%9C%AF%E8%B7%AF%E7%BA%BF-wo-zhi-xiang-zuo-ji-shu-zou-ji-shu-lu-xian/>2024-08-02 我只想做技术 走技术路线</a></li><li><a href=/docs/%E5%B8%B8%E8%A7%81linux%E8%BF%90%E7%BB%B4%E9%9D%A2%E8%AF%95%E9%A2%98-chang-jian-linux-yun-wei-mian-shi-ti/>2024-08-02 常见linux运维面试题</a></li><li><a href=/docs/%E5%A4%A7%E5%8E%82%E6%80%BB%E7%BB%93nginx%E9%AB%98%E5%B9%B6%E5%8F%91%E4%BC%98%E5%8C%96%E7%AC%94%E8%AE%B0-da-chang-zong-jie-nginx-gao-bing-fa-you-hua-bi-ji/>2024-08-02 大厂总结nginx高并发优化笔记</a></li><li><a href=/docs/%E5%8F%B2%E4%B8%8A%E6%9C%80%E7%89%9Bjenkins-pipeline%E6%B5%81%E6%B0%B4%E7%BA%BF%E8%AF%A6%E8%A7%A3-shi-shang-zui-niu-jenkinspipeline-liu-shui-xian-xiang-jie/>2024-08-02 史上最牛jenkins pipeline流水线详解</a></li><li><a href=/docs/teg%E4%B8%8Eistio%E9%9B%86%E6%88%90-teg-yu-istio-ji-cheng/>2024-08-02 TEG与istio集成</a></li><li><a href=/docs/prometheus-stack-prometheus-stack/>2024-08-02 prometheus-stack</a></li><li><a href=/docs/pixie-pixie/>2024-08-02 pixie</a></li><li><a href=/docs/nginx%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E6%83%8A%E7%BE%A4%E6%95%88%E5%BA%94-nginx-ru-he-jie-jue-jing-qun-xiao-ying/>2024-08-02 nginx如何解决惊群效应</a></li><li><a href=/docs/netctl%E6%A3%80%E6%B5%8B%E9%9B%86%E7%BE%A4pod%E9%97%B4%E8%BF%9E%E9%80%9A%E6%80%A7-netctl-jian-ce-ji-qun-pod-jian-lian-tong-xing/>2024-08-02 netctl检测集群pod间连通性</a></li><li><a href=/docs/linux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%8850%E4%B8%AA%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98-linux-yun-wei-gong-cheng-shi-50-ge-chang-jian-mian-shi-ti/>2024-08-02 linux运维工程师50个常见面试题</a></li><li><a href=/docs/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-%E4%B8%83%E4%B8%AA%E5%AE%9E%E6%88%98%E7%BB%8F%E9%AA%8C-linux-xi-tong-xing-neng-you-hua-qi-ge-shi-zhan-jing-yan/>2024-08-02 linux系统性能优化 七个实战经验</a></li><li><a href=/docs/linux-awk%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%99%A8-8%E4%B8%AA%E6%A1%88%E4%BE%8B-linuxawk-wen-ben-chu-li-qi-8-ge-an-li/>2024-08-02 linux awk文本处理器 8个案例</a></li><li><a href=/docs/kubewharf-kubewharf/>2024-08-02 kubewharf</a></li><li><a href=/docs/kruise%E5%8E%9F%E5%9C%B0%E5%8D%87%E7%BA%A7%E8%A7%A3%E6%9E%90-kruise-yuan-de-sheng-ji-jie-xi/>2024-08-02 kruise原地升级解析</a></li><li><a href=/docs/k8s%E9%9D%A2%E8%AF%95%E9%A2%98-k8s-mian-shi-ti/>2024-08-02 K8S面试题</a></li><li><a href=/docs/k8s%E8%83%8C%E5%90%8Eservice%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84-k8s-bei-hou-service-shi-ru-he-gong-zuo-de/>2024-08-02 k8s背后service是如何工作的</a></li><li><a href=/docs/k8s%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E5%9D%97%E6%8B%BC%E5%9B%BE-dbpaas-k8s-de-zui-hou-yi-kuai-pin-tu-dbpaas/>2024-08-02 K8S的最后一块拼图</a></li><li><a href=/docs/istio%E9%83%A8%E7%BD%B2-istio-bu-shu/>2024-08-02 istio部署</a></li><li><a href=/docs/istio-ingress-gateway-istio-ingress-gateway/>2024-08-02 istio-ingress-gateway</a></li><li><a href=/docs/godel-scheduler-godel-scheduler/>2024-08-02 godel-scheduler</a></li><li><a href=/docs/dockerfile%E5%AE%9A%E5%88%B6%E4%B8%93%E5%B1%9E%E9%95%9C%E5%83%8F-dockerfile-ding-zhi-zhuan-shu-jing-xiang/>2024-08-02 dockerfile定制专属镜像</a></li><li><a href=/docs/33%E6%AC%BEgitops%E4%B8%8Edevops%E4%B8%BB%E6%B5%81%E7%B3%BB%E7%BB%9F-33-kuan-gitops-yu-devops-zhu-liu-xi-tong/>2024-08-02 33款gitops与devops主流系统</a></li><li><a href=/docs/2024-8-1-linux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%8850%E4%B8%AA%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/>2024-08-01 linux面试题</a></li><li><a href=/docs/2024-8-1-%E5%B8%B8%E8%A7%81linux%E8%BF%90%E7%BB%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%BF%85%E7%9C%8B/>2024-08-01 linux运维面试题</a></li><li><a href=/docs/2024-8-1-kubernetes%E9%9D%A2%E8%AF%95%E9%A2%98/>2024-08-01 k8s面试题</a></li><li><a href=/docs/openkruise%E8%AF%A6%E7%BB%86%E8%A7%A3%E9%87%8A%E4%BB%A5%E5%8F%8A%E5%8E%9F%E5%9C%B0%E5%8D%87%E7%BA%A7%E5%8F%8A%E5%85%A8%E9%93%BE%E8%B7%AF%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83%E6%96%B9%E6%A1%88-openkruise-xiang-xi-jie-shi-yi-ji-yuan-de-sheng-ji-ji-quan-lian-lu-hui-du-fa-bu-fang-an/>2024-07-22 OpenKruise详细解释以及原地升级及全链路灰度发布方案</a></li><li><a href=/docs/k8s%E4%B9%8Bingress-nginx%E5%8E%9F%E7%90%86%E5%8F%8A%E9%85%8D%E7%BD%AE-k8s-zhi-ingress-nginx-yuan-li-ji-pei-zhi/>2024-07-05 K8S之ingress-nginx原理及配置</a></li><li><a href=/docs/%E4%BD%BF%E7%94%A8cloudflarecf%E6%90%AD%E5%BB%BAdockerhub%E4%BB%A3%E7%90%86-shi-yong-cloudflarecf-da-jian-dockerhub-dai-li/>2024-06-28 使用cloudflare(CF)搭建dockerhub代理</a></li><li><a href=/docs/2024-5-14-%E5%8D%95master%E5%8D%95etcd%E6%94%B9%E9%80%A0/>2024-05-01 单master单etcd改造为3master3etcd</a></li><li><a href=/docs/2024-4-17-%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/>2024-04-17 面试总结</a></li><li><a href=/docs/%E5%A6%82%E4%BD%95%E4%B8%BAk8s%E4%BF%9D%E9%A9%BE%E6%8A%A4%E8%88%AA-ru-he-wei-k8s-bao-jia-hu-hang/>2024-04-16 如何为K8S保驾护航</a></li><li><a href=/docs/k8s%E5%A6%82%E4%BD%95%E8%8E%B7%E5%BE%97-ip-k8s-ru-he-huo-de-ip/>2024-04-16 K8S如何获得 IP</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Bstateful_setgo%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-statefulsetgo-yuan-ma-jie-du/>2024-04-10 K8S控制器之stateful_set.go源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Bstateful_set_status_updatego%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-statefulsetstatusupdatego-yuan-ma-jie-du/>2024-04-10 K8S控制器之stateful_set_status_update.go源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Bstateful_set_controlgo%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-statefulsetcontrolgo-yuan-ma-jie-du/>2024-04-10 K8S控制器之stateful_set_control.go源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Bstateful_pod_controlgo%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-statefulpodcontrolgo-yuan-ma-jie-du/>2024-04-10 K8S控制器之stateful_pod_control.go源码解读</a></li><li><a href=/docs/k8s%E8%B0%83%E5%BA%A6%E5%99%A8-extendergo-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-diao-du-qi-extendergo-yuan-ma-jie-du/>2024-04-09 K8S调度器 extender.go 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Bsyncgo-%E5%90%8C%E6%AD%A5-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-syncgo-tong-bu-yuan-ma-jie-du/>2024-04-09 K8S控制器之sync.go 同步 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Brollbackgo-%E5%9B%9E%E6%BB%9A-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-rollbackgo-hui-gun-yuan-ma-jie-du/>2024-04-09 K8S控制器之rollback.go 回滚 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Brecreatego-%E9%87%8D%E5%BB%BA-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-recreatego-zhong-jian-yuan-ma-jie-du/>2024-04-09 K8S控制器之recreate.go 重建 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8B-schedulergo-%E8%B0%83%E5%BA%A6%E5%99%A8-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-schedulergo-diao-du-qi-yuan-ma-jie-du/>2024-04-09 K8S控制器之 scheduler.go 调度器 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8B-rollinggo-%E6%BB%9A%E5%8A%A8%E6%9B%B4%E6%96%B0-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-rollinggo-gun-dong-geng-xin-yuan-ma-jie-du/>2024-04-09 K8S控制器之 rolling.go 滚动更新 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8B-progressgo-%E8%BF%9B%E5%BA%A6-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-progressgo-jin-du-yuan-ma-jie-du/>2024-04-09 K8S控制器之 progress.go 进度 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8B-deployment_controllergo%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-deploymentcontrollergo-yuan-ma-jie-du/>2024-04-09 K8S控制器之 deployment_controller.go源码解读</a></li><li><a href=/docs/k8s-%E8%B0%83%E5%BA%A6%E5%99%A8-scheduler_onego-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-diao-du-qi-scheduleronego-yuan-ma-jie-du/>2024-04-09 K8S 调度器 scheduler_one.go 源码解读</a></li><li><a href=/docs/%E5%BD%BB%E6%82%9F%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C-che-wu-rong-qi-wang-luo/>2024-04-07 彻悟容器网络</a></li><li><a href=/docs/%E9%9D%A2%E8%AF%95%E7%94%A8-golang-%E6%89%8B%E6%92%B8-lru-mian-shi-yong-golang-shou-lu-lru/>2024-04-03 面试用 Golang 手撸 LRU</a></li><li><a href=/docs/%E8%87%AA%E5%8A%A8%E5%B1%8F%E8%94%BDip%E6%94%BB%E5%87%BB-zi-dong-ping-bi-ip-gong-ji/>2024-04-03 自动屏蔽IP攻击</a></li><li><a href=/docs/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85kubephere-li-xian-an-zhuang-kubephere/>2024-04-03 离线安装kubephere</a></li><li><a href=/docs/%E7%A3%81%E7%9B%98%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D-ci-pan-shu-ju-hui-fu/>2024-04-03 磁盘数据恢复</a></li><li><a href=/docs/%E6%B8%85%E7%90%86%E6%AE%8B%E7%95%99%E7%9A%84calico%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6-qing-li-can-liu-de-calico-wang-luo/>2024-04-03 清理残留的calico网络插件</a></li><li><a href=/docs/%E6%B5%81%E9%87%8F%E4%BD%95%E5%A4%84%E6%9D%A5%E4%BD%95%E5%A4%84%E5%8E%BB-liu-liang-he-chu-lai-he-chu-qu/>2024-04-03 流量何处来何处去</a></li><li><a href=/docs/%E6%9E%81%E5%A4%A7%E6%8F%90%E9%AB%98%E5%B7%A5%E4%BD%9C%E6%95%88%E7%8E%87%E7%9A%84-linux-%E5%91%BD%E4%BB%A4-ji-da-ti-gao-gong-zuo-xiao-lv-de-linux-ming-ling/>2024-04-03 极大提高工作效率的 Linux 命令</a></li><li><a href=/docs/%E6%96%87%E5%AD%A6%E7%9A%84%E6%95%85%E4%B9%A1-wen-xue-de-gu-xiang/>2024-04-03 文学的故乡</a></li><li><a href=/docs/%E6%90%9E%E6%87%82k8s%E9%89%B4%E6%9D%83-gao-dong-k8s-jian-quan/>2024-04-03 搞懂K8S鉴权</a></li><li><a href=/docs/%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86-rong-qi-wang-luo-yuan-li/>2024-04-03 容器网络原理</a></li><li><a href=/docs/%E5%AE%B9%E5%99%A8%E7%9A%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%80-overlayfs-%E5%8E%9F%E7%90%86-rong-qi-de-wen-jian-xi-tong--yi-overlayfs-yuan-li/>2024-04-03 容器的文件系统 OverlayFS 原理</a></li><li><a href=/docs/%E5%AE%B9%E5%99%A8%E5%8E%9F%E7%90%86-rong-qi-yuan-li/>2024-04-03 容器原理</a></li><li><a href=/docs/%E5%AE%B9%E5%99%A8%E5%86%85%E7%9A%84-1-%E5%8F%B7%E8%BF%9B%E7%A8%8B-rong-qi-nei-de-1-hao-jin-cheng/>2024-04-03 容器内的 1 号进程</a></li><li><a href=/docs/%E5%AE%B9%E5%99%A8%E4%B8%AD%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E4%BB%A5%E5%8F%8A%E4%B8%8D%E5%90%8Cdnspolicy%E5%AF%B9%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E7%9A%84%E5%BD%B1%E5%93%8D-rong-qi-zhong-yu-ming-jie-xi-yi-ji-bu-tong-dnspolicy-dui-yu-ming-jie-xi-de-ying-xiang/>2024-04-03 容器中域名解析以及不同dnspolicy对域名解析的影响</a></li><li><a href=/docs/%E5%A6%82%E4%BD%95%E8%B0%83%E8%AF%95-crash-%E5%AE%B9%E5%99%A8%E7%9A%84%E7%BD%91%E7%BB%9C-ru-he-diao-shi-crash-rong-qi-de-wang-luo/>2024-04-03 如何调试 crash 容器的网络</a></li><li><a href=/docs/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8tekton%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAcicd%E5%B9%B3%E5%8F%B0-ru-he-shi-yong-tekton-kuai-su-da-jian-cicd-ping-tai/>2024-04-03 如何使用tekton快速搭建CI/CD平台</a></li><li><a href=/docs/%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%B9%B6%E5%8F%91%E4%B8%8B%E5%A6%82%E4%BD%95%E5%8A%A0%E5%BF%AB-pod-%E5%90%AF%E5%8A%A8%E9%80%9F%E5%BA%A6-da-gui-mo-bing-fa-xia-ru-he-jia-kuai-pod-qi-dong-su-du/>2024-04-03 大规模并发下如何加快 Pod 启动速度</a></li><li><a href=/docs/%E4%BD%BF%E7%94%A8kubernees-leases-%E8%BD%BB%E6%9D%BE%E5%AE%9E%E7%8E%B0leader-election-shi-yong-kuberneesleases-qing-song-shi-xian-leaderelection/>2024-04-03 使用kubernees leases 轻松实现leader election</a></li><li><a href=/docs/%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2k8s%E5%8A%A0%E8%8A%82%E7%82%B9%E6%93%8D%E4%BD%9C-er-jin-zhi-bu-shu-k8s-jia-jie-dian-cao-zuo/>2024-04-03 二进制部署K8S加节点操作</a></li><li><a href=/docs/%E4%B8%A4%E5%BC%A0%E5%9B%BE%E5%85%A8%E9%9D%A2%E7%90%86%E8%A7%A3k8s%E5%8E%9F%E7%90%86-liang-zhang-tu-quan-mian-li-jie-k8s-yuan-li/>2024-04-03 两张图全面理解K8S原理</a></li><li><a href=/docs/ssl%E8%AF%81%E4%B9%A6%E8%87%AA%E7%AD%BE%E5%8F%91-ssl-zheng-shu-zi-qian-fa/>2024-04-03 ssl证书自签发</a></li><li><a href=/docs/prometheus%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9B%91%E6%8E%A7%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93-prometheus-qi-ye-ji-jian-kong-shi-yong-zong-jie/>2024-04-03 prometheus企业级监控使用总结</a></li><li><a href=/docs/metallb-l2-%E5%8E%9F%E7%90%86-metallbl2-yuan-li/>2024-04-03 MetalLB L2 原理</a></li><li><a href=/docs/linux-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%A4%A7%E5%85%A8-linux-xing-neng-you-hua-da-quan/>2024-04-03 Linux 性能优化大全</a></li><li><a href=/docs/kubernetes-%E8%AF%81%E4%B9%A6%E8%AF%A6%E8%A7%A3%E9%89%B4%E6%9D%83-kubernetes-zheng-shu-xiang-jie--jian-quan-/>2024-04-03 Kubernetes 证书详解(鉴权)</a></li><li><a href=/docs/kubernetes-%E8%AF%81%E4%B9%A6%E8%AF%A6%E8%A7%A3%E8%AE%A4%E8%AF%81-kubernetes-zheng-shu-xiang-jie--ren-zheng-/>2024-04-03 Kubernetes 证书详解(认证)</a></li><li><a href=/docs/kubernetes-%E6%BA%90%E7%A0%81%E7%BB%93%E6%9E%84-kubernetes-yuan-ma-jie-gou/>2024-04-03 Kubernetes 源码结构</a></li><li><a href=/docs/kubernetes-api-kubernetesapi/>2024-04-03 Kubernetes API</a></li><li><a href=/docs/kubekey%E6%B7%BB%E5%8A%A0%E6%96%B0%E8%8A%82%E7%82%B9-kubekey-tian-jia-xin-jie-dian/>2024-04-03 kubekey添加新节点</a></li><li><a href=/docs/k8s%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8-k8s-mian-shi-bao-dian/>2024-04-03 K8S面试宝典</a></li><li><a href=/docs/k8s%E9%9D%A2%E8%AF%95%E5%A4%A7%E5%85%A8-k8s-mian-shi-da-quan/>2024-04-03 K8S面试大全</a></li><li><a href=/docs/k8s%E8%BF%90%E7%BB%B4%E4%B9%8B%E6%B8%85%E7%90%86%E7%A3%81%E7%9B%98-k8s-yun-wei-zhi-qing-li-ci-pan/>2024-04-03 k8s运维之清理磁盘</a></li><li><a href=/docs/k8s%E8%B0%83%E8%AF%95pod-k8s-diao-shi-pod/>2024-04-03 K8S调试POD</a></li><li><a href=/docs/k8s%E7%9A%84pod%E7%B1%BB%E5%9E%8B-k8s-de-pod-lei-xing/>2024-04-03 K8S的POD类型</a></li><li><a href=/docs/k8s%E5%BA%94%E7%94%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5-k8s-ying-yong-de-zui-jia-shi-jian/>2024-04-03 k8s应用的最佳实践</a></li><li><a href=/docs/k8s%E5%91%BD%E4%BB%A4%E6%8C%87%E5%8D%97-k8s-ming-ling-zhi-nan/>2024-04-03 K8S命令指南</a></li><li><a href=/docs/k8s%E5%8E%9F%E5%9C%B0%E5%8D%87%E7%BA%A7-k8s-yuan-de-sheng-ji/>2024-04-03 K8S原地升级</a></li><li><a href=/docs/k8s-%E6%8E%A2%E9%92%88%E5%8E%9F%E7%90%86-k8s-tan-zhen-yuan-li/>2024-04-03 K8S 探针原理</a></li><li><a href=/docs/k8s-%E5%BC%80%E5%8F%91%E5%8F%AF%E4%B8%8D%E6%AD%A2-crud-k8s-kai-fa-ke-bu-zhi-crud/>2024-04-03 K8S 开发可不止 CRUD</a></li><li><a href=/docs/k8s-gpt-k8sgpt/>2024-04-03 K8S GPT</a></li><li><a href=/docs/k8s-csi-openebs%E5%8E%9F%E7%90%86-k8scsiopenebs-yuan-li/>2024-04-03 K8S csi openebs原理</a></li><li><a href=/docs/helm-chart%E5%92%8Crepo-helmchart-he-repo/>2024-04-03 helm chart和repo</a></li><li><a href=/docs/flanel%E7%BD%91%E7%BB%9C-flanel-wang-luo/>2024-04-03 flanel网络</a></li><li><a href=/docs/etcd%E7%A8%B3%E5%AE%9A%E6%80%A7%E5%8F%8A%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5-etcd-wen-ding-xing-ji-xing-neng-you-hua-shi-jian/>2024-04-03 ETCD稳定性及性能优化实践</a></li><li><a href=/docs/etcd%E5%A4%87%E4%BB%BD-etcd-bei-fen/>2024-04-03 ETCD备份</a></li><li><a href=/docs/docker%E9%87%8D%E8%A6%81%E7%9A%84%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E7%82%B9-docker-zhong-yao-de-wang-luo-zhi-shi-dian/>2024-04-03 Docker重要的网络知识点</a></li><li><a href=/docs/dockerfile%E7%9A%84copy%E5%92%8Cadd%E7%9A%84%E5%8C%BA%E5%88%AB-dockerfile-de-copy-he-add-de-qu-bie/>2024-04-03 dockerfile的copy和add的区别</a></li><li><a href=/docs/coredns%E4%B9%8B%E5%85%89-coredns-zhi-guang/>2024-04-03 COREDNS之光</a></li><li><a href=/docs/containerd-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C-containerd-ji-ben-cao-zuo/>2024-04-03 Containerd 基本操作</a></li><li><a href=/docs/cni%E6%8F%92%E4%BB%B6%E9%80%89%E5%9E%8B-cni-cha-jian-xuan-xing/>2024-04-03 CNI插件选型</a></li><li><a href=/docs/client-go-%E6%9E%B6%E6%9E%84-client-go-jia-gou/>2024-04-03 Client-go 架构</a></li><li><a href=/docs/client-go-%E5%9B%9B%E7%A7%8D%E5%AE%A2%E6%88%B7%E7%AB%AF-client-go-si-zhong-ke-hu-duan/>2024-04-03 Client-go 四种客户端</a></li><li><a href=/docs/cicd%E6%80%9D%E8%80%83-cicd-si-kao/>2024-04-03 CICD思考</a></li><li><a href=/docs/calico%E7%BD%91%E7%BB%9C%E8%87%AA%E5%AE%9A%E4%B9%89-calico-wang-luo-zi-ding-yi/>2024-04-03 Calico网络自定义</a></li><li><a href=/docs/acme%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0%E8%AF%81%E4%B9%A6-acme-zi-dong-geng-xin-zheng-shu/>2024-04-03 acme自动更新证书</a></li><li><a href=/docs/16%E4%B8%AA%E6%A6%82%E5%BF%B5%E5%B8%A6%E4%BD%A0%E5%85%A5%E9%97%A8-kubernetes-16-ge-gai-nian-dai-ni-ru-men-kubernetes/>2024-04-03 16个概念带你入门 Kubernetes</a></li><li><a href=/docs/%E9%9D%A2%E8%AF%950308-mian-shi-0308/>2024-04-03 面试0308</a></li><li><a href=/docs/600%E6%9D%A1%E6%9C%80%E5%BC%BAlinux%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93-600-tiao-zui-qiang-linux-ming-ling-zong-jie/>2024-04-03 600条最强linux命令总结</a></li><li><a href=/docs/16%E5%BC%A0%E7%A1%AC%E6%A0%B8%E5%9B%BE%E8%A7%A3k8s%E7%BD%91%E7%BB%9C-16-zhang-ying-he-tu-jie-k8s-wang-luo/>2024-04-03 16张硬核图解k8s网络</a></li><li><a href=/docs/k8s%E4%B9%8Bkubelet%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-zhi-kubelet-yuan-ma-jie-du/>2024-03-28 k8s之kubelet源码解读</a></li><li><a href=/docs/2024-3-19-%E4%B8%A4%E5%BC%A0%E5%9B%BE%E5%85%A8%E9%9D%A2%E7%90%86%E8%A7%A3k8s%E5%8E%9F%E7%90%86/>2024-03-19 两张图全面理解k8s原理</a></li><li><a href=/docs/2024-3-8-%E9%9D%A2%E8%AF%950308/>2024-03-08 面试</a></li><li><a href=/docs/2024-3-4-k8s%E6%B5%81%E9%87%8F%E9%93%BE%E8%B7%AF%E5%89%96%E6%9E%90/>2024-03-04 k8s流量链路剖析</a></li><li><a href=/docs/k8s-%E6%B5%81%E9%87%8F%E9%93%BE%E8%B7%AF%E5%89%96%E6%9E%90-k8s-liu-liang-lian-lu-pou-xi/>2024-03-04 K8S 流量链路剖析</a></li><li><a href=/docs/k8s-csi%E5%89%96%E6%9E%90%E6%BC%94%E8%BF%9B-k8scsi-pou-xi-yan-jin/>2024-03-04 K8S CSI剖析演进</a></li><li><a href=/docs/k8s-cni%E5%89%96%E6%9E%90%E6%BC%94%E8%BF%9B-k8scni-pou-xi-yan-jin/>2024-03-04 K8S CNI剖析演进</a></li><li><a href=/docs/2024-3-4-k8s-csi%E5%89%96%E6%9E%90/>2024-03-04 CSI剖析演进</a></li><li><a href=/docs/2024-3-4-cni%E5%89%96%E6%9E%90%E6%BC%94%E8%BF%9B/>2024-03-04 CNI剖析演进</a></li><li><a href=/docs/2024-2-26-%E9%9D%A2%E8%AF%95/>2024-02-26 面试</a></li><li><a href=/docs/2024-2-22-k8s%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8/>2024-02-22 k8s面试宝典</a></li><li><a href=/docs/2024-2-22-k8s%E6%9E%B6%E6%9E%84%E5%B8%88%E9%9D%A2%E8%AF%95%E5%A4%A7%E5%85%A8/>2024-02-22 k8s架构师面试大全</a></li><li><a href=/docs/%E4%BD%BF%E7%94%A8-openfunction-%E5%9C%A8%E4%BB%BB%E4%BD%95%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E4%B8%8A%E8%BF%90%E8%A1%8C%E6%97%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD-shi-yong-openfunction-zai-ren-he-ji-chu-she-shi-shang-yun-xing-wu-fu-wu-qi-gong-zuo-fu-zai/>2024-01-21 使用 OpenFunction 在任何基础设施上运行无服务器工作负载</a></li><li><a href=/docs/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E9%9B%86%E7%BE%A4-li-xian-an-zhuang-ji-qun/>2023-09-28 离线安装集群</a></li><li><a href=/docs/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%B4%E6%98%8E-cao-zuo-xi-tong-shuo-ming/>2023-09-28 操作系统说明</a></li><li><a href=/docs/%E5%BF%AB%E9%80%9F%E6%8C%87%E5%8D%97-kuai-su-zhi-nan/>2023-09-28 快速指南</a></li><li><a href=/docs/%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8-cilium-kai-shi-shi-yong-cilium/>2023-09-28 开始使用 cilium</a></li><li><a href=/docs/%E5%A4%9A%E6%9E%B6%E6%9E%84%E6%94%AF%E6%8C%81-duo-jia-gou-zhi-chi/>2023-09-28 多架构支持</a></li><li><a href=/docs/%E5%85%AC%E6%9C%89%E4%BA%91%E4%B8%8A%E9%83%A8%E7%BD%B2-kubeasz-gong-you-yun-shang-bu-shu-kubeasz/>2023-09-28 公有云上部署</a></li><li><a href=/docs/%E4%B8%AA%E6%80%A7%E5%8C%96%E9%9B%86%E7%BE%A4%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE-ge-xing-hua-ji-qun-can-shu-pei-zhi/>2023-09-28 个性化集群参数配置</a></li><li><a href=/docs/network-check-network-check/>2023-09-28 network-check</a></li><li><a href=/docs/kube-router-%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-kube-router-wang-luo-zu-jian/>2023-09-28 kube-router 网络组件</a></li><li><a href=/docs/ezctl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BB%8B%E7%BB%8D-ezctl-ming-ling-xing-jie-shao/>2023-09-28 ezctl 命令行介绍</a></li><li><a href=/docs/ex-lb-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E9%83%A8%E7%BD%B2-ex-lb-fu-zai-jun-heng-bu-shu/>2023-09-28 EX-LB 负载均衡部署</a></li><li><a href=/docs/calico-%E9%85%8D%E7%BD%AE-bgp-route-reflectors-calico-pei-zhi-bgproutereflectors/>2023-09-28 calico 配置 BGP Route Reflectors</a></li><li><a href=/docs/07-%E5%AE%89%E8%A3%85%E9%9B%86%E7%BE%A4%E4%B8%BB%E8%A6%81%E6%8F%92%E4%BB%B6-07--an-zhuang-ji-qun-zhu-yao-cha-jian/>2023-09-28 15:26:42.651 07-安装集群主要插件</a></li><li><a href=/docs/08-k8s-%E9%9B%86%E7%BE%A4%E5%AD%98%E5%82%A8--k8s-ji-qun-cun-chu/>2023-09-28 08-K8S 集群存储</a></li><li><a href=/docs/06-%E5%AE%89%E8%A3%85%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-06--an-zhuang-wang-luo-zu-jian/>2023-09-28 06-安装网络组件</a></li><li><a href=/docs/06-%E5%AE%89%E8%A3%85kube-ovn%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-06--an-zhuang-kube-ovn-wang-luo-zu-jian/>2023-09-28 06-安装kube-ovn网络组件</a></li><li><a href=/docs/06-%E5%AE%89%E8%A3%85flannel%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-06--an-zhuang-flannel-wang-luo-zu-jian/>2023-09-28 06-安装flannel网络组件</a></li><li><a href=/docs/06-%E5%AE%89%E8%A3%85cilium%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-06--an-zhuang-cilium-wang-luo-zu-jian/>2023-09-28 06-安装cilium网络组件</a></li><li><a href=/docs/06-%E5%AE%89%E8%A3%85calico%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-06--an-zhuang-calico-wang-luo-zu-jian/>2023-09-28 06-安装calico网络组件</a></li><li><a href=/docs/02-%E5%AE%89%E8%A3%85etcd%E9%9B%86%E7%BE%A4-02--an-zhuang-etcd-ji-qun/>2023-09-28 02-安装etcd集群</a></li><li><a href=/docs/00-%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92%E5%92%8C%E5%9F%BA%E7%A1%80%E5%8F%82%E6%95%B0%E8%AE%BE%E5%AE%9A-00--ji-qun-gui-hua-he-ji-chu-can-shu-she-ding/>2023-09-28 00-集群规划和基础参数设定</a></li><li><a href=/docs/05-%E5%AE%89%E8%A3%85kube_node%E8%8A%82%E7%82%B9-05--an-zhuang-kubenode-jie-dian/>2023-09-28 05-安装kube_node节点</a></li><li><a href=/docs/04-%E5%AE%89%E8%A3%85kube_master%E8%8A%82%E7%82%B9-04--an-zhuang-kubemaster-jie-dian/>2023-09-28 04-安装kube_master节点</a></li><li><a href=/docs/03-%E5%AE%89%E8%A3%85%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6-03--an-zhuang-rong-qi-yun-xing-shi/>2023-09-28 03-安装容器运行时</a></li><li><a href=/docs/01-%E5%88%9B%E5%BB%BA%E8%AF%81%E4%B9%A6%E5%92%8C%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87-01--chuang-jian-zheng-shu-he-huan-jing-zhun-bei/>2023-09-28 01-创建证书和环境准备</a></li><li><a href=/docs/%E6%9C%89%E8%BF%993%E4%B8%AA%E8%BF%B9%E8%B1%A1%E4%BD%A0%E5%B0%B1%E8%AF%A5%E7%A6%BB%E8%81%8C%E4%BA%86-you-zhe-3-ge-ji-xiang--ni-jiu-gai-li-zhi-le/>2023-09-21 思考</a></li><li><a href=/docs/%E4%BD%BF%E7%94%A8-keepalived-%E5%92%8C-haproxy-%E5%88%9B%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8-kubernetes-%E9%9B%86%E7%BE%A4-shi-yong-keepalived-he-haproxy-chuang-jian-gao-ke-yong-kubernetes-ji-qun/>2023-04-12 使用 Keepalived 和 HAproxy 创建高可用 Kubernetes 集群</a></li><li><a href=/docs/2025-4-20-%E6%80%A7%E5%90%8C%E6%84%8Fapp/>2025 4 20 性同意app</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>2025-2-19 面试0219</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#排查cpu使用率过高-linux>排查cpu使用率过高 linux</a><ul><li><a href=#1-查看当前-cpu-使用情况>1. <strong>查看当前 CPU 使用情况</strong></a></li><li><a href=#2-使用>2. <strong>使用 <code>ps</code> 查看具体进程</strong></a></li><li><a href=#3-检查系统负载>3. <strong>检查系统负载</strong></a></li><li><a href=#4-查看硬件性能>4. <strong>查看硬件性能</strong></a></li><li><a href=#5-查看-io-和进程状态>5. <strong>查看 I/O 和进程状态</strong></a></li><li><a href=#6-检查系统日志>6. <strong>检查系统日志</strong></a></li><li><a href=#7-分析具体进程>7. <strong>分析具体进程</strong></a></li><li><a href=#8-检查僵尸进程>8. <strong>检查僵尸进程</strong></a></li><li><a href=#9-优化配置>9. <strong>优化配置</strong></a></li><li><a href=#10-检查是否有恶意软件>10. <strong>检查是否有恶意软件</strong></a></li></ul></li><li><a href=#排查内存使用率过高-linux>排查内存使用率过高 linux</a><ul><li><a href=#1-查看系统内存使用情况>1. <strong>查看系统内存使用情况</strong></a></li><li><a href=#2-使用-1>2. <strong>使用 <code>top</code> 或 <code>htop</code> 查看内存占用进程</strong></a></li><li><a href=#3-使用>3. <strong>使用 <code>ps</code> 查看内存使用的前几个进程</strong></a></li><li><a href=#4-查看内存的具体细节>4. <strong>查看内存的具体细节（<code>vmstat</code>）</strong></a></li><li><a href=#5-查看交换空间的使用情况>5. <strong>查看交换空间的使用情况</strong></a></li><li><a href=#6-检查是否有内存泄漏>6. <strong>检查是否有内存泄漏</strong></a></li><li><a href=#7-使用>7. <strong>使用 <code>smem</code> 查看内存使用情况</strong></a></li><li><a href=#8-查看缓存和缓冲区的使用情况>8. <strong>查看缓存和缓冲区的使用情况</strong></a></li><li><a href=#9-分析内存的分配情况>9. <strong>分析内存的分配情况（<code>/proc/meminfo</code>）</strong></a></li><li><a href=#10-检查进程的内存使用情况>10. <strong>检查进程的内存使用情况（<code>pmap</code>）</strong></a></li><li><a href=#11-检查系统的-oom-out-of-memory-事件>11. <strong>检查系统的 OOM (Out of Memory) 事件</strong></a></li><li><a href=#12-使用>12. <strong>使用 <code>lsof</code> 查找打开的文件</strong></a></li><li><a href=#13-内存优化和限制>13. <strong>内存优化和限制</strong></a></li></ul></li><li><a href=#echo-devmappervgdocker-lvapp-apps--------------------xfs----rwpquota--------0-0--etcfstabpquota-啥意思-不加这个参数会导致docker容器根磁盘限额失效吗或者说导致docker起不来-导致kubelet起不来>echo &ldquo;#/dev/mapper/vg&ndash;docker-lvapp /apps xfs rw,pquota 0 0&rdquo; &#187; /etc/fstab，pquota 啥意思 不加这个参数会导致docker容器根磁盘限额失效吗，或者说导致docker起不来 导致kubelet起不来</a><ul><li><a href=#1-配额的作用>1. <strong>配额的作用</strong></a></li><li><a href=#2-不加>2. <strong>不加 <code>pquota</code> 会有什么影响？</strong></a></li><li><a href=#3-可能的风险>3. <strong>可能的风险</strong></a></li><li><a href=#4-总结>4. <strong>总结</strong></a></li><li><a href=#1-检查挂载是否正确>1. <strong>检查挂载是否正确</strong></a></li><li><a href=#2-检查磁盘配额是否启用>2. <strong>检查磁盘配额是否启用</strong></a></li><li><a href=#3-检查系统日志>3. <strong>检查系统日志</strong></a></li><li><a href=#4-检查-docker-和-kubelet-配置>4. <strong>检查 Docker 和 Kubelet 配置</strong></a></li><li><a href=#5-确认磁盘是否满>5. <strong>确认磁盘是否满</strong></a></li><li><a href=#6-尝试移除>6. <strong>尝试移除 <code>pquota</code> 选项</strong></a></li><li><a href=#7-重新启动-docker-和-kubelet>7. <strong>重新启动 Docker 和 Kubelet</strong></a></li></ul></li><li><a href=#修改calico的默认的vxlan的端口号>修改calico的默认的vxlan的端口号</a><ul><li><a href=#1-修改-calico-配置>1. <strong>修改 Calico 配置</strong></a></li><li><a href=#2-验证配置>2. <strong>验证配置</strong></a></li><li><a href=#3-注意事项>3. <strong>注意事项</strong></a></li><li><a href=#修改-felix-配置来更改-vxlan-端口号>修改 Felix 配置来更改 VXLAN 端口号</a></li><li><a href=#总结>总结</a></li></ul></li><li><a href=#没有启用配额但docker的daemonjson的opt有限制磁盘大小的参数docker起不来的吧>没有启用配额，但docker的daemon.json的opt有限制磁盘大小的参数，docker起不来的吧</a><ul><li><a href=#1-daemonjson>1. <strong><code>daemon.json</code> 配置示例</strong></a></li><li><a href=#2-可能的错误>2. <strong>可能的错误</strong></a></li><li><a href=#3-如何避免-docker-启动失败>3. <strong>如何避免 Docker 启动失败</strong></a></li><li><a href=#4-解决方法>4. <strong>解决方法</strong></a></li><li><a href=#5-排查-docker-启动问题>5. <strong>排查 Docker 启动问题</strong></a></li></ul></li><li><a href=#单etcd单master拓展为3master3etcdmaster节点挂上vip做高可用证书重新生成etcd之前数据保留>单etcd单master拓展为3master3etcd，master节点挂上vip，做高可用，证书重新生成，etcd之前数据保留</a><ul><li><a href=#1-准备工作>1. <strong>准备工作</strong></a></li><li><a href=#2-部署-3-master-节点>2. <strong>部署 3 Master 节点</strong></a></li><li><a href=#3-部署-3-etcd-节点>3. <strong>部署 3 ETCD 节点</strong></a></li><li><a href=#4-更新证书>4. <strong>更新证书</strong></a></li><li><a href=#5-恢复-etcd-数据>5. <strong>恢复 ETCD 数据</strong></a></li><li><a href=#6-验证集群>6. <strong>验证集群</strong></a></li><li><a href=#总结-1>总结</a></li></ul></li><li><a href=#跨网段的机器组成k8s集群不同网段机器上的pod之间无法相互访问用calico的vxlan模式修改默认的vxlan的端口号因为之前的4789被物理网关设备占用了>跨网段的机器组成k8s集群，不同网段机器上的pod之间无法相互访问，用calico的vxlan模式，修改默认的vxlan的端口号，因为之前的4789被物理网关设备占用了</a><ul><li><a href=#步骤-1-修改-felix-配置修改-vxlan-端口>步骤 1: 修改 Felix 配置（修改 VXLAN 端口）</a></li><li><a href=#步骤-2-修改-kubernetes-api-server-和节点配置>步骤 2: 修改 Kubernetes API Server 和节点配置</a></li><li><a href=#步骤-3-验证配置>步骤 3: 验证配置</a></li><li><a href=#总结-2>总结</a></li></ul></li><li><a href=#envoy的版本过低导致流量被拦截升级版本解决了>envoy的版本过低导致流量被拦截，升级版本解决了</a><ul><li><a href=#1-过时的协议支持>1. <strong>过时的协议支持</strong></a></li><li><a href=#2-安全性问题>2. <strong>安全性问题</strong></a></li><li><a href=#3-代理和路由问题>3. <strong>代理和路由问题</strong></a></li><li><a href=#4-性能优化和-bug-修复>4. <strong>性能优化和 bug 修复</strong></a></li><li><a href=#如何升级-envoy>如何升级 Envoy</a></li><li><a href=#总结-3>总结</a></li></ul></li><li><a href=#节点noteready-恢复>节点noteready 恢复</a><ul><li><a href=#1-查看节点状态>1. <strong>查看节点状态</strong></a></li><li><a href=#2-检查-kubelet-状态>2. <strong>检查 Kubelet 状态</strong></a></li><li><a href=#3-检查网络配置>3. <strong>检查网络配置</strong></a></li><li><a href=#4-资源使用情况>4. <strong>资源使用情况</strong></a></li><li><a href=#5-检查-api-server-与节点连接>5. <strong>检查 API Server 与节点连接</strong></a></li><li><a href=#6-重新加入节点到集群>6. <strong>重新加入节点到集群</strong></a></li><li><a href=#7-检查-kubelet-配置文件>7. <strong>检查 Kubelet 配置文件</strong></a></li><li><a href=#8-节点恢复后的验证>8. <strong>节点恢复后的验证</strong></a></li><li><a href=#总结-4>总结</a></li></ul></li><li><a href=#数据库磁盘使用超过85导致数据库只读>数据库磁盘使用超过85%导致数据库只读</a><ul><li><a href=#解决方案>解决方案</a></li></ul></li><li><a href=#prometheus指标拆分解决oom的问题>prometheus指标拆分解决oom的问题</a><ul><li><a href=#1-拆分大型指标>1. <strong>拆分大型指标</strong></a></li><li><a href=#2-限制-prometheus-存储使用>2. <strong>限制 Prometheus 存储使用</strong></a></li><li><a href=#3-调整指标采集频率>3. <strong>调整指标采集频率</strong></a></li><li><a href=#4-分布式-prometheus-部署sharding>4. <strong>分布式 Prometheus 部署（Sharding）</strong></a></li><li><a href=#5-优化查询>5. <strong>优化查询</strong></a></li><li><a href=#6-使用外部存储远程存储>6. <strong>使用外部存储（远程存储）</strong></a></li><li><a href=#总结-6>总结</a></li></ul></li><li><a href=#prometheus的告警延迟问题>prometheus的告警延迟问题</a><ul><li><a href=#1-告警规则的评估间隔>1. <strong>告警规则的评估间隔</strong></a></li><li><a href=#2-告警规则的评估条件过于宽松>2. <strong>告警规则的评估条件过于宽松</strong></a></li><li><a href=#3-prometheus-数据采集频率>3. <strong>Prometheus 数据采集频率</strong></a></li><li><a href=#4-alertmanager-配置问题>4. <strong>Alertmanager 配置问题</strong></a></li><li><a href=#5-prometheus-存储问题>5. <strong>Prometheus 存储问题</strong></a></li><li><a href=#6-复杂的-prometheus-查询>6. <strong>复杂的 Prometheus 查询</strong></a></li><li><a href=#7-网络延迟或-dns-解析问题>7. <strong>网络延迟或 DNS 解析问题</strong></a></li><li><a href=#8-alertmanager-缓存问题>8. <strong>Alertmanager 缓存问题</strong></a></li><li><a href=#总结-7>总结</a></li></ul></li><li><a href=#告警抑制和收敛>告警抑制和收敛</a><ul><li><a href=#1-告警抑制alert-suppression>1. <strong>告警抑制（Alert Suppression）</strong></a></li><li><a href=#2-告警收敛alert-aggregation>2. <strong>告警收敛（Alert Aggregation）</strong></a></li><li><a href=#3-告警收敛与告警抑制的区别>3. <strong>告警收敛与告警抑制的区别</strong></a></li><li><a href=#4-告警收敛和抑制的配置实践>4. <strong>告警收敛和抑制的配置实践</strong></a></li><li><a href=#总结-8>总结</a></li></ul></li><li><a href=#业务pod的告警规则>业务pod的告警规则</a><ul><li><a href=#1-pod-资源使用情况>1. <strong>Pod 资源使用情况</strong></a></li><li><a href=#2-pod-健康检查失败>2. <strong>Pod 健康检查失败</strong></a></li><li><a href=#3-pod-容器的重启>3. <strong>Pod 容器的重启</strong></a></li><li><a href=#4-pod-调度和资源限制>4. <strong>Pod 调度和资源限制</strong></a></li><li><a href=#5-网络延迟或连接问题>5. <strong>网络延迟或连接问题</strong></a></li><li><a href=#总结-9>总结</a></li><li><a href=#1-cpu-使用率告警>1. <strong>CPU 使用率告警</strong></a></li><li><a href=#2-内存使用率告警>2. <strong>内存使用率告警</strong></a></li><li><a href=#3-pod-失效告警>3. <strong>Pod 失效告警</strong></a></li><li><a href=#4-pod-重启告警>4. <strong>Pod 重启告警</strong></a></li></ul></li><li><a href=#请求成功率的监控怎么做的>请求成功率的监控怎么做的</a><ul><li><a href=#1-监控请求成功率的基础指标>1. <strong>监控请求成功率的基础指标</strong></a></li><li><a href=#2-计算请求成功率>2. <strong>计算请求成功率</strong></a></li><li><a href=#3-设置告警规则>3. <strong>设置告警规则</strong></a></li><li><a href=#4-监控失败的请求>4. <strong>监控失败的请求</strong></a></li><li><a href=#5-高级监控与告警>5. <strong>高级监控与告警</strong></a></li><li><a href=#总结-10>总结</a></li></ul></li><li><a href=#接口探活呢>接口探活呢</a><ul><li><a href=#1-暴露健康检查端点>1. <strong>暴露健康检查端点</strong></a></li><li><a href=#2-暴露健康检查指标>2. <strong>暴露健康检查指标</strong></a></li><li><a href=#3-通过-prometheus-查询健康检查状态>3. <strong>通过 Prometheus 查询健康检查状态</strong></a></li><li><a href=#4-设置告警规则>4. <strong>设置告警规则</strong></a></li><li><a href=#5-使用-kubernetes-探针livenessreadiness>5. <strong>使用 Kubernetes 探针（Liveness/Readiness）</strong></a></li><li><a href=#6-总结>6. <strong>总结</strong></a></li></ul></li><li><a href=#一个微服务的业务流量通过外部进入集群内部的过程>一个微服务的业务，流量通过外部进入集群内部的过程</a><ul><li><a href=#1-外部流量的接入>1. <strong>外部流量的接入</strong></a></li><li><a href=#2-ingress-controller-处理流量>2. <strong>Ingress Controller 处理流量</strong></a></li><li><a href=#3-服务发现与流量路由>3. <strong>服务发现与流量路由</strong></a></li><li><a href=#4-内部流量的路由与负载均衡>4. <strong>内部流量的路由与负载均衡</strong></a></li><li><a href=#5-服务间通信>5. <strong>服务间通信</strong></a></li><li><a href=#6-安全控制与认证>6. <strong>安全控制与认证</strong></a></li><li><a href=#7-监控与日志收集>7. <strong>监控与日志收集</strong></a></li><li><a href=#8-总结>8. <strong>总结</strong></a></li></ul></li><li><a href=#elkfluentd-怎么收集pod的日志>ELK/fluentd 怎么收集pod的日志</a><ul><li><a href=#1-使用-fluentd-收集-pod-日志>1. <strong>使用 Fluentd 收集 Pod 日志</strong></a></li><li><a href=#2-使用-elk-stackelasticsearch-logstash-kibana收集-pod-日志>2. <strong>使用 ELK Stack（Elasticsearch, Logstash, Kibana）收集 Pod 日志</strong></a></li><li><a href=#3-通过-fluentd-与-elk-集成>3. <strong>通过 Fluentd 与 ELK 集成</strong></a></li><li><a href=#4-总结-1>4. <strong>总结</strong></a></li></ul></li><li><a href=#pod的标准输出日志在这哪>pod的标准输出日志在这哪</a><ul><li><a href=#pod-标准输出日志路径><strong>Pod 标准输出日志路径</strong></a></li><li><a href=#如何查看-pod-的标准输出日志><strong>如何查看 Pod 的标准输出日志</strong></a></li><li><a href=#日志收集与存储><strong>日志收集与存储</strong></a></li><li><a href=#总结-11>总结</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h2 id=排查cpu使用率过高-linux>排查cpu使用率过高 linux
<a class=anchor href=#%e6%8e%92%e6%9f%a5cpu%e4%bd%bf%e7%94%a8%e7%8e%87%e8%bf%87%e9%ab%98-linux>#</a></h2><p>排查 CPU 使用率过高时，通常可以从以下几个方面入手：</p><h3 id=1-查看当前-cpu-使用情况>1. <strong>查看当前 CPU 使用情况</strong>
<a class=anchor href=#1-%e6%9f%a5%e7%9c%8b%e5%bd%93%e5%89%8d-cpu-%e4%bd%bf%e7%94%a8%e6%83%85%e5%86%b5>#</a></h3><p>使用 <code>top</code> 或 <code>htop</code> 命令查看系统当前的 CPU 使用情况，找到占用 CPU 资源较高的进程。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>top
</span></span></code></pre></div><p>或者如果你有 <code>htop</code>，可以提供更直观的界面：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>htop
</span></span></code></pre></div><p>这些工具可以显示进程的 CPU 使用率，并且帮助你找到哪个进程占用了过多的 CPU。</p><h3 id=2-使用>2. <strong>使用 <code>ps</code> 查看具体进程</strong>
<a class=anchor href=#2-%e4%bd%bf%e7%94%a8>#</a></h3><p>使用 <code>ps</code> 命令来列出所有进程并按 CPU 使用率排序：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ps aux --sort<span style=color:#f92672>=</span>-%cpu | head -n <span style=color:#ae81ff>10</span>
</span></span></code></pre></div><p>这条命令会列出 CPU 使用率最高的前 10 个进程。</p><h3 id=3-检查系统负载>3. <strong>检查系统负载</strong>
<a class=anchor href=#3-%e6%a3%80%e6%9f%a5%e7%b3%bb%e7%bb%9f%e8%b4%9f%e8%bd%bd>#</a></h3><p>使用 <code>uptime</code> 或 <code>top</code> 可以查看系统的负载情况。如果负载过高，可能是 CPU 资源被占用过多，导致系统过载。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>uptime
</span></span></code></pre></div><p>或者</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>top
</span></span></code></pre></div><p>系统负载（load average）越高，表示系统的负载越重。通常负载值大于 CPU 核数时，表示系统处于过载状态。</p><h3 id=4-查看硬件性能>4. <strong>查看硬件性能</strong>
<a class=anchor href=#4-%e6%9f%a5%e7%9c%8b%e7%a1%ac%e4%bb%b6%e6%80%a7%e8%83%bd>#</a></h3><p>查看硬件的 CPU 使用情况，可以使用 <code>mpstat</code> 命令（<code>sysstat</code> 包）：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>mpstat -P ALL <span style=color:#ae81ff>1</span>
</span></span></code></pre></div><p>该命令会按 CPU 核心查看 CPU 使用情况。</p><h3 id=5-查看-io-和进程状态>5. <strong>查看 I/O 和进程状态</strong>
<a class=anchor href=#5-%e6%9f%a5%e7%9c%8b-io-%e5%92%8c%e8%bf%9b%e7%a8%8b%e7%8a%b6%e6%80%81>#</a></h3><p>如果 CPU 占用过高可能与 I/O 阻塞有关，可以使用 <code>iotop</code> 来查看系统的 I/O 活动：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo iotop
</span></span></code></pre></div><p>通过它可以识别高 I/O 活动的进程，这可能间接导致 CPU 过高使用。</p><h3 id=6-检查系统日志>6. <strong>检查系统日志</strong>
<a class=anchor href=#6-%e6%a3%80%e6%9f%a5%e7%b3%bb%e7%bb%9f%e6%97%a5%e5%bf%97>#</a></h3><p>查看 <code>/var/log/syslog</code> 或 <code>/var/log/messages</code> 文件，检查是否有异常的系统日志或者进程错误，可能导致 CPU 使用率过高：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tail -f /var/log/syslog
</span></span></code></pre></div><p>或者</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tail -f /var/log/messages
</span></span></code></pre></div><h3 id=7-分析具体进程>7. <strong>分析具体进程</strong>
<a class=anchor href=#7-%e5%88%86%e6%9e%90%e5%85%b7%e4%bd%93%e8%bf%9b%e7%a8%8b>#</a></h3><p>如果你发现某个进程占用了大量 CPU，可以使用 <code>strace</code> 或 <code>lsof</code> 来进一步调查该进程在做什么：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>strace -p &lt;PID&gt;
</span></span></code></pre></div><p>这会显示该进程的系统调用，帮助你理解它的行为。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>lsof -p &lt;PID&gt;
</span></span></code></pre></div><p>这会列出该进程打开的文件资源。</p><h3 id=8-检查僵尸进程>8. <strong>检查僵尸进程</strong>
<a class=anchor href=#8-%e6%a3%80%e6%9f%a5%e5%83%b5%e5%b0%b8%e8%bf%9b%e7%a8%8b>#</a></h3><p>僵尸进程虽然不占用 CPU，但会导致系统资源浪费，可以使用 <code>ps aux | grep Z</code> 查看是否有僵尸进程。</p><h3 id=9-优化配置>9. <strong>优化配置</strong>
<a class=anchor href=#9-%e4%bc%98%e5%8c%96%e9%85%8d%e7%bd%ae>#</a></h3><ul><li><strong>调整进程优先级</strong>：使用 <code>nice</code> 和 <code>renice</code> 来调整高 CPU 使用进程的优先级。</li><li><strong>限制进程的 CPU 使用</strong>：使用 <code>cpulimit</code> 工具来限制进程的最大 CPU 使用率。</li></ul><h3 id=10-检查是否有恶意软件>10. <strong>检查是否有恶意软件</strong>
<a class=anchor href=#10-%e6%a3%80%e6%9f%a5%e6%98%af%e5%90%a6%e6%9c%89%e6%81%b6%e6%84%8f%e8%bd%af%e4%bb%b6>#</a></h3><p>如果排除了一般的原因，可能需要检查是否有恶意软件占用系统资源。可以使用一些防病毒工具（如 <code>clamav</code>）进行扫描。</p><p>通过这些步骤，你应该能够定位导致 CPU 使用率过高的原因，并采取相应的措施进行处理。</p><h2 id=排查内存使用率过高-linux>排查内存使用率过高 linux
<a class=anchor href=#%e6%8e%92%e6%9f%a5%e5%86%85%e5%ad%98%e4%bd%bf%e7%94%a8%e7%8e%87%e8%bf%87%e9%ab%98-linux>#</a></h2><p>排查内存使用率过高时，以下是一些常见的排查步骤，可以帮助你找出问题的根本原因：</p><h3 id=1-查看系统内存使用情况>1. <strong>查看系统内存使用情况</strong>
<a class=anchor href=#1-%e6%9f%a5%e7%9c%8b%e7%b3%bb%e7%bb%9f%e5%86%85%e5%ad%98%e4%bd%bf%e7%94%a8%e6%83%85%e5%86%b5>#</a></h3><p>使用 <code>free</code> 命令查看系统的内存使用情况：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>free -h
</span></span></code></pre></div><p>输出会显示系统的总内存、已用内存、空闲内存、缓存以及交换区使用情况。关注 <code>used</code> 和 <code>free</code> 列，以及 <code>swap</code> 是否被大量使用。</p><h3 id=2-使用-1>2. <strong>使用 <code>top</code> 或 <code>htop</code> 查看内存占用进程</strong>
<a class=anchor href=#2-%e4%bd%bf%e7%94%a8-1>#</a></h3><ul><li><p><code>top</code> 命令：默认显示内存的使用情况，并按内存占用排序：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>top
</span></span></code></pre></div><p>按 <code>%MEM</code> 列排序，找到占用内存最多的进程。</p></li><li><p><code>htop</code>（如果安装）：提供更为友好的界面，显示 CPU、内存和进程使用情况：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>htop
</span></span></code></pre></div><p>在 <code>htop</code> 中，你可以直接使用 F6 按钮按内存使用量排序。</p></li></ul><h3 id=3-使用>3. <strong>使用 <code>ps</code> 查看内存使用的前几个进程</strong>
<a class=anchor href=#3-%e4%bd%bf%e7%94%a8>#</a></h3><p>使用 <code>ps</code> 命令按内存使用量列出进程：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ps aux --sort<span style=color:#f92672>=</span>-%mem | head -n <span style=color:#ae81ff>10</span>
</span></span></code></pre></div><p>这会显示内存占用最多的前 10 个进程。</p><h3 id=4-查看内存的具体细节>4. <strong>查看内存的具体细节（<code>vmstat</code>）</strong>
<a class=anchor href=#4-%e6%9f%a5%e7%9c%8b%e5%86%85%e5%ad%98%e7%9a%84%e5%85%b7%e4%bd%93%e7%bb%86%e8%8a%82>#</a></h3><p>使用 <code>vmstat</code> 命令可以查看系统内存、交换空间以及其他资源的使用情况：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>vmstat <span style=color:#ae81ff>1</span>
</span></span></code></pre></div><p>该命令每秒输出一次系统的内存统计信息，帮助你判断内存瓶颈所在。</p><h3 id=5-查看交换空间的使用情况>5. <strong>查看交换空间的使用情况</strong>
<a class=anchor href=#5-%e6%9f%a5%e7%9c%8b%e4%ba%a4%e6%8d%a2%e7%a9%ba%e9%97%b4%e7%9a%84%e4%bd%bf%e7%94%a8%e6%83%85%e5%86%b5>#</a></h3><p>如果系统内存不足，操作系统会使用交换空间（swap），这会导致性能下降。查看交换区使用情况：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>swapon -s
</span></span><span style=display:flex><span>free -h
</span></span></code></pre></div><p>如果交换空间使用过多，可能表示系统内存不足。</p><p><strong>解决方案</strong>：</p><ul><li><strong>增加物理内存</strong>。</li><li><strong>优化应用程序内存使用</strong>，避免过多的内存泄漏。</li><li><strong>减少或禁用交换空间</strong>，如果内存足够用的话。</li></ul><h3 id=6-检查是否有内存泄漏>6. <strong>检查是否有内存泄漏</strong>
<a class=anchor href=#6-%e6%a3%80%e6%9f%a5%e6%98%af%e5%90%a6%e6%9c%89%e5%86%85%e5%ad%98%e6%b3%84%e6%bc%8f>#</a></h3><p>内存泄漏会导致进程持续占用内存而不释放。使用以下命令可以查看进程的内存占用：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>top
</span></span></code></pre></div><p>然后查看是否有进程的内存使用持续增长。</p><p>对于某些应用程序，如果你怀疑存在内存泄漏，可以尝试重启进程，或者使用工具如 <code>valgrind</code> 来进一步排查问题。</p><h3 id=7-使用>7. <strong>使用 <code>smem</code> 查看内存使用情况</strong>
<a class=anchor href=#7-%e4%bd%bf%e7%94%a8>#</a></h3><p><code>smem</code> 命令可以显示更详细的内存使用情况，包括共享内存和私有内存：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>smem -r
</span></span></code></pre></div><p>这会显示所有进程的内存占用情况，包括共享内存。</p><h3 id=8-查看缓存和缓冲区的使用情况>8. <strong>查看缓存和缓冲区的使用情况</strong>
<a class=anchor href=#8-%e6%9f%a5%e7%9c%8b%e7%bc%93%e5%ad%98%e5%92%8c%e7%bc%93%e5%86%b2%e5%8c%ba%e7%9a%84%e4%bd%bf%e7%94%a8%e6%83%85%e5%86%b5>#</a></h3><p>Linux 会将空闲内存用作文件缓存和缓冲区，以提高磁盘访问性能。可以通过 <code>free</code> 或 <code>cat /proc/meminfo</code> 查看这些数据：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cat /proc/meminfo
</span></span></code></pre></div><p>你会看到 <code>Cached</code> 和 <code>Buffers</code> 项，它们表示内存缓存和缓冲区的使用。通常，缓存和缓冲区的内存使用不算真正的“已用内存”，因为它们会在需要时释放。</p><h3 id=9-分析内存的分配情况>9. <strong>分析内存的分配情况（<code>/proc/meminfo</code>）</strong>
<a class=anchor href=#9-%e5%88%86%e6%9e%90%e5%86%85%e5%ad%98%e7%9a%84%e5%88%86%e9%85%8d%e6%83%85%e5%86%b5>#</a></h3><p><code>/proc/meminfo</code> 文件包含了系统的详细内存信息。你可以通过以下命令查看：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cat /proc/meminfo
</span></span></code></pre></div><p>你可以根据以下项来查看内存使用情况：</p><ul><li><code>MemTotal</code>: 总内存</li><li><code>MemFree</code>: 空闲内存</li><li><code>Buffers</code>: 缓冲区内存</li><li><code>Cached</code>: 缓存内存</li><li><code>SwapTotal</code>: 总交换空间</li><li><code>SwapFree</code>: 空闲交换空间</li></ul><h3 id=10-检查进程的内存使用情况>10. <strong>检查进程的内存使用情况（<code>pmap</code>）</strong>
<a class=anchor href=#10-%e6%a3%80%e6%9f%a5%e8%bf%9b%e7%a8%8b%e7%9a%84%e5%86%85%e5%ad%98%e4%bd%bf%e7%94%a8%e6%83%85%e5%86%b5>#</a></h3><p><code>pmap</code> 命令可以查看某个进程的内存分配情况：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pmap &lt;PID&gt;
</span></span></code></pre></div><p>这可以帮助你深入了解一个特定进程的内存使用情况。</p><h3 id=11-检查系统的-oom-out-of-memory-事件>11. <strong>检查系统的 OOM (Out of Memory) 事件</strong>
<a class=anchor href=#11-%e6%a3%80%e6%9f%a5%e7%b3%bb%e7%bb%9f%e7%9a%84-oom-out-of-memory-%e4%ba%8b%e4%bb%b6>#</a></h3><p>如果系统内存不足，内核可能会启动 OOM 杀手，杀死某些进程以释放内存。你可以查看系统日志文件来确认是否有 OOM 事件：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>dmesg | grep -i oom
</span></span></code></pre></div><p>或查看 <code>/var/log/syslog</code> 或 <code>/var/log/messages</code>。</p><h3 id=12-使用>12. <strong>使用 <code>lsof</code> 查找打开的文件</strong>
<a class=anchor href=#12-%e4%bd%bf%e7%94%a8>#</a></h3><p>在某些情况下，进程可能会占用大量内存和文件句柄，导致内存耗尽。可以使用 <code>lsof</code> 查看系统中打开的文件：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>lsof | grep &lt;PID&gt;
</span></span></code></pre></div><p>查看是否有大量文件被打开，尤其是一些大文件或连接。</p><h3 id=13-内存优化和限制>13. <strong>内存优化和限制</strong>
<a class=anchor href=#13-%e5%86%85%e5%ad%98%e4%bc%98%e5%8c%96%e5%92%8c%e9%99%90%e5%88%b6>#</a></h3><ul><li><p>限制进程内存使用</p><p>：你可以使用</p><pre tabindex=0><code>ulimit
</code></pre><p>设置进程的内存使用限制，避免某些进程占用过多内存：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ulimit -v &lt;memory_limit&gt;
</span></span></code></pre></div></li><li><p>内存清理</p><p>：如果发现系统内存被缓存占用，可以尝试释放缓存：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sync; echo <span style=color:#ae81ff>3</span> &gt; /proc/sys/vm/drop_caches
</span></span></code></pre></div></li></ul><p>通过这些步骤，你应该能够确定内存过高使用的原因，并采取相应的措施解决问题。如果是某个进程异常占用内存，可以考虑优化或重启该进程；如果是系统配置问题，可能需要增加物理内存或优化交换空间的使用。</p><h2 id=echo-devmappervgdocker-lvapp-apps--------------------xfs----rwpquota--------0-0--etcfstabpquota-啥意思-不加这个参数会导致docker容器根磁盘限额失效吗或者说导致docker起不来-导致kubelet起不来>echo &ldquo;#/dev/mapper/vg&ndash;docker-lvapp /apps xfs rw,pquota 0 0&rdquo; &#187; /etc/fstab，pquota 啥意思 不加这个参数会导致docker容器根磁盘限额失效吗，或者说导致docker起不来 导致kubelet起不来
<a class=anchor href=#echo-devmappervgdocker-lvapp-apps--------------------xfs----rwpquota--------0-0--etcfstabpquota-%e5%95%a5%e6%84%8f%e6%80%9d-%e4%b8%8d%e5%8a%a0%e8%bf%99%e4%b8%aa%e5%8f%82%e6%95%b0%e4%bc%9a%e5%af%bc%e8%87%b4docker%e5%ae%b9%e5%99%a8%e6%a0%b9%e7%a3%81%e7%9b%98%e9%99%90%e9%a2%9d%e5%a4%b1%e6%95%88%e5%90%97%e6%88%96%e8%80%85%e8%af%b4%e5%af%bc%e8%87%b4docker%e8%b5%b7%e4%b8%8d%e6%9d%a5-%e5%af%bc%e8%87%b4kubelet%e8%b5%b7%e4%b8%8d%e6%9d%a5>#</a></h2><p><code>pquota</code> 是一个挂载选项，通常与 <strong>xfs</strong> 文件系统的配额（quota）功能相关，表示启用磁盘配额功能来限制某些用户、组或目录的磁盘使用量。</p><ul><li><strong><code>pquota</code></strong>：这个选项用于启用 XFS 文件系统的 <strong>项目配额</strong>（Project Quotas），也就是对特定项目（项目是基于某个目录的，可以理解为一个与特定目录关联的配额）设置配额。启用该选项后，系统会对 <code>/apps</code> 目录的文件进行配额管理。</li></ul><h3 id=1-配额的作用>1. <strong>配额的作用</strong>
<a class=anchor href=#1-%e9%85%8d%e9%a2%9d%e7%9a%84%e4%bd%9c%e7%94%a8>#</a></h3><ul><li>配额用于控制文件系统中用户或项目的最大磁盘使用量。例如，你可以限制某个 Docker 容器根目录的磁盘空间，避免某个容器占满整个磁盘，影响其他容器或系统运行。</li><li>如果启用了配额，系统会根据配置限制某个用户、组或路径下的文件总占用空间，一旦达到配额限制，文件的写入操作就会被拒绝。</li></ul><h3 id=2-不加>2. <strong>不加 <code>pquota</code> 会有什么影响？</strong>
<a class=anchor href=#2-%e4%b8%8d%e5%8a%a0>#</a></h3><ul><li><strong>不会启用项目配额</strong>：如果不加 <code>pquota</code>，就不会启用 XFS 文件系统的配额功能。因此，你就无法控制 <code>/apps</code> 目录下的磁盘使用配额，或者说，无法设置 Docker 容器的磁盘限制。</li><li><strong>对 Docker 或 Kubelet 是否影响</strong>：如果你没有启用配额，理论上 Docker 和 Kubernetes 的容器应该还是能够正常启动，因为它们依赖于磁盘的可用性，而不是配额功能。配额只是在磁盘空间使用上进行额外的限制和管理。如果没有配额，容器仍然能够使用整个磁盘，只是没有限制。</li></ul><h3 id=3-可能的风险>3. <strong>可能的风险</strong>
<a class=anchor href=#3-%e5%8f%af%e8%83%bd%e7%9a%84%e9%a3%8e%e9%99%a9>#</a></h3><ul><li><strong>没有配额的风险</strong>：如果 Docker 容器没有配额限制，某个容器可能会无限制地占用磁盘空间，导致磁盘被填满，影响系统的其他部分（包括 Kubelet）。如果没有设置限制，Docker 容器可能会导致系统磁盘空间耗尽，从而影响容器或其他服务的运行。</li></ul><h3 id=4-总结>4. <strong>总结</strong>
<a class=anchor href=#4-%e6%80%bb%e7%bb%93>#</a></h3><ul><li><strong><code>pquota</code></strong> 参数启用 XFS 的配额功能，确保某个目录（如 <code>/apps</code>）下的文件使用量受到限制。</li><li><strong>如果不加 <code>pquota</code>，配额功能会失效</strong>，但是 <strong>Docker 容器和 Kubelet 仍然能够正常启动</strong>，前提是磁盘没有被完全占满。</li><li>只有在你希望对 Docker 容器的磁盘使用进行严格限制时，才需要启用这个选项。否则，如果你不加 <code>pquota</code>，Docker 容器会自由使用磁盘空间，但仍可能面临磁盘满的问题。</li></ul><p>如果你的目的是限制 Docker 容器的磁盘空间，启用配额功能会更加稳妥，避免单个容器占用过多磁盘空间影响其他容器和系统的正常运行。</p><p>如果 Docker 容器和 Kubelet 无法启动，并且你怀疑是由于 <code>/etc/fstab</code> 中缺少 <code>pquota</code> 参数导致的，以下是一些排查和解决步骤：</p><h3 id=1-检查挂载是否正确>1. <strong>检查挂载是否正确</strong>
<a class=anchor href=#1-%e6%a3%80%e6%9f%a5%e6%8c%82%e8%bd%bd%e6%98%af%e5%90%a6%e6%ad%a3%e7%a1%ae>#</a></h3><p>确保 <code>/etc/fstab</code> 文件中的挂载项正确配置，并且文件系统已成功挂载。运行以下命令检查挂载情况：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>mount | grep /apps
</span></span></code></pre></div><p>如果没有显示 <code>/apps</code> 挂载的相关信息，说明该文件系统没有成功挂载。你可以尝试手动挂载：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>mount -a
</span></span></code></pre></div><p>这个命令会根据 <code>/etc/fstab</code> 文件的配置挂载所有未挂载的文件系统。</p><h3 id=2-检查磁盘配额是否启用>2. <strong>检查磁盘配额是否启用</strong>
<a class=anchor href=#2-%e6%a3%80%e6%9f%a5%e7%a3%81%e7%9b%98%e9%85%8d%e9%a2%9d%e6%98%af%e5%90%a6%e5%90%af%e7%94%a8>#</a></h3><p>如果确实需要启用项目配额（<code>pquota</code>），首先确保系统支持并已启用配额。可以查看 <code>/etc/fstab</code> 配置中的挂载选项是否正确。你可以通过以下命令查看 XFS 文件系统是否启用了项目配额：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>xfs_info /apps
</span></span></code></pre></div><p>在输出中查找 <code>pquota</code> 是否启用。如果没有启用配额，尝试修改 <code>/etc/fstab</code>，加上 <code>pquota</code> 选项：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>echo <span style=color:#e6db74>&#34;#/dev/mapper/vg--docker-lvapp /apps xfs rw,pquota 0 0&#34;</span> &gt;&gt; /etc/fstab
</span></span></code></pre></div><p>然后重新挂载：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>mount -o remount /apps
</span></span></code></pre></div><h3 id=3-检查系统日志>3. <strong>检查系统日志</strong>
<a class=anchor href=#3-%e6%a3%80%e6%9f%a5%e7%b3%bb%e7%bb%9f%e6%97%a5%e5%bf%97>#</a></h3><p>查看系统日志来确定为什么 Docker 和 Kubelet 没有启动，特别是看看是否有与磁盘挂载或配额相关的错误。检查以下日志：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>journalctl -xe | grep docker
</span></span><span style=display:flex><span>journalctl -xe | grep kubelet
</span></span></code></pre></div><p>这些日志可能会提供更具体的错误信息，帮助你定位问题。</p><h3 id=4-检查-docker-和-kubelet-配置>4. <strong>检查 Docker 和 Kubelet 配置</strong>
<a class=anchor href=#4-%e6%a3%80%e6%9f%a5-docker-%e5%92%8c-kubelet-%e9%85%8d%e7%bd%ae>#</a></h3><ul><li><strong>Docker 配置</strong>：查看 Docker 的日志（通常在 <code>/var/log/docker.log</code>）来确认是否有磁盘空间问题或者其他启动失败的原因。</li><li><strong>Kubelet 配置</strong>：Kubelet 启动失败也可能与挂载或磁盘配置有关，查看 <code>/var/log/syslog</code> 或 <code>/var/log/messages</code> 中的错误信息。</li></ul><h3 id=5-确认磁盘是否满>5. <strong>确认磁盘是否满</strong>
<a class=anchor href=#5-%e7%a1%ae%e8%ae%a4%e7%a3%81%e7%9b%98%e6%98%af%e5%90%a6%e6%bb%a1>#</a></h3><p>如果磁盘空间不足，Docker 和 Kubelet 可能也无法启动。检查磁盘的使用情况：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>df -h
</span></span></code></pre></div><p>如果磁盘空间已满，可以清理不必要的文件，或者增加磁盘空间。</p><h3 id=6-尝试移除>6. <strong>尝试移除 <code>pquota</code> 选项</strong>
<a class=anchor href=#6-%e5%b0%9d%e8%af%95%e7%a7%bb%e9%99%a4>#</a></h3><p>如果你怀疑是 <code>pquota</code> 选项导致 Docker 或 Kubelet 启动失败，可以临时移除该选项，重新挂载文件系统，并重试 Docker 和 Kubelet 启动。修改 <code>/etc/fstab</code> 移除 <code>pquota</code> 选项后，重新挂载：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>mount -o remount /apps
</span></span></code></pre></div><p>然后检查 Docker 和 Kubelet 是否能启动。</p><h3 id=7-重新启动-docker-和-kubelet>7. <strong>重新启动 Docker 和 Kubelet</strong>
<a class=anchor href=#7-%e9%87%8d%e6%96%b0%e5%90%af%e5%8a%a8-docker-%e5%92%8c-kubelet>#</a></h3><p>在确认文件系统挂载无误后，尝试重新启动 Docker 和 Kubelet：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>systemctl restart docker
</span></span><span style=display:flex><span>systemctl restart kubelet
</span></span></code></pre></div><p>然后检查它们的状态：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>systemctl status docker
</span></span><span style=display:flex><span>systemctl status kubelet
</span></span></code></pre></div><hr><p>如果 Docker 和 Kubelet 仍然无法启动，可以通过查看日志或增加 <code>pquota</code> 配额选项来进一步诊断。</p><h2 id=修改calico的默认的vxlan的端口号>修改calico的默认的vxlan的端口号
<a class=anchor href=#%e4%bf%ae%e6%94%b9calico%e7%9a%84%e9%bb%98%e8%ae%a4%e7%9a%84vxlan%e7%9a%84%e7%ab%af%e5%8f%a3%e5%8f%b7>#</a></h2><p>要修改 Calico 默认的 VXLAN 端口号，你需要修改 Calico 的配置文件，使其使用自定义端口。Calico 默认使用 VXLAN 隧道技术来处理节点间的网络通信，默认端口号是 4789。如果你想修改该端口，可以通过修改 Calico 的配置文件来实现。</p><h3 id=1-修改-calico-配置>1. <strong>修改 Calico 配置</strong>
<a class=anchor href=#1-%e4%bf%ae%e6%94%b9-calico-%e9%85%8d%e7%bd%ae>#</a></h3><p>Calico 的 VXLAN 配置通常在 <code>calicoctl</code> 配置文件或者 Kubernetes 的 ConfigMap 中进行修改。以下是两种常见的方式：</p><h4 id=方式一使用-calicoctl-修改-vxlan-端口>方式一：使用 <code>calicoctl</code> 修改 VXLAN 端口
<a class=anchor href=#%e6%96%b9%e5%bc%8f%e4%b8%80%e4%bd%bf%e7%94%a8-calicoctl-%e4%bf%ae%e6%94%b9-vxlan-%e7%ab%af%e5%8f%a3>#</a></h4><p>你可以使用 <code>calicoctl</code> 命令来修改 VXLAN 的端口配置。</p><ol><li><p><strong>检查现有的 Calico 配置</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>calicoctl get bgpconfiguration default -o yaml
</span></span></code></pre></div></li><li><p><strong>创建或修改 Calico 配置</strong>： 要修改 VXLAN 端口号，需要修改 Calico 的 <code>bgpconfiguration</code> 或 <code>ipam</code> 配置。首先创建一个新的配置文件（例如 <code>calico-vxlan-port.yaml</code>）：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>crd.projectcalico.org/v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>BGPConfiguration</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>default</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>vxlanPort</span>: <span style=color:#ae81ff>&lt;new-port-number&gt; </span> <span style=color:#75715e># 替换为你想设置的端口号</span>
</span></span></code></pre></div></li><li><p><strong>应用配置</strong>： 使用以下命令应用该配置：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>calicoctl apply -f calico-vxlan-port.yaml
</span></span></code></pre></div></li><li><p><strong>验证配置</strong>： 应用后，你可以通过以下命令确认配置是否成功：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>calicoctl get bgpconfiguration default -o yaml
</span></span></code></pre></div></li></ol><h4 id=方式二通过-kubernetes-configmap-修改>方式二：通过 Kubernetes ConfigMap 修改
<a class=anchor href=#%e6%96%b9%e5%bc%8f%e4%ba%8c%e9%80%9a%e8%bf%87-kubernetes-configmap-%e4%bf%ae%e6%94%b9>#</a></h4><p>如果你是使用 Kubernetes 来部署 Calico，可以通过修改 ConfigMap 来修改 VXLAN 端口。</p><ol><li><p><strong>找到 Calico 的 ConfigMap</strong>： 在 Kubernetes 中，Calico 的配置通常保存在 <code>calico-config</code> ConfigMap 中，使用以下命令查找它：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get configmap -n kube-system calico-config -o yaml
</span></span></code></pre></div></li><li><p><strong>修改 ConfigMap</strong>： 找到并编辑 <code>calico-config</code> ConfigMap，修改 <code>vxlanPort</code> 的配置。你可以使用 <code>kubectl edit</code> 或者手动编辑 ConfigMap 文件：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl edit configmap calico-config -n kube-system
</span></span></code></pre></div><p>在编辑文件时，找到 <code>vxlanPort</code> 选项并设置新的端口号。例如：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>data</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>calico_backend</span>: <span style=color:#ae81ff>vxlan</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>vxlanPort</span>: <span style=color:#e6db74>&#34;&lt;new-port-number&gt;&#34;</span>  <span style=color:#75715e># 替换为你想设置的端口号</span>
</span></span></code></pre></div></li><li><p><strong>应用更新后的 ConfigMap</strong>： 保存文件并退出编辑器。更新后的 ConfigMap 会自动应用。</p></li><li><p><strong>重启 Calico Pods</strong>： 更新配置后，需要重启 Calico 的 Pod 来使新配置生效。你可以使用以下命令来重启 Calico 的 DaemonSet：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl rollout restart daemonset calico-node -n kube-system
</span></span></code></pre></div></li></ol><h3 id=2-验证配置>2. <strong>验证配置</strong>
<a class=anchor href=#2-%e9%aa%8c%e8%af%81%e9%85%8d%e7%bd%ae>#</a></h3><p>配置修改完成后，你可以通过以下命令来确认 VXLAN 端口是否已经修改成功：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>calicoctl get bgpconfiguration default -o yaml
</span></span></code></pre></div><p>或者在 Kubernetes 环境中，检查 Calico Pod 的日志：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl logs -n kube-system &lt;calico-pod-name&gt;
</span></span></code></pre></div><p>你还可以查看 <code>ip link</code> 或 <code>ss</code> 来确认 VXLAN 的端口号是否已经生效。</p><h3 id=3-注意事项>3. <strong>注意事项</strong>
<a class=anchor href=#3-%e6%b3%a8%e6%84%8f%e4%ba%8b%e9%a1%b9>#</a></h3><ul><li>修改 VXLAN 端口号后，确保你的防火墙规则或网络策略允许新的端口号通过，特别是节点间的网络。</li><li>修改配置后，可能需要重新启动 Calico 节点，以确保配置生效。</li></ul><p>通过这些步骤，你可以成功修改 Calico 的 VXLAN 端口号。</p><p>是的，<strong>Felix</strong>（Calico 的数据平面代理）也有一个配置项用于指定 VXLAN 的端口号。Felix 配置项可以通过修改 <code>FelixConfiguration</code> CRD 或 Kubernetes 中的 ConfigMap 来修改 VXLAN 的端口号。具体配置项是 <code>vxlanPort</code>，你可以在这里指定新的端口号。</p><h3 id=修改-felix-配置来更改-vxlan-端口号>修改 Felix 配置来更改 VXLAN 端口号
<a class=anchor href=#%e4%bf%ae%e6%94%b9-felix-%e9%85%8d%e7%bd%ae%e6%9d%a5%e6%9b%b4%e6%94%b9-vxlan-%e7%ab%af%e5%8f%a3%e5%8f%b7>#</a></h3><ol><li><p><strong>查找当前 Felix 配置</strong>：</p><p>如果你正在 Kubernetes 中使用 Calico，可以通过以下命令查看 <code>FelixConfiguration</code> 配置：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get felixconfiguration default -o yaml
</span></span></code></pre></div></li><li><p><strong>修改 Felix 配置</strong>：</p><p>使用 <code>kubectl edit</code> 编辑 <code>FelixConfiguration</code> CRD，或者你可以直接创建一个新的 YAML 文件，指定自定义的 VXLAN 端口号。例如：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>crd.projectcalico.org/v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>FelixConfiguration</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>default</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>vxlanPort</span>: <span style=color:#ae81ff>&lt;new-port-number&gt; </span> <span style=color:#75715e># 替换为你想设置的端口号</span>
</span></span></code></pre></div><p>使用 <code>kubectl</code> 应用配置：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f felix-vxlan-port.yaml
</span></span></code></pre></div></li><li><p><strong>验证配置</strong>：</p><p>你可以通过以下命令检查 Felix 配置是否成功应用：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get felixconfiguration default -o yaml
</span></span></code></pre></div></li><li><p><strong>重启 Calico 节点</strong>：</p><p>修改 Felix 配置后，需要重启 Calico 节点才能使新配置生效。你可以通过以下命令重启 <code>calico-node</code> DaemonSet：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl rollout restart daemonset calico-node -n kube-system
</span></span></code></pre></div></li><li><p><strong>验证 VXLAN 端口是否修改成功</strong>：</p><p>使用以下命令检查 VXLAN 端口是否已经生效：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>calicoctl get bgpconfiguration default -o yaml
</span></span></code></pre></div><p>或者你可以查看 <code>calico-node</code> 的日志来确认是否使用了新的 VXLAN 端口：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl logs -n kube-system &lt;calico-pod-name&gt;
</span></span></code></pre></div></li></ol><h3 id=总结>总结
<a class=anchor href=#%e6%80%bb%e7%bb%93>#</a></h3><ul><li><strong>Felix 配置</strong>：通过修改 <code>FelixConfiguration</code> CRD，可以指定 VXLAN 的端口号。配置项是 <code>vxlanPort</code>。</li><li><strong>通过 <code>kubectl</code> 修改</strong>：可以直接使用 <code>kubectl</code> 修改或创建 <code>FelixConfiguration</code>，并应用新的配置。</li><li><strong>重启 <code>calico-node</code></strong>：修改配置后需要重启 Calico 节点，以使配置生效。</li></ul><p>通过以上步骤，你可以成功地修改 Calico 中 Felix 的 VXLAN 端口号。</p><h2 id=没有启用配额但docker的daemonjson的opt有限制磁盘大小的参数docker起不来的吧>没有启用配额，但docker的daemon.json的opt有限制磁盘大小的参数，docker起不来的吧
<a class=anchor href=#%e6%b2%a1%e6%9c%89%e5%90%af%e7%94%a8%e9%85%8d%e9%a2%9d%e4%bd%86docker%e7%9a%84daemonjson%e7%9a%84opt%e6%9c%89%e9%99%90%e5%88%b6%e7%a3%81%e7%9b%98%e5%a4%a7%e5%b0%8f%e7%9a%84%e5%8f%82%e6%95%b0docker%e8%b5%b7%e4%b8%8d%e6%9d%a5%e7%9a%84%e5%90%a7>#</a></h2><p>是的，如果在 Docker 的 <code>daemon.json</code> 配置文件中启用了磁盘大小限制参数（如 <code>storage-opts</code> 中的 <code>size</code> 配置），但是没有正确设置文件系统的配额（特别是对于 Docker 容器的磁盘限制），那么 Docker 守护进程可能会无法启动，尤其是在以下情况下：</p><h3 id=1-daemonjson>1. <strong><code>daemon.json</code> 配置示例</strong>
<a class=anchor href=#1-daemonjson>#</a></h3><p>如果你在 <code>daemon.json</code> 中启用了磁盘大小限制参数（例如 <code>storage-opts</code> 下的 <code>size</code> 参数），它通常会限制 Docker 容器使用的存储空间。下面是一个典型的 <code>daemon.json</code> 配置示例：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;storage-driver&#34;</span>: <span style=color:#e6db74>&#34;overlay2&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;storage-opts&#34;</span>: [
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;size=20G&#34;</span>
</span></span><span style=display:flex><span>  ]
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>这段配置表示每个 Docker 容器的磁盘空间最大为 20GB。</p><h3 id=2-可能的错误>2. <strong>可能的错误</strong>
<a class=anchor href=#2-%e5%8f%af%e8%83%bd%e7%9a%84%e9%94%99%e8%af%af>#</a></h3><p>如果没有启用磁盘配额（尤其是在使用 XFS 或其他文件系统时），而 <code>daemon.json</code> 中的 <code>storage-opts</code> 参数试图限制磁盘大小，Docker 守护进程可能会遇到以下问题：</p><ul><li><strong>容器无法限制磁盘空间</strong>：如果没有配额，<code>size</code> 参数将无法实际生效，可能导致 Docker 容器无法启动，因为 Docker 不能控制容器的存储空间大小。</li><li><strong>Docker 启动失败</strong>：如果 <code>daemon.json</code> 中的参数与系统设置（如文件系统配额或磁盘空间）不兼容，Docker 可能会因配置错误无法启动。</li><li><strong>磁盘空间不足</strong>：如果 Docker 守护进程配置了磁盘限制（例如限制了容器磁盘空间），而文件系统本身没有配额支持，可能会导致磁盘使用不当，最终导致 Docker 守护进程启动失败。</li></ul><h3 id=3-如何避免-docker-启动失败>3. <strong>如何避免 Docker 启动失败</strong>
<a class=anchor href=#3-%e5%a6%82%e4%bd%95%e9%81%bf%e5%85%8d-docker-%e5%90%af%e5%8a%a8%e5%a4%b1%e8%b4%a5>#</a></h3><ul><li><p><strong>检查文件系统支持</strong>：确保文件系统支持容器磁盘配额功能。如果使用的是 <code>xfs</code> 文件系统，需要确保配额（<code>pquota</code>）已启用。</p></li><li><p><strong>检查 <code>daemon.json</code> 配置</strong>：确保 Docker 配置中 <code>storage-opts</code> 与文件系统的配额配置兼容。</p></li><li><p>重启 Docker 服务</p><p>：修改配置后，记得重启 Docker 服务：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>systemctl restart docker
</span></span></code></pre></div></li></ul><h3 id=4-解决方法>4. <strong>解决方法</strong>
<a class=anchor href=#4-%e8%a7%a3%e5%86%b3%e6%96%b9%e6%b3%95>#</a></h3><ul><li><strong>启用文件系统配额</strong>：如果你需要限制容器的磁盘使用量，确保文件系统（如 XFS）启用了配额功能。对于 XFS，可以在挂载时加上 <code>pquota</code> 参数，并确保文件系统支持该功能。</li><li><strong>避免过度配置限制</strong>：在没有配额支持的情况下，不要在 <code>daemon.json</code> 中配置磁盘大小限制，或者考虑移除 <code>size</code> 参数。</li></ul><h3 id=5-排查-docker-启动问题>5. <strong>排查 Docker 启动问题</strong>
<a class=anchor href=#5-%e6%8e%92%e6%9f%a5-docker-%e5%90%af%e5%8a%a8%e9%97%ae%e9%a2%98>#</a></h3><p>如果 Docker 因为磁盘大小限制而无法启动，可以通过查看 Docker 日志来获取更多信息：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>journalctl -u docker.service
</span></span></code></pre></div><p>查看是否有与磁盘配额或磁盘空间限制相关的错误信息。</p><hr><p>总结来说，<strong>如果没有启用文件系统配额</strong>，而在 <code>daemon.json</code> 中设置了磁盘大小限制，Docker 可能无法启动，因为它会尝试应用这些限制，但是缺乏合适的配额支持。因此，你需要确保配置一致性，并且文件系统支持相关的配额功能。</p><h2 id=单etcd单master拓展为3master3etcdmaster节点挂上vip做高可用证书重新生成etcd之前数据保留>单etcd单master拓展为3master3etcd，master节点挂上vip，做高可用，证书重新生成，etcd之前数据保留
<a class=anchor href=#%e5%8d%95etcd%e5%8d%95master%e6%8b%93%e5%b1%95%e4%b8%ba3master3etcdmaster%e8%8a%82%e7%82%b9%e6%8c%82%e4%b8%8avip%e5%81%9a%e9%ab%98%e5%8f%af%e7%94%a8%e8%af%81%e4%b9%a6%e9%87%8d%e6%96%b0%e7%94%9f%e6%88%90etcd%e4%b9%8b%e5%89%8d%e6%95%b0%e6%8d%ae%e4%bf%9d%e7%95%99>#</a></h2><p><a href=https://qq547475331.github.io/2025/02/19/2024-5-14%20%E5%8D%95master%E5%8D%95etcd%E6%94%B9%E9%80%A0/>单master单etcd改造为3master3etcd</a></p><p>将一个 <strong>单 Master 单 ETCD</strong> 的 Kubernetes 集群拓展为 <strong>3 Master 3 ETCD</strong> 并实现高可用性（HA），同时保持 <strong>ETCD 数据</strong> 的持久性，并确保新证书的生成，可以按照以下步骤进行：</p><h3 id=1-准备工作>1. <strong>准备工作</strong>
<a class=anchor href=#1-%e5%87%86%e5%a4%87%e5%b7%a5%e4%bd%9c>#</a></h3><p>在开始之前，确保：</p><ul><li><strong>备份现有的 ETCD 数据</strong>：在操作前，请备份当前单 Master 集群的 ETCD 数据，以防万一。</li><li><strong>准备证书</strong>：由于需要重新生成证书（尤其是 Kubernetes 控制平面的证书），你应该确保有一个新的证书管理工具（如 <code>kubeadm</code> 或自定义脚本）来处理证书。</li><li><strong>网络和防火墙配置</strong>：确保新的 Master 和 ETCD 节点之间的网络连接没有问题，尤其是 TCP 端口 2379 和 2380（ETCD 的通信端口）要开放。</li></ul><h3 id=2-部署-3-master-节点>2. <strong>部署 3 Master 节点</strong>
<a class=anchor href=#2-%e9%83%a8%e7%bd%b2-3-master-%e8%8a%82%e7%82%b9>#</a></h3><h4 id=21-配置-vip>2.1. <strong>配置 VIP</strong>
<a class=anchor href=#21-%e9%85%8d%e7%bd%ae-vip>#</a></h4><p>为 Master 节点配置 <strong>虚拟 IP (VIP)</strong>，使得客户端（如 kubelet 和 kubectl）可以访问一个统一的 API Server 地址。你可以使用 <strong>Keepalived</strong> 或其他工具来配置高可用 VIP。</p><p><strong>安装 Keepalived</strong>（在每个 Master 节点上）：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>apt install keepalived
</span></span></code></pre></div><p>然后在每个 Master 节点上配置 <strong>keepalived.conf</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># /etc/keepalived/keepalived.conf</span>
</span></span><span style=display:flex><span>vrrp_instance VI_1 <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    state MASTER
</span></span><span style=display:flex><span>    interface eth0  <span style=color:#75715e># 修改为你的网络接口</span>
</span></span><span style=display:flex><span>    virtual_ipaddress <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>        192.168.1.100  <span style=color:#75715e># 配置一个虚拟 IP 地址</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span></code></pre></div><p><strong>启动 Keepalived</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>systemctl enable keepalived
</span></span><span style=display:flex><span>systemctl start keepalived
</span></span></code></pre></div><p>这样你就可以为 Kubernetes API Server 配置一个高可用的 VIP。</p><h4 id=22-安装-kubeadm-和-kubernetes>2.2. <strong>安装 kubeadm 和 Kubernetes</strong>
<a class=anchor href=#22-%e5%ae%89%e8%a3%85-kubeadm-%e5%92%8c-kubernetes>#</a></h4><p>在新 Master 节点上安装 kubeadm 和 Kubernetes（如果未安装）：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>apt update
</span></span><span style=display:flex><span>apt install -y kubeadm kubelet kubectl
</span></span></code></pre></div><h4 id=23-加入新-master-节点到集群>2.3. <strong>加入新 Master 节点到集群</strong>
<a class=anchor href=#23-%e5%8a%a0%e5%85%a5%e6%96%b0-master-%e8%8a%82%e7%82%b9%e5%88%b0%e9%9b%86%e7%be%a4>#</a></h4><p>从现有 Master 节点获取加入令牌和集群证书：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubeadm token create --print-join-command
</span></span></code></pre></div><p>将返回的 <code>kubeadm join</code> 命令用于新的 Master 节点，加入现有集群：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubeadm join &lt;api-server-vip&gt;:6443 --token &lt;token&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt;
</span></span></code></pre></div><h4 id=24-升级-api-server-以支持多个-master-节点>2.4. <strong>升级 API Server 以支持多个 Master 节点</strong>
<a class=anchor href=#24-%e5%8d%87%e7%ba%a7-api-server-%e4%bb%a5%e6%94%af%e6%8c%81%e5%a4%9a%e4%b8%aa-master-%e8%8a%82%e7%82%b9>#</a></h4><p>确保 API Server 配置支持多 Master 集群。此时你可能需要编辑现有的 API Server 配置，启用负载均衡器或更新 <code>kube-apiserver</code> 的启动参数，以支持在多个 Master 节点上运行。</p><h3 id=3-部署-3-etcd-节点>3. <strong>部署 3 ETCD 节点</strong>
<a class=anchor href=#3-%e9%83%a8%e7%bd%b2-3-etcd-%e8%8a%82%e7%82%b9>#</a></h3><h4 id=31-etcd-高可用配置>3.1. <strong>ETCD 高可用配置</strong>
<a class=anchor href=#31-etcd-%e9%ab%98%e5%8f%af%e7%94%a8%e9%85%8d%e7%bd%ae>#</a></h4><p>为使 ETCD 集群支持高可用性，需要将现有的单节点 ETCD 拓展为 3 个节点的集群。</p><ol><li><p><strong>备份现有的 ETCD 数据</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ETCDCTL_API<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span> etcdctl snapshot save /tmp/etcd-backup.db
</span></span></code></pre></div></li><li><p><strong>将现有的单节点 ETCD 数据同步到新节点</strong>： 在每个新的 ETCD 节点上安装 ETCD：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>apt-get install etcd
</span></span></code></pre></div></li><li><p><strong>在每个 ETCD 节点上配置 <code>etcd.conf</code></strong>，确保它们可以相互通信。设置 <code>ETCD_INITIAL_CLUSTER</code> 参数，定义每个节点的名称和 IP 地址。例如：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>export ETCD_INITIAL_CLUSTER<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;etcd1=http://&lt;node1-ip&gt;:2380,etcd2=http://&lt;node2-ip&gt;:2380,etcd3=http://&lt;node3-ip&gt;:2380&#34;</span>
</span></span></code></pre></div></li><li><p><strong>启动 ETCD 集群</strong>： 启动每个 ETCD 节点，确保它们彼此之间能连接。</p></li></ol><h4 id=32-修改-kubernetes-配置来使用-3-节点-etcd-集群>3.2. <strong>修改 Kubernetes 配置来使用 3 节点 ETCD 集群</strong>
<a class=anchor href=#32-%e4%bf%ae%e6%94%b9-kubernetes-%e9%85%8d%e7%bd%ae%e6%9d%a5%e4%bd%bf%e7%94%a8-3-%e8%8a%82%e7%82%b9-etcd-%e9%9b%86%e7%be%a4>#</a></h4><p>修改 Kubernetes API Server 配置，使其连接到 3 节点的 ETCD 集群。编辑 <code>kube-apiserver</code> 配置文件，更新 <code>--etcd-servers</code> 参数，指向 3 个 ETCD 节点。</p><p>例如：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>--etcd-servers<span style=color:#f92672>=</span>http://etcd1:2379,http://etcd2:2379,http://etcd3:2379
</span></span></code></pre></div><h3 id=4-更新证书>4. <strong>更新证书</strong>
<a class=anchor href=#4-%e6%9b%b4%e6%96%b0%e8%af%81%e4%b9%a6>#</a></h3><p>在升级为多节点高可用的集群时，所有证书都需要重新生成。可以使用 <code>kubeadm</code> 来重新生成证书：</p><h4 id=41-备份现有证书>4.1. <strong>备份现有证书</strong>
<a class=anchor href=#41-%e5%a4%87%e4%bb%bd%e7%8e%b0%e6%9c%89%e8%af%81%e4%b9%a6>#</a></h4><p>备份现有的 Kubernetes 证书文件（通常在 <code>/etc/kubernetes/pki</code> 下）：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cp -r /etc/kubernetes/pki /etc/kubernetes/pki.bak
</span></span></code></pre></div><h4 id=42-重新生成证书>4.2. <strong>重新生成证书</strong>
<a class=anchor href=#42-%e9%87%8d%e6%96%b0%e7%94%9f%e6%88%90%e8%af%81%e4%b9%a6>#</a></h4><p>使用 <code>kubeadm</code> 重新生成证书：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubeadm init phase certs all --config /etc/kubernetes/kubeadm.conf
</span></span></code></pre></div><h4 id=43-重新部署-kubernetes-组件>4.3. <strong>重新部署 Kubernetes 组件</strong>
<a class=anchor href=#43-%e9%87%8d%e6%96%b0%e9%83%a8%e7%bd%b2-kubernetes-%e7%bb%84%e4%bb%b6>#</a></h4><p>更新证书后，重新部署 Kubernetes 组件（如 kube-apiserver、kube-controller-manager、kube-scheduler 等）。可以使用以下命令进行：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f /etc/kubernetes/manifests/
</span></span></code></pre></div><h3 id=5-恢复-etcd-数据>5. <strong>恢复 ETCD 数据</strong>
<a class=anchor href=#5-%e6%81%a2%e5%a4%8d-etcd-%e6%95%b0%e6%8d%ae>#</a></h3><p>将之前备份的 ETCD 数据恢复到新部署的 ETCD 集群：</p><ol><li><p>在所有 ETCD 节点上停止 ETCD 服务。</p></li><li><p>使用备份的 ETCD 数据恢复：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ETCDCTL_API<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span> etcdctl snapshot restore /tmp/etcd-backup.db --data-dir /var/lib/etcd
</span></span></code></pre></div></li><li><p>启动 ETCD 服务。</p></li></ol><h3 id=6-验证集群>6. <strong>验证集群</strong>
<a class=anchor href=#6-%e9%aa%8c%e8%af%81%e9%9b%86%e7%be%a4>#</a></h3><p>确保所有节点、服务和证书都配置正确，集群正常运行。检查以下内容：</p><ul><li><code>kubectl get nodes</code>：确保所有节点（包括新的 Master）都已加入集群。</li><li><code>kubectl get pods -n kube-system</code>：确保所有核心组件（如 API Server、Controller Manager、Scheduler）都正常运行。</li><li><code>kubectl get componentstatus</code>：检查集群组件的状态。</li></ul><h3 id=总结-1>总结
<a class=anchor href=#%e6%80%bb%e7%bb%93-1>#</a></h3><p>通过以上步骤，您可以将单 Master 单 ETCD 的 Kubernetes 集群扩展为 <strong>3 Master 3 ETCD</strong> 的高可用集群，并在确保 ETCD 数据持久性的同时重新生成所需的证书。这个过程中，确保正确配置 VIP 和负载均衡，确保新的 ETCD 集群与 API Server 配置能够互相通信，最终实现 Kubernetes 高可用性。</p><h6><a class=anchor href=#>#</a></h6><h2 id=跨网段的机器组成k8s集群不同网段机器上的pod之间无法相互访问用calico的vxlan模式修改默认的vxlan的端口号因为之前的4789被物理网关设备占用了>跨网段的机器组成k8s集群，不同网段机器上的pod之间无法相互访问，用calico的vxlan模式，修改默认的vxlan的端口号，因为之前的4789被物理网关设备占用了
<a class=anchor href=#%e8%b7%a8%e7%bd%91%e6%ae%b5%e7%9a%84%e6%9c%ba%e5%99%a8%e7%bb%84%e6%88%90k8s%e9%9b%86%e7%be%a4%e4%b8%8d%e5%90%8c%e7%bd%91%e6%ae%b5%e6%9c%ba%e5%99%a8%e4%b8%8a%e7%9a%84pod%e4%b9%8b%e9%97%b4%e6%97%a0%e6%b3%95%e7%9b%b8%e4%ba%92%e8%ae%bf%e9%97%ae%e7%94%a8calico%e7%9a%84vxlan%e6%a8%a1%e5%bc%8f%e4%bf%ae%e6%94%b9%e9%bb%98%e8%ae%a4%e7%9a%84vxlan%e7%9a%84%e7%ab%af%e5%8f%a3%e5%8f%b7%e5%9b%a0%e4%b8%ba%e4%b9%8b%e5%89%8d%e7%9a%844789%e8%a2%ab%e7%89%a9%e7%90%86%e7%bd%91%e5%85%b3%e8%ae%be%e5%a4%87%e5%8d%a0%e7%94%a8%e4%ba%86>#</a></h2><p>在 Kubernetes 集群中使用 <strong>Calico</strong> 的 VXLAN 模式时，默认情况下，VXLAN 使用 UDP 端口 <strong>4789</strong> 进行通信。如果你的物理网关设备已经占用了 4789 端口，导致不同网段的机器之间的 Pod 无法相互访问，你可以修改 Calico VXLAN 使用的端口号。</p><p>为了修改 <strong>Calico VXLAN</strong> 使用的默认端口号，可以通过配置 <strong>Felix</strong>（Calico 的数据平面代理）和 <strong>Calico 配置文件</strong>来实现。以下是修改 VXLAN 默认端口号的详细步骤。</p><h3 id=步骤-1-修改-felix-配置修改-vxlan-端口>步骤 1: 修改 Felix 配置（修改 VXLAN 端口）
<a class=anchor href=#%e6%ad%a5%e9%aa%a4-1-%e4%bf%ae%e6%94%b9-felix-%e9%85%8d%e7%bd%ae%e4%bf%ae%e6%94%b9-vxlan-%e7%ab%af%e5%8f%a3>#</a></h3><p>Calico 的数据平面由 <strong>Felix</strong> 处理，它可以控制 VXLAN 端口的设置。你可以通过修改 <code>FelixConfiguration</code> CRD（自定义资源定义）来调整 VXLAN 端口。</p><h4 id=11-查看当前的-felix-配置>1.1. <strong>查看当前的 Felix 配置</strong>
<a class=anchor href=#11-%e6%9f%a5%e7%9c%8b%e5%bd%93%e5%89%8d%e7%9a%84-felix-%e9%85%8d%e7%bd%ae>#</a></h4><p>使用以下命令查看当前的 <code>FelixConfiguration</code>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get felixconfiguration default -o yaml
</span></span></code></pre></div><h4 id=12-创建或修改-felix-配置>1.2. <strong>创建或修改 Felix 配置</strong>
<a class=anchor href=#12-%e5%88%9b%e5%bb%ba%e6%88%96%e4%bf%ae%e6%94%b9-felix-%e9%85%8d%e7%bd%ae>#</a></h4><p>为了修改 VXLAN 端口，可以创建或修改 <code>FelixConfiguration</code> CRD，指定新的端口号。比如将默认端口 <code>4789</code> 修改为 <code>12345</code>。</p><p>创建一个新的配置文件（例如：<code>felix-vxlan-port.yaml</code>）：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>crd.projectcalico.org/v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>FelixConfiguration</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>default</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>vxlanPort</span>: <span style=color:#ae81ff>12345</span>  <span style=color:#75715e># 将此处端口号修改为你想使用的端口</span>
</span></span></code></pre></div><p>应用该配置：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f felix-vxlan-port.yaml
</span></span></code></pre></div><h4 id=13-重启-calico-节点>1.3. <strong>重启 Calico 节点</strong>
<a class=anchor href=#13-%e9%87%8d%e5%90%af-calico-%e8%8a%82%e7%82%b9>#</a></h4><p>配置完成后，重启 <strong>Calico</strong> 节点以使配置生效。你可以通过以下命令重启 <code>calico-node</code> DaemonSet：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl rollout restart daemonset calico-node -n kube-system
</span></span></code></pre></div><h3 id=步骤-2-修改-kubernetes-api-server-和节点配置>步骤 2: 修改 Kubernetes API Server 和节点配置
<a class=anchor href=#%e6%ad%a5%e9%aa%a4-2-%e4%bf%ae%e6%94%b9-kubernetes-api-server-%e5%92%8c%e8%8a%82%e7%82%b9%e9%85%8d%e7%bd%ae>#</a></h3><p>Calico VXLAN 的端口号是由 Felix 配置的，但你还需要确保集群中每个节点的网络设置允许跨网段通信，并且新的端口号不被其他网络设备占用。</p><h4 id=21-更新-api-server-配置>2.1. <strong>更新 API Server 配置</strong>
<a class=anchor href=#21-%e6%9b%b4%e6%96%b0-api-server-%e9%85%8d%e7%bd%ae>#</a></h4><p>如果你修改了 VXLAN 端口号，需要确保所有节点的网络路由能够通过新的端口进行通信。通常，Kubernetes 的 API Server 配置（<code>kube-apiserver</code>）无需特别更改，但你要确保节点间的网络路由和防火墙规则允许通过新的 VXLAN 端口进行通信。</p><h4 id=22-更新防火墙和网络规则>2.2. <strong>更新防火墙和网络规则</strong>
<a class=anchor href=#22-%e6%9b%b4%e6%96%b0%e9%98%b2%e7%81%ab%e5%a2%99%e5%92%8c%e7%bd%91%e7%bb%9c%e8%a7%84%e5%88%99>#</a></h4><p>确保跨网段的机器间能够通过新的 VXLAN 端口进行通信。你需要在集群节点上开放新的端口（例如 <code>12345</code>）：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 以 root 权限开放端口</span>
</span></span><span style=display:flex><span>iptables -A INPUT -p udp --dport <span style=color:#ae81ff>12345</span> -j ACCEPT
</span></span></code></pre></div><p>对于 <strong>iptables</strong> 和其他防火墙系统，确保 <code>12345</code> 端口可以在所有节点间进行通信。</p><h3 id=步骤-3-验证配置>步骤 3: 验证配置
<a class=anchor href=#%e6%ad%a5%e9%aa%a4-3-%e9%aa%8c%e8%af%81%e9%85%8d%e7%bd%ae>#</a></h3><p>修改配置后，确认以下几项：</p><ol><li><p><strong>检查 VXLAN 端口是否生效</strong></p><p>在每个节点上，确认 VXLAN 使用的是新的端口号。你可以使用 <code>ss</code> 或 <code>netstat</code> 工具来确认端口监听情况：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ss -uln | grep <span style=color:#ae81ff>12345</span>
</span></span></code></pre></div></li><li><p><strong>验证跨网段通信是否正常</strong></p><p>在不同网段的 Pod 上，执行 <code>ping</code> 或 <code>curl</code> 来确认它们是否能够通过新的 VXLAN 端口号进行通信。</p></li><li><p><strong>检查 Calico Pod 和 DaemonSet 的状态</strong></p><p>确认所有 <code>calico-node</code> DaemonSet Pods 正常运行：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get pods -n kube-system -l k8s-app<span style=color:#f92672>=</span>calico-node
</span></span></code></pre></div><p>检查是否有任何错误或挂起的 Pod。</p></li><li><p><strong>检查 Calico 日志</strong></p><p>查看 Calico 的日志，以确认是否有任何与 VXLAN 配置或端口号相关的错误：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl logs -n kube-system &lt;calico-node-pod-name&gt;
</span></span></code></pre></div></li></ol><h3 id=总结-2>总结
<a class=anchor href=#%e6%80%bb%e7%bb%93-2>#</a></h3><ol><li>修改 Calico 的 VXLAN 默认端口号，你需要更新 <strong>FelixConfiguration</strong> 配置文件中的 <code>vxlanPort</code> 参数，指定新的端口号。</li><li>更新后，重新启动 Calico 节点（<code>calico-node</code> DaemonSet），并确保网络路由和防火墙规则允许通过新的端口号进行通信。</li><li>验证配置是否生效，并检查跨网段的 Pod 是否能够互相访问。</li></ol><p>通过这些步骤，你就可以将 Calico 的 VXLAN 端口号修改为新的端口，并解决跨网段通信的问题。</p><h2 id=envoy的版本过低导致流量被拦截升级版本解决了>envoy的版本过低导致流量被拦截，升级版本解决了
<a class=anchor href=#envoy%e7%9a%84%e7%89%88%e6%9c%ac%e8%bf%87%e4%bd%8e%e5%af%bc%e8%87%b4%e6%b5%81%e9%87%8f%e8%a2%ab%e6%8b%a6%e6%88%aa%e5%8d%87%e7%ba%a7%e7%89%88%e6%9c%ac%e8%a7%a3%e5%86%b3%e4%ba%86>#</a></h2><p>如果 <strong>Envoy</strong> 版本过低导致流量被拦截的问题，通过升级 Envoy 版本解决了问题，这通常是由于以下几种原因：</p><h3 id=1-过时的协议支持>1. <strong>过时的协议支持</strong>
<a class=anchor href=#1-%e8%bf%87%e6%97%b6%e7%9a%84%e5%8d%8f%e8%ae%ae%e6%94%af%e6%8c%81>#</a></h3><p>较低版本的 Envoy 可能不支持某些新协议或特性，比如新的 <strong>HTTP/2</strong>、<strong>gRPC</strong> 或 <strong>mTLS</strong> 配置等。这可能会导致流量被拦截，无法正确路由或处理。</p><h3 id=2-安全性问题>2. <strong>安全性问题</strong>
<a class=anchor href=#2-%e5%ae%89%e5%85%a8%e6%80%a7%e9%97%ae%e9%a2%98>#</a></h3><p>较低版本的 Envoy 可能存在已知的安全漏洞，某些流量被拦截可能是因为旧版本存在某些未修复的缺陷。在安全修复后，升级到较新的版本可以避免这些问题。</p><h3 id=3-代理和路由问题>3. <strong>代理和路由问题</strong>
<a class=anchor href=#3-%e4%bb%a3%e7%90%86%e5%92%8c%e8%b7%af%e7%94%b1%e9%97%ae%e9%a2%98>#</a></h3><p>在较低版本中，Envoy 可能存在一些 bug 或不兼容的配置，导致流量未能正确路由或通过代理。升级到新版后，Envoy 中的路由、流量管理等功能会得到改进，从而解决了流量拦截的问题。</p><h3 id=4-性能优化和-bug-修复>4. <strong>性能优化和 bug 修复</strong>
<a class=anchor href=#4-%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96%e5%92%8c-bug-%e4%bf%ae%e5%a4%8d>#</a></h3><p>新版 Envoy 通常会包括性能优化和 bug 修复，这些优化不仅能提高流量处理能力，还能避免由于版本限制导致的流量拦截或不正常路由。</p><hr><h3 id=如何升级-envoy>如何升级 Envoy
<a class=anchor href=#%e5%a6%82%e4%bd%95%e5%8d%87%e7%ba%a7-envoy>#</a></h3><p>如果你已经解决了这个问题，下面是一般的 <strong>Envoy 升级流程</strong>，以防你以后遇到类似的情况：</p><h4 id=1-检查当前-envoy-版本>1. <strong>检查当前 Envoy 版本</strong>
<a class=anchor href=#1-%e6%a3%80%e6%9f%a5%e5%bd%93%e5%89%8d-envoy-%e7%89%88%e6%9c%ac>#</a></h4><p>你可以通过以下命令检查当前安装的 Envoy 版本：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>envoy --version
</span></span></code></pre></div><h4 id=2-安装或升级到最新版本>2. <strong>安装或升级到最新版本</strong>
<a class=anchor href=#2-%e5%ae%89%e8%a3%85%e6%88%96%e5%8d%87%e7%ba%a7%e5%88%b0%e6%9c%80%e6%96%b0%e7%89%88%e6%9c%ac>#</a></h4><p>根据你使用的操作系统和安装方式，选择适合的升级方法：</p><ul><li><p><strong>使用官方 APT 仓库（Ubuntu/Debian）</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>curl -sL https://getenvoy.io | sudo bash
</span></span><span style=display:flex><span>sudo apt-get install envoy
</span></span></code></pre></div></li><li><p><strong>使用 Homebrew（macOS）</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>brew install envoy
</span></span></code></pre></div></li><li><p><strong>使用 Docker（容器环境）</strong>：</p><p>如果你使用容器运行 Envoy，可以更新 Docker 镜像：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>docker pull envoyproxy/envoy:v1.24.0  <span style=color:#75715e># 替换为所需的版本</span>
</span></span></code></pre></div></li><li><p><strong>手动下载并安装</strong>：</p><p>你可以从 <a href=https://github.com/envoyproxy/envoy/releases>Envoy 的 GitHub releases 页面</a> 下载适合你平台的最新版本，并手动安装。</p></li></ul><h4 id=3-验证升级后的版本>3. <strong>验证升级后的版本</strong>
<a class=anchor href=#3-%e9%aa%8c%e8%af%81%e5%8d%87%e7%ba%a7%e5%90%8e%e7%9a%84%e7%89%88%e6%9c%ac>#</a></h4><p>升级完成后，确认 Envoy 已经成功升级到新版本：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>envoy --version
</span></span></code></pre></div><h4 id=4-检查配置和功能>4. <strong>检查配置和功能</strong>
<a class=anchor href=#4-%e6%a3%80%e6%9f%a5%e9%85%8d%e7%bd%ae%e5%92%8c%e5%8a%9f%e8%83%bd>#</a></h4><p>确保你的配置（如 <strong>xDS</strong>、<strong>路由配置</strong>、<strong>安全证书配置</strong> 等）兼容新版本的 Envoy。你可能需要检查日志以确认升级后的 Envoy 是否正确加载了新的配置。</p><h3 id=总结-3>总结
<a class=anchor href=#%e6%80%bb%e7%bb%93-3>#</a></h3><p><strong>Envoy 版本过低</strong>通常会导致一些流量问题，升级后不仅能解决这些问题，还能享受更好的安全性、性能和协议支持。通过正确的升级步骤，你可以确保 Envoy 为集群提供最佳的流量管理和代理服务。如果你还需要进行其它配置修改或性能优化，记得检查新版本的发布说明和文档。</p><h2 id=节点noteready-恢复>节点noteready 恢复
<a class=anchor href=#%e8%8a%82%e7%82%b9noteready-%e6%81%a2%e5%a4%8d>#</a></h2><p>当 Kubernetes 节点状态变为 <strong>NotReady</strong> 时，表示该节点未能正常加入集群或者与集群的控制平面失去联系。通常，节点的 <code>NotReady</code> 状态可能由以下几种原因引起：网络问题、节点资源不足、Kubelet 配置问题、系统组件未正常运行等。</p><p>以下是一些常见的故障排查和恢复步骤，帮助你将节点恢复到 <strong>Ready</strong> 状态：</p><h3 id=1-查看节点状态>1. <strong>查看节点状态</strong>
<a class=anchor href=#1-%e6%9f%a5%e7%9c%8b%e8%8a%82%e7%82%b9%e7%8a%b6%e6%80%81>#</a></h3><p>首先，你可以使用 <code>kubectl</code> 命令查看节点状态及相关的事件：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get nodes
</span></span></code></pre></div><p>查看详细信息：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl describe node &lt;node-name&gt;
</span></span></code></pre></div><p>输出中会显示有关节点的详细信息，包括 <code>NotReady</code> 的原因和事件日志，这将帮助你定位问题的根源。</p><h3 id=2-检查-kubelet-状态>2. <strong>检查 Kubelet 状态</strong>
<a class=anchor href=#2-%e6%a3%80%e6%9f%a5-kubelet-%e7%8a%b6%e6%80%81>#</a></h3><p>Kubelet 是运行在每个节点上的组件，负责与控制平面通信并管理容器。如果 Kubelet 出现问题，节点会处于 <code>NotReady</code> 状态。</p><ul><li><p><strong>检查 Kubelet 状态</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>systemctl status kubelet
</span></span></code></pre></div></li><li><p><strong>查看 Kubelet 日志</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>journalctl -u kubelet -f
</span></span></code></pre></div></li></ul><p>如果 Kubelet 没有正常运行，可以尝试重新启动：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>systemctl restart kubelet
</span></span></code></pre></div><h3 id=3-检查网络配置>3. <strong>检查网络配置</strong>
<a class=anchor href=#3-%e6%a3%80%e6%9f%a5%e7%bd%91%e7%bb%9c%e9%85%8d%e7%bd%ae>#</a></h3><p>网络问题可能导致节点无法与其他节点或控制平面通信。检查以下内容：</p><ul><li><strong>防火墙规则</strong>：确保节点间的必要端口（如 6443、2379、2380、10250、10255）没有被阻塞。</li><li><strong>网络插件</strong>：如果你使用了网络插件（如 Calico、Weave），确保它们的配置正确，并且插件运行正常。</li></ul><p>查看网络插件的日志，确认它是否在正常工作：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl logs -n kube-system &lt;network-plugin-pod-name&gt;
</span></span></code></pre></div><h3 id=4-资源使用情况>4. <strong>资源使用情况</strong>
<a class=anchor href=#4-%e8%b5%84%e6%ba%90%e4%bd%bf%e7%94%a8%e6%83%85%e5%86%b5>#</a></h3><p>节点可能由于资源不足（如 CPU、内存、磁盘等）而变为 <code>NotReady</code>。</p><ul><li><p><strong>检查节点的资源使用情况</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>top node &lt;node-name&gt;
</span></span></code></pre></div></li><li><p><strong>检查磁盘空间</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>df -h
</span></span></code></pre></div></li><li><p><strong>查看系统负载</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>uptime
</span></span></code></pre></div></li></ul><p>如果发现资源过载，考虑扩展节点资源或优化资源使用。</p><h3 id=5-检查-api-server-与节点连接>5. <strong>检查 API Server 与节点连接</strong>
<a class=anchor href=#5-%e6%a3%80%e6%9f%a5-api-server-%e4%b8%8e%e8%8a%82%e7%82%b9%e8%bf%9e%e6%8e%a5>#</a></h3><p>如果节点无法与控制平面（API Server）通信，节点将显示为 <code>NotReady</code>。检查以下内容：</p><ul><li><p><strong>API Server 是否正常运行</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get pods -n kube-system -l component<span style=color:#f92672>=</span>kube-apiserver
</span></span></code></pre></div></li><li><p><strong>节点到 API Server 的连接状态</strong>： 你可以尝试使用 <code>curl</code> 或 <code>telnet</code> 测试节点与控制平面之间的连接。</p></li></ul><h3 id=6-重新加入节点到集群>6. <strong>重新加入节点到集群</strong>
<a class=anchor href=#6-%e9%87%8d%e6%96%b0%e5%8a%a0%e5%85%a5%e8%8a%82%e7%82%b9%e5%88%b0%e9%9b%86%e7%be%a4>#</a></h3><p>如果节点的状态长时间为 <code>NotReady</code>，并且没有明显的错误，尝试将节点从集群中移除并重新加入：</p><ol><li><p>从集群中驱逐节点：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl drain &lt;node-name&gt; --ignore-daemonsets --delete-local-data
</span></span></code></pre></div></li><li><p>从集群中删除节点：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl delete node &lt;node-name&gt;
</span></span></code></pre></div></li><li><p>重新将节点加入集群： 如果节点是通过 <code>kubeadm</code> 安装的，使用之前的 <code>kubeadm join</code> 命令将节点重新加入集群。</p></li></ol><h3 id=7-检查-kubelet-配置文件>7. <strong>检查 Kubelet 配置文件</strong>
<a class=anchor href=#7-%e6%a3%80%e6%9f%a5-kubelet-%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6>#</a></h3><p>Kubelet 配置文件（通常在 <code>/etc/kubernetes/kubelet.conf</code> 或 <code>/etc/kubernetes/manifests</code>）可能存在配置问题，导致无法正常启动。检查配置是否正确，尤其是 API Server 地址和证书配置。</p><h3 id=8-节点恢复后的验证>8. <strong>节点恢复后的验证</strong>
<a class=anchor href=#8-%e8%8a%82%e7%82%b9%e6%81%a2%e5%a4%8d%e5%90%8e%e7%9a%84%e9%aa%8c%e8%af%81>#</a></h3><p>恢复节点后，验证节点是否已经恢复为 <strong>Ready</strong> 状态：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get nodes
</span></span></code></pre></div><p>确认节点的状态是否变为 <code>Ready</code>。如果恢复成功，可以重新调度 Pod。</p><h3 id=总结-4>总结
<a class=anchor href=#%e6%80%bb%e7%bb%93-4>#</a></h3><p>当节点处于 <strong>NotReady</strong> 状态时，排查和修复的步骤通常包括检查 Kubelet 状态、网络配置、资源使用情况以及控制平面与节点的连接。通过这些步骤，通常能够找到问题并恢复节点。如果无法解决，重新加入节点到集群也是一种有效的恢复方式。</p><h2 id=数据库磁盘使用超过85导致数据库只读>数据库磁盘使用超过85%导致数据库只读
<a class=anchor href=#%e6%95%b0%e6%8d%ae%e5%ba%93%e7%a3%81%e7%9b%98%e4%bd%bf%e7%94%a8%e8%b6%85%e8%bf%8785%e5%af%bc%e8%87%b4%e6%95%b0%e6%8d%ae%e5%ba%93%e5%8f%aa%e8%af%bb>#</a></h2><p>当数据库磁盘使用超过 85% 时，许多数据库管理系统（如 MySQL、PostgreSQL、Oracle 等）会进入只读模式，防止数据丢失或进一步的磁盘满载。这是一种保护机制，旨在避免在磁盘空间耗尽时对数据库的操作产生不可预知的影响。</p><h3 id=解决方案>解决方案
<a class=anchor href=#%e8%a7%a3%e5%86%b3%e6%96%b9%e6%a1%88>#</a></h3><h4 id=1-清理磁盘空间>1. <strong>清理磁盘空间</strong>
<a class=anchor href=#1-%e6%b8%85%e7%90%86%e7%a3%81%e7%9b%98%e7%a9%ba%e9%97%b4>#</a></h4><p>首先，必须立即清理磁盘空间，以便数据库恢复写入操作。以下是一些常见的清理方法：</p><ul><li><p><strong>删除不必要的日志文件</strong>： 数据库通常会生成大量的日志文件，包括错误日志、查询日志、慢查询日志等。查看并删除不再需要的日志文件。</p><p>对于 MySQL，可以查看日志目录并删除旧日志：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ls /var/log/mysql/
</span></span><span style=display:flex><span>sudo rm /var/log/mysql/mysql-slow.log
</span></span><span style=display:flex><span>sudo rm /var/log/mysql/error.log.*
</span></span></code></pre></div><p>对于 PostgreSQL，查看日志并删除：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ls /var/log/postgresql/
</span></span><span style=display:flex><span>sudo rm /var/log/postgresql/postgresql.log.*
</span></span></code></pre></div></li><li><p><strong>清理数据库表中的临时数据</strong>：</p><ul><li><p>检查数据库中是否有临时表、过期数据或无用数据表，删除不必要的数据。</p></li><li><p>对于 MySQL，执行：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>DELETE</span> <span style=color:#66d9ef>FROM</span> <span style=color:#f92672>&lt;</span><span style=color:#66d9ef>table_name</span><span style=color:#f92672>&gt;</span> <span style=color:#66d9ef>WHERE</span> <span style=color:#f92672>&lt;</span>condition<span style=color:#f92672>&gt;</span>;
</span></span></code></pre></div></li></ul></li><li><p><strong>删除或压缩备份文件</strong>： 数据库备份文件往往占用大量空间。检查并删除旧的或不需要的备份文件，或者将它们转移到其他存储位置。</p></li><li><p><strong>检查磁盘使用情况</strong>： 使用 <code>du</code> 或 <code>df</code> 命令检查具体哪些目录或文件占用最多的磁盘空间：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>du -sh /var/lib/mysql  <span style=color:#75715e># 对于 MySQL</span>
</span></span><span style=display:flex><span>df -h  <span style=color:#75715e># 检查整个磁盘的使用情况</span>
</span></span></code></pre></div></li></ul><h4 id=2-扩大磁盘空间>2. <strong>扩大磁盘空间</strong>
<a class=anchor href=#2-%e6%89%a9%e5%a4%a7%e7%a3%81%e7%9b%98%e7%a9%ba%e9%97%b4>#</a></h4><p>如果清理后仍然无法解决问题，你可能需要为数据库服务器增加磁盘空间：</p><ul><li><strong>扩展现有磁盘</strong>：通过云平台或者物理机器管理工具增加磁盘空间。</li><li><strong>挂载额外的磁盘</strong>：如果有多余的磁盘，可以将它挂载到数据库目录，并调整数据库配置使用新的磁盘空间。</li></ul><h4 id=3-检查数据库表的大小和碎片>3. <strong>检查数据库表的大小和碎片</strong>
<a class=anchor href=#3-%e6%a3%80%e6%9f%a5%e6%95%b0%e6%8d%ae%e5%ba%93%e8%a1%a8%e7%9a%84%e5%a4%a7%e5%b0%8f%e5%92%8c%e7%a2%8e%e7%89%87>#</a></h4><p>数据库表和索引的过度膨胀可能导致磁盘空间的异常消耗。你可以通过以下方式进行优化：</p><ul><li><p><strong>优化数据库表（MySQL）</strong>： 执行 <code>OPTIMIZE TABLE</code> 来优化表，释放碎片：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span>OPTIMIZE <span style=color:#66d9ef>TABLE</span> <span style=color:#f92672>&lt;</span><span style=color:#66d9ef>table_name</span><span style=color:#f92672>&gt;</span>;
</span></span></code></pre></div></li><li><p><strong>对于 PostgreSQL，使用 <code>VACUUM</code> 清理无效空间</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>VACUUM</span> <span style=color:#66d9ef>FULL</span>;
</span></span></code></pre></div></li></ul><h4 id=4-恢复数据库写入权限>4. <strong>恢复数据库写入权限</strong>
<a class=anchor href=#4-%e6%81%a2%e5%a4%8d%e6%95%b0%e6%8d%ae%e5%ba%93%e5%86%99%e5%85%a5%e6%9d%83%e9%99%90>#</a></h4><p>一旦磁盘空间恢复并且足够使用，数据库应该自动恢复写入权限。如果没有恢复，可以手动执行以下操作：</p><ul><li><p><strong>MySQL</strong>： 检查数据库是否仍在只读模式：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SHOW</span> VARIABLES <span style=color:#66d9ef>LIKE</span> <span style=color:#e6db74>&#39;read_only&#39;</span>;
</span></span></code></pre></div><p>如果显示为 <code>ON</code>，则可以执行以下命令恢复写入权限：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SET</span> <span style=color:#66d9ef>GLOBAL</span> read_only <span style=color:#f92672>=</span> <span style=color:#66d9ef>OFF</span>;
</span></span></code></pre></div></li><li><p><strong>PostgreSQL</strong>： PostgreSQL 通常通过设置 <code>default_transaction_read_only</code> 进入只读模式。检查并修改：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SHOW</span> default_transaction_read_only;
</span></span><span style=display:flex><span><span style=color:#66d9ef>SET</span> default_transaction_read_only <span style=color:#f92672>=</span> <span style=color:#66d9ef>off</span>;
</span></span></code></pre></div></li></ul><h4 id=5-配置磁盘监控和告警>5. <strong>配置磁盘监控和告警</strong>
<a class=anchor href=#5-%e9%85%8d%e7%bd%ae%e7%a3%81%e7%9b%98%e7%9b%91%e6%8e%a7%e5%92%8c%e5%91%8a%e8%ad%a6>#</a></h4><p>为了避免磁盘空间再次用尽，配置磁盘监控和告警非常重要。你可以设置如下的监控措施：</p><ul><li><p>使用 <strong>Prometheus</strong> + <strong>Grafana</strong> 来监控磁盘使用情况，并设置告警规则。</p></li><li><p>配置操作系统的</p><pre tabindex=0><code>cron
</code></pre><p>定期检查磁盘使用情况，并在达到阈值时发送告警邮件：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>df -h | awk <span style=color:#e6db74>&#39;$5 &gt; 85 {print $0}&#39;</span> | mail -s <span style=color:#e6db74>&#34;Disk Usage Alert&#34;</span> admin@example.com
</span></span></code></pre></div></li></ul><h4 id=总结-5>总结
<a class=anchor href=#%e6%80%bb%e7%bb%93-5>#</a></h4><p>当数据库磁盘使用超过 85% 时，通常会进入只读模式以保护数据的完整性。解决此问题的步骤包括清理磁盘空间、扩大磁盘容量、优化数据库表和恢复数据库写入权限。同时，建立磁盘监控和告警机制，能够帮助预防类似问题的再次发生。</p><h2 id=prometheus指标拆分解决oom的问题>prometheus指标拆分解决oom的问题
<a class=anchor href=#prometheus%e6%8c%87%e6%a0%87%e6%8b%86%e5%88%86%e8%a7%a3%e5%86%b3oom%e7%9a%84%e9%97%ae%e9%a2%98>#</a></h2><p>当 Prometheus 遇到 OOM（Out of Memory）问题时，通常是因为某些指标（例如某些高频率采集的指标、某些非常大的指标数据）占用了过多的内存。为了避免这种情况，可以采取以下几种方法来拆分指标、优化 Prometheus 的内存使用。</p><h3 id=1-拆分大型指标>1. <strong>拆分大型指标</strong>
<a class=anchor href=#1-%e6%8b%86%e5%88%86%e5%a4%a7%e5%9e%8b%e6%8c%87%e6%a0%87>#</a></h3><p>某些指标可能包含大量的数据点，尤其是高卡特利性（high cardinality）指标。这类指标会占用大量内存。以下是拆分指标的方法：</p><ul><li><p><strong>减少高卡特利性指标的采集频率</strong>： 如果某个指标具有大量的不同标签值（例如每个请求的响应时间），你可以考虑减少采集频率，或者限制某些标签的组合。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>scrape_configs</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>job_name</span>: <span style=color:#e6db74>&#39;my_job&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>scrape_interval</span>: <span style=color:#ae81ff>10s  </span> <span style=color:#75715e># 降低采集频率</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>relabel_configs</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>source_labels</span>: [<span style=color:#ae81ff>__name__]</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>target_label</span>: <span style=color:#ae81ff>job</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>replacement</span>: <span style=color:#ae81ff>my_job</span>
</span></span></code></pre></div></li><li><p><strong>过滤不必要的标签</strong>： 对于一些指标，可以通过 <strong>relabeling</strong> 过滤掉不必要的标签。高卡特利性通常是由标签组合导致的，可以通过减少某些标签的数量来减小内存消耗。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>scrape_configs</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>job_name</span>: <span style=color:#e6db74>&#39;my_job&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>static_configs</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>targets</span>: [<span style=color:#e6db74>&#39;localhost:9090&#39;</span>]
</span></span><span style=display:flex><span>    <span style=color:#f92672>relabel_configs</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>source_labels</span>: [<span style=color:#ae81ff>__name__]</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>target_label</span>: <span style=color:#ae81ff>job</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>replacement</span>: <span style=color:#ae81ff>my_job</span>
</span></span><span style=display:flex><span>      - <span style=color:#f92672>source_labels</span>: [<span style=color:#ae81ff>some_label]</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>target_label</span>: <span style=color:#ae81ff>some_label</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>action</span>: <span style=color:#ae81ff>drop </span> <span style=color:#75715e># 丢弃不需要的标签</span>
</span></span></code></pre></div></li><li><p><strong>拆分大指标为多个小指标</strong>： 对于一些指标，如果它们的维度较高，可以考虑拆分为多个指标，而不是一个大指标。例如，将 <code>http_requests_total</code> 按路径或方法拆分成多个指标。</p></li></ul><h3 id=2-限制-prometheus-存储使用>2. <strong>限制 Prometheus 存储使用</strong>
<a class=anchor href=#2-%e9%99%90%e5%88%b6-prometheus-%e5%ad%98%e5%82%a8%e4%bd%bf%e7%94%a8>#</a></h3><p>Prometheus 会将指标数据存储在本地磁盘上。如果存储量过大，Prometheus 可能会消耗过多内存。通过配置 <code>retention</code> 和 <code>max_age</code> 限制存储的时间，可以减少 Prometheus 占用的内存。</p><ul><li><p><strong>配置数据保留时间</strong>： 你可以通过调整 <code>--storage.tsdb.retention.time</code> 来限制存储数据的时长。默认情况下，Prometheus 会保留最近的 15 天的数据，但你可以根据需要调整为较短的时间。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>prometheus --storage.tsdb.retention.time<span style=color:#f92672>=</span>7d  <span style=color:#75715e># 保留 7 天的数据</span>
</span></span></code></pre></div></li><li><p><strong>调整存储块大小</strong>： Prometheus 使用存储块来管理数据的写入。调整 <code>--storage.tsdb.min-block-duration</code> 和 <code>--storage.tsdb.max-block-duration</code> 参数可以影响内存的使用。增加存储块的大小，可能会增加 Prometheus 的内存占用。</p></li></ul><h3 id=3-调整指标采集频率>3. <strong>调整指标采集频率</strong>
<a class=anchor href=#3-%e8%b0%83%e6%95%b4%e6%8c%87%e6%a0%87%e9%87%87%e9%9b%86%e9%a2%91%e7%8e%87>#</a></h3><ul><li><p><strong>减少采集频率</strong>： 默认的 <code>scrape_interval</code> 是 15 秒，你可以根据需求调整为更长的时间，减少采集频率，从而减少 Prometheus 的内存使用。例如，将采集间隔从 15 秒调整为 30 秒：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>scrape_configs</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>job_name</span>: <span style=color:#e6db74>&#39;my_job&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>scrape_interval</span>: <span style=color:#ae81ff>30s </span> <span style=color:#75715e># 将采集间隔调整为 30 秒</span>
</span></span></code></pre></div><p>这可以减少 Prometheus 存储的数据量，避免因采集过于频繁而导致 OOM。</p></li></ul><h3 id=4-分布式-prometheus-部署sharding>4. <strong>分布式 Prometheus 部署（Sharding）</strong>
<a class=anchor href=#4-%e5%88%86%e5%b8%83%e5%bc%8f-prometheus-%e9%83%a8%e7%bd%b2sharding>#</a></h3><ul><li><p><strong>使用多个 Prometheus 实例</strong>： 你可以将数据划分为多个 Prometheus 实例（Sharding）。每个 Prometheus 实例负责采集特定的指标或目标，然后使用 <strong>Prometheus Federation</strong> 将它们集中到一个主 Prometheus 实例进行查询。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>scrape_configs</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>job_name</span>: <span style=color:#e6db74>&#39;prometheus&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>static_configs</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>targets</span>: [<span style=color:#e6db74>&#39;prometheus-instance1:9090&#39;</span>]
</span></span><span style=display:flex><span>  - <span style=color:#f92672>job_name</span>: <span style=color:#e6db74>&#39;prometheus&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>static_configs</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>targets</span>: [<span style=color:#e6db74>&#39;prometheus-instance2:9090&#39;</span>]
</span></span></code></pre></div><p>通过这种方式，每个 Prometheus 实例只需要处理部分指标，从而减少内存负担。</p></li></ul><h3 id=5-优化查询>5. <strong>优化查询</strong>
<a class=anchor href=#5-%e4%bc%98%e5%8c%96%e6%9f%a5%e8%af%a2>#</a></h3><p>某些复杂的 Prometheus 查询可能会消耗大量内存。优化查询，避免过于复杂的计算，可以减少内存消耗。</p><ul><li><strong>避免高卡特利性查询</strong>：对于查询时需要使用大量标签值的指标，要避免在查询中进行复杂的聚合或过滤。</li><li><strong>使用采样数据</strong>：对一些大数据集，可以使用采样来减少查询时的数据量。比如，使用 <code>rate()</code> 函数时，可以考虑使用较短的时间窗口，减少计算的数据量。</li></ul><h3 id=6-使用外部存储远程存储>6. <strong>使用外部存储（远程存储）</strong>
<a class=anchor href=#6-%e4%bd%bf%e7%94%a8%e5%a4%96%e9%83%a8%e5%ad%98%e5%82%a8%e8%bf%9c%e7%a8%8b%e5%ad%98%e5%82%a8>#</a></h3><p>如果本地存储的容量无法满足需求，可以考虑将数据导出到远程存储系统（如 <strong>Cortex</strong>、<strong>Thanos</strong> 或 <strong>Mimir</strong>），以便进行更大规模的存储和查询。</p><ul><li><p><strong>配置远程存储</strong>： Prometheus 支持将数据写入外部存储系统，如 <strong>Cortex</strong> 或 <strong>Thanos</strong>，这样可以将较老的数据存储在远程系统中，减轻 Prometheus 节点的存储压力。</p><p>配置示例：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>remote_write</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>url</span>: <span style=color:#e6db74>&#34;http://&lt;remote-storage-url&gt;/write&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>remote_read</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>url</span>: <span style=color:#e6db74>&#34;http://&lt;remote-storage-url&gt;/read&#34;</span>
</span></span></code></pre></div></li></ul><h3 id=总结-6>总结
<a class=anchor href=#%e6%80%bb%e7%bb%93-6>#</a></h3><p>为了解决 Prometheus 的 OOM 问题，可以通过以下几种方式优化：</p><ol><li><strong>拆分大型高卡特利性指标</strong>，减少标签的数量或采集频率。</li><li><strong>限制存储使用</strong>，通过调整数据保留时间来减少内存占用。</li><li><strong>减少采集频率</strong>，优化 Prometheus 配置。</li><li><strong>使用分布式 Prometheus 部署</strong>，将数据分散到多个实例中。</li><li><strong>优化查询</strong>，避免高内存消耗的查询。</li><li><strong>使用外部存储</strong>，将数据存储到远程系统中。</li></ol><p>通过这些方法，可以有效减少 Prometheus 的内存消耗，避免 OOM 问题的发生。</p><h2 id=prometheus的告警延迟问题>prometheus的告警延迟问题
<a class=anchor href=#prometheus%e7%9a%84%e5%91%8a%e8%ad%a6%e5%bb%b6%e8%bf%9f%e9%97%ae%e9%a2%98>#</a></h2><p>Prometheus 的告警延迟问题通常发生在告警规则触发后，Prometheus 需要一定时间才能检测到指标变化、计算规则并发出通知。造成告警延迟的原因可能有多个，以下是一些常见的原因以及相应的解决方法：</p><h3 id=1-告警规则的评估间隔>1. <strong>告警规则的评估间隔</strong>
<a class=anchor href=#1-%e5%91%8a%e8%ad%a6%e8%a7%84%e5%88%99%e7%9a%84%e8%af%84%e4%bc%b0%e9%97%b4%e9%9a%94>#</a></h3><p>Prometheus 的告警规则是基于 <code>evaluation_interval</code>（评估间隔）来周期性评估的。如果评估间隔设置过长，告警会延迟触发。</p><ul><li><p><strong>解决方法</strong>： 默认的评估间隔通常是 1 分钟，但如果你的环境需要更快的告警响应，可以考虑缩短评估间隔。</p><p>在 <code>prometheus.yml</code> 配置文件中，修改 <code>evaluation_interval</code>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>global</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>scrape_interval</span>: <span style=color:#ae81ff>15s </span> <span style=color:#75715e># 采集间隔</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>evaluation_interval</span>: <span style=color:#ae81ff>30s </span> <span style=color:#75715e># 告警规则评估间隔</span>
</span></span></code></pre></div><p>注意：缩短评估间隔可能会增加 Prometheus 的负载，因此需要平衡性能和告警响应的需求。</p></li></ul><h3 id=2-告警规则的评估条件过于宽松>2. <strong>告警规则的评估条件过于宽松</strong>
<a class=anchor href=#2-%e5%91%8a%e8%ad%a6%e8%a7%84%e5%88%99%e7%9a%84%e8%af%84%e4%bc%b0%e6%9d%a1%e4%bb%b6%e8%bf%87%e4%ba%8e%e5%ae%bd%e6%9d%be>#</a></h3><p>告警规则中可能存在宽松的条件，导致 Prometheus 需要更长时间才能触发告警。例如，使用 <code>avg</code> 或 <code>rate</code> 聚合函数时，如果数据波动较小，可能会导致告警判断延迟。</p><ul><li><p><strong>解决方法</strong>： 确保告警规则的条件尽量精确，避免使用过于模糊的聚合函数或过长的时间窗口。例如，避免使用过大的 <code>rate</code> 时间窗口，或者缩短 <code>for</code> 参数的值。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>groups</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>example-alerts</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>rules</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>alert</span>: <span style=color:#ae81ff>HighCPUUsage</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>expr</span>: <span style=color:#ae81ff>rate(cpu_usage_seconds_total[5m]) &gt; 0.9</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>for</span>: <span style=color:#ae81ff>1m </span> <span style=color:#75715e># 告警至少持续1分钟</span>
</span></span></code></pre></div></li></ul><h3 id=3-prometheus-数据采集频率>3. <strong>Prometheus 数据采集频率</strong>
<a class=anchor href=#3-prometheus-%e6%95%b0%e6%8d%ae%e9%87%87%e9%9b%86%e9%a2%91%e7%8e%87>#</a></h3><p>Prometheus 从各个监控目标上采集数据时，采集的频率也会影响告警的响应时间。如果采集间隔过长，数据更新的频率就会降低，从而导致告警响应的延迟。</p><ul><li><p><strong>解决方法</strong>： 通过 <code>scrape_interval</code> 配置调整数据采集的频率。通常来说，采集间隔越短，数据更新越频繁，告警响应速度越快。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>global</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>scrape_interval</span>: <span style=color:#ae81ff>15s </span> <span style=color:#75715e># 数据采集间隔</span>
</span></span></code></pre></div><p>但需要注意，频繁的数据采集可能会增加 Prometheus 的负载，影响性能，因此应根据实际情况调整。</p></li></ul><h3 id=4-alertmanager-配置问题>4. <strong>Alertmanager 配置问题</strong>
<a class=anchor href=#4-alertmanager-%e9%85%8d%e7%bd%ae%e9%97%ae%e9%a2%98>#</a></h3><p>Alertmanager 是 Prometheus 的告警处理组件。如果 Alertmanager 配置有问题，可能会导致告警的通知延迟。常见的延迟原因包括网络问题、Alertmanager 配置不当或并发负载过高。</p><ul><li><p><strong>解决方法</strong>：</p><ul><li>检查 Alertmanager 的配置，确保通知规则配置正确。</li><li>确保 Alertmanager 的实例健康，并且能快速处理告警请求。</li><li>增加 Alertmanager 的副本数，以提高处理性能。</li><li>监控 Alertmanager 本身的性能，确保它不会成为瓶颈。</li></ul><p>配置示例：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>route</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>receiver</span>: <span style=color:#e6db74>&#39;email-notifications&#39;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>group_by</span>: [<span style=color:#e6db74>&#39;alertname&#39;</span>]
</span></span><span style=display:flex><span>  <span style=color:#f92672>group_wait</span>: <span style=color:#ae81ff>30s </span> <span style=color:#75715e># 等待30秒合并告警</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>group_interval</span>: <span style=color:#ae81ff>1m </span> <span style=color:#75715e># 合并告警的间隔时间</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>repeat_interval</span>: <span style=color:#ae81ff>1h </span> <span style=color:#75715e># 重复告警的时间间隔</span>
</span></span></code></pre></div></li></ul><h3 id=5-prometheus-存储问题>5. <strong>Prometheus 存储问题</strong>
<a class=anchor href=#5-prometheus-%e5%ad%98%e5%82%a8%e9%97%ae%e9%a2%98>#</a></h3><p>如果 Prometheus 的存储系统存在性能瓶颈（例如磁盘 IO 过载、存储容量不足等），这可能会导致告警规则评估时延迟数据访问，从而增加告警延迟。</p><ul><li><p>解决方法</p><p>：</p><ul><li>确保 Prometheus 存储系统有足够的资源（磁盘、内存、网络等）。</li><li>调整 Prometheus 的存储配置，如使用更快的磁盘、调整 TSDB（时间序列数据库）的存储参数等。</li></ul></li></ul><h3 id=6-复杂的-prometheus-查询>6. <strong>复杂的 Prometheus 查询</strong>
<a class=anchor href=#6-%e5%a4%8d%e6%9d%82%e7%9a%84-prometheus-%e6%9f%a5%e8%af%a2>#</a></h3><p>告警规则中可能使用了复杂的 Prometheus 查询，例如高卡特利性指标的聚合、多个 <code>join</code> 操作等。这些复杂的查询可能会导致 Prometheus 的查询延迟，进而影响告警的响应时间。</p><ul><li><p><strong>解决方法</strong>： 优化 Prometheus 查询，避免使用过于复杂的查询条件，或者使用 <code>rate</code> 或 <code>avg</code> 之类的函数时，尽量减小时间范围。</p><p>示例：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>expr</span>: <span style=color:#ae81ff>avg(rate(cpu_usage_seconds_total{instance=&#34;localhost&#34;}[1m])) &gt; 0.8</span>
</span></span></code></pre></div><p>确保查询尽可能高效，避免不必要的计算。</p></li></ul><h3 id=7-网络延迟或-dns-解析问题>7. <strong>网络延迟或 DNS 解析问题</strong>
<a class=anchor href=#7-%e7%bd%91%e7%bb%9c%e5%bb%b6%e8%bf%9f%e6%88%96-dns-%e8%a7%a3%e6%9e%90%e9%97%ae%e9%a2%98>#</a></h3><p>告警从 Prometheus 发送到 Alertmanager，或者 Alertmanager 发送通知到外部系统（如电子邮件、Slack）时，可能会遇到网络延迟或 DNS 解析问题，导致告警的通知延迟。</p><ul><li><p>解决方法</p><p>：</p><ul><li>检查 Prometheus 和 Alertmanager 之间的网络连接是否正常。</li><li>确保外部通知系统（如 Slack、PagerDuty 等）的网络连接正常。</li></ul></li></ul><h3 id=8-alertmanager-缓存问题>8. <strong>Alertmanager 缓存问题</strong>
<a class=anchor href=#8-alertmanager-%e7%bc%93%e5%ad%98%e9%97%ae%e9%a2%98>#</a></h3><p>Alertmanager 会缓存已发送的告警信息，如果相同的告警多次触发，可能会出现通知延迟或者重复告警的情况。</p><ul><li><p><strong>解决方法</strong>： 调整 <code>group_interval</code> 和 <code>repeat_interval</code> 参数，避免过多的重复告警。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>route</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>group_interval</span>: <span style=color:#ae81ff>10s </span> <span style=color:#75715e># 在同一告警被发送多次时，最小的时间间隔</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>repeat_interval</span>: <span style=color:#ae81ff>30m </span> <span style=color:#75715e># 重复告警的最小时间间隔</span>
</span></span></code></pre></div></li></ul><h3 id=总结-7>总结
<a class=anchor href=#%e6%80%bb%e7%bb%93-7>#</a></h3><p>Prometheus 告警延迟的问题通常与以下几个方面相关：</p><ol><li><strong>评估间隔和采集频率</strong>：调整 <code>evaluation_interval</code> 和 <code>scrape_interval</code>，以便更频繁地评估和采集数据。</li><li><strong>告警规则优化</strong>：确保告警规则的条件明确且高效，避免使用高卡特利性指标或不必要的复杂查询。</li><li><strong>Alertmanager 配置</strong>：检查和优化 Alertmanager 配置，确保通知的及时发送。</li><li><strong>存储和网络问题</strong>：确保 Prometheus 存储系统和网络正常，避免性能瓶颈。</li></ol><p>通过优化这些方面，你可以有效减少 Prometheus 的告警延迟，提升监控和告警的响应速度。</p><h2 id=告警抑制和收敛>告警抑制和收敛
<a class=anchor href=#%e5%91%8a%e8%ad%a6%e6%8a%91%e5%88%b6%e5%92%8c%e6%94%b6%e6%95%9b>#</a></h2><p>告警抑制和收敛（Alert Suppression and Alert Aggregation）是 Prometheus 和 Alertmanager 中的两个关键概念，用于避免告警通知的泛滥或重复，优化告警系统的处理效率，并减少用户的告警干扰。这两个概念能帮助团队集中注意力在最重要的告警上，防止被大量无关的告警信息淹没。</p><h3 id=1-告警抑制alert-suppression>1. <strong>告警抑制（Alert Suppression）</strong>
<a class=anchor href=#1-%e5%91%8a%e8%ad%a6%e6%8a%91%e5%88%b6alert-suppression>#</a></h3><p>告警抑制是指在某些特定条件下，抑制某些告警的触发或通知。例如，当一个告警触发时，可能有其他相关告警也会触发，但这些告警可能只是副作用，且没有带来新的信息。在这种情况下，告警抑制可以避免发送重复或冗余的告警通知。</p><h4 id=使用场景>使用场景：
<a class=anchor href=#%e4%bd%bf%e7%94%a8%e5%9c%ba%e6%99%af>#</a></h4><ul><li><strong>同一事件的重复告警</strong>：如果某个系统出现故障，可能会触发多个相似的告警。通过告警抑制，可以避免对相同问题产生多次告警通知。</li><li><strong>避免链式告警</strong>：当一个故障引发一系列告警时，可以抑制这些次级告警，直到主告警得到解决为止。</li></ul><h4 id=配置告警抑制>配置告警抑制：
<a class=anchor href=#%e9%85%8d%e7%bd%ae%e5%91%8a%e8%ad%a6%e6%8a%91%e5%88%b6>#</a></h4><p>在 Alertmanager 中，可以使用 <code>group_by</code> 和 <code>group_interval</code> 来进行告警的抑制和分组。</p><ul><li><strong><code>group_by</code></strong>：指定哪些标签应当被用来分组告警。如果多条告警有相同的标签，它们会被视为同一事件的一部分，并在一定时间内进行合并。</li><li><strong><code>group_interval</code></strong>：告警组间的最小通知间隔。如果同一个组中的告警再次触发，它们会在 <code>group_interval</code> 时间内被合并，而不是发送新的告警。</li><li><strong><code>repeat_interval</code></strong>：控制告警在经过指定时间后是否会再次发送。例如，当一个告警已经发送过通知后，直到 <code>repeat_interval</code> 时间过去，再次符合条件时才会再次发送告警。</li></ul><p>配置示例：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>route</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>group_by</span>: [<span style=color:#e6db74>&#39;alertname&#39;</span>, <span style=color:#e6db74>&#39;instance&#39;</span>]  <span style=color:#75715e># 按 alertname 和 instance 标签分组</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>group_interval</span>: <span style=color:#ae81ff>5m </span> <span style=color:#75715e># 同一组告警之间的最小间隔时间</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>repeat_interval</span>: <span style=color:#ae81ff>30m </span> <span style=color:#75715e># 重复告警的最小时间间隔</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>receiver</span>: <span style=color:#e6db74>&#39;email-notifications&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>receivers</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>name</span>: <span style=color:#e6db74>&#39;email-notifications&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>email_configs</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>to</span>: <span style=color:#e6db74>&#39;alerts@example.com&#39;</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>send_resolved</span>: <span style=color:#66d9ef>true</span>
</span></span></code></pre></div><h3 id=2-告警收敛alert-aggregation>2. <strong>告警收敛（Alert Aggregation）</strong>
<a class=anchor href=#2-%e5%91%8a%e8%ad%a6%e6%94%b6%e6%95%9balert-aggregation>#</a></h3><p>告警收敛是指将多个相似的告警合并为一个告警，避免发送过多的单独告警通知。这种方式能减少噪声，并使告警更易于管理和响应。</p><h4 id=使用场景-1>使用场景：
<a class=anchor href=#%e4%bd%bf%e7%94%a8%e5%9c%ba%e6%99%af-1>#</a></h4><ul><li><strong>多个节点告警合并</strong>：如果你的系统有多个相似的节点，出现故障时，多个节点可能会触发相同类型的告警。告警收敛可以将这些节点的告警合并成一个告警，避免多个相同告警的通知。</li><li><strong>系统组件告警合并</strong>：例如，多个服务的故障可能会同时触发告警。将这些告警合并成一个，可以集中处理。</li></ul><h4 id=配置告警收敛>配置告警收敛：
<a class=anchor href=#%e9%85%8d%e7%bd%ae%e5%91%8a%e8%ad%a6%e6%94%b6%e6%95%9b>#</a></h4><p>可以使用 <code>alert</code> 规则中的 <code>for</code> 参数和 <code>group_by</code> 来合并告警。</p><ul><li><strong><code>for</code></strong>：指定在告警触发之后，必须持续一定时间才能被通知。这有助于减少短时间内的波动导致的告警。</li><li><strong><code>group_by</code></strong>：将告警分组到相同组内，便于对相关告警进行合并。</li></ul><p>配置示例：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>groups</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>name</span>: <span style=color:#e6db74>&#39;example-alerts&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>rules</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>alert</span>: <span style=color:#ae81ff>HighCPUUsage</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>expr</span>: <span style=color:#ae81ff>rate(cpu_usage_seconds_total[1m]) &gt; 0.8</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>for</span>: <span style=color:#ae81ff>1m </span> <span style=color:#75715e># 持续1分钟触发告警</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>severity</span>: <span style=color:#e6db74>&#39;critical&#39;</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>description</span>: <span style=color:#e6db74>&#39;CPU usage is over 80%&#39;</span>
</span></span></code></pre></div><p>在 Alertmanager 中，也可以通过 <code>group_by</code> 将相似的告警合并。例如，将多个 CPU 使用高的告警合并成一个告警，并且通过 <code>group_interval</code> 控制多次触发时的合并间隔。</p><h3 id=3-告警收敛与告警抑制的区别>3. <strong>告警收敛与告警抑制的区别</strong>
<a class=anchor href=#3-%e5%91%8a%e8%ad%a6%e6%94%b6%e6%95%9b%e4%b8%8e%e5%91%8a%e8%ad%a6%e6%8a%91%e5%88%b6%e7%9a%84%e5%8c%ba%e5%88%ab>#</a></h3><ul><li><strong>告警抑制</strong>：在一个告警触发后，抑制其他相关告警的触发，直到主告警得到解决。例如，在节点宕机的情况下，抑制其上面所有服务的告警，避免告警泛滥。</li><li><strong>告警收敛</strong>：将多个相似的告警合并为一个告警，以避免多个重复的告警通知。例如，当多台机器的 CPU 使用率超过阈值时，将其合并为一个告警。</li></ul><h3 id=4-告警收敛和抑制的配置实践>4. <strong>告警收敛和抑制的配置实践</strong>
<a class=anchor href=#4-%e5%91%8a%e8%ad%a6%e6%94%b6%e6%95%9b%e5%92%8c%e6%8a%91%e5%88%b6%e7%9a%84%e9%85%8d%e7%bd%ae%e5%ae%9e%e8%b7%b5>#</a></h3><p>在实际使用中，告警收敛和抑制的配置通常结合使用，以优化告警系统：</p><ul><li><strong>收敛</strong>：将相似的告警合并成一个，避免过多的重复通知。</li><li><strong>抑制</strong>：当一个主告警触发时，抑制与之相关的次要告警，避免通知过多。</li></ul><p>以下是一个结合收敛和抑制的配置示例：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>route</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>group_by</span>: [<span style=color:#e6db74>&#39;alertname&#39;</span>, <span style=color:#e6db74>&#39;instance&#39;</span>]
</span></span><span style=display:flex><span>  <span style=color:#f92672>group_interval</span>: <span style=color:#ae81ff>10m </span> <span style=color:#75715e># 合并告警的间隔</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>repeat_interval</span>: <span style=color:#ae81ff>1h </span> <span style=color:#75715e># 重复告警的时间间隔</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>receiver</span>: <span style=color:#e6db74>&#39;email-notifications&#39;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>routes</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>match</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>severity</span>: <span style=color:#e6db74>&#39;critical&#39;</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>group_by</span>: [<span style=color:#e6db74>&#39;alertname&#39;</span>]
</span></span><span style=display:flex><span>      <span style=color:#f92672>group_interval</span>: <span style=color:#ae81ff>5m</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>repeat_interval</span>: <span style=color:#ae81ff>30m</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>receivers</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>name</span>: <span style=color:#e6db74>&#39;email-notifications&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>email_configs</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>to</span>: <span style=color:#e6db74>&#39;alerts@example.com&#39;</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>send_resolved</span>: <span style=color:#66d9ef>true</span>
</span></span></code></pre></div><h3 id=总结-8>总结
<a class=anchor href=#%e6%80%bb%e7%bb%93-8>#</a></h3><ul><li><strong>告警抑制</strong>（Alert Suppression）：通过抑制不必要的告警通知，减少冗余和噪声。常用于避免链式告警或相似告警的重复触发。</li><li><strong>告警收敛</strong>（Alert Aggregation）：将多个相似的告警合并成一个告警，集中处理，减少过多告警的通知。</li></ul><p>合理使用告警抑制和收敛可以显著提高告警系统的效率和响应速度，避免告警泛滥，确保用户能够专注于最关键的告警。</p><h6><a class=anchor href=#>#</a></h6><h2 id=业务pod的告警规则>业务pod的告警规则
<a class=anchor href=#%e4%b8%9a%e5%8a%a1pod%e7%9a%84%e5%91%8a%e8%ad%a6%e8%a7%84%e5%88%99>#</a></h2><p>业务 pod 的告警规则通常是根据 Kubernetes 集群中部署的业务应用的性能、健康状况和资源使用情况来进行监控和告警的。这些告警规则可以帮助运维人员及时发现和处理业务 pod 的问题，保证业务的高可用性和稳定性。</p><p>以下是一些常见的业务 pod 的告警规则示例，涵盖了不同层面的监控需求：</p><h3 id=1-pod-资源使用情况>1. <strong>Pod 资源使用情况</strong>
<a class=anchor href=#1-pod-%e8%b5%84%e6%ba%90%e4%bd%bf%e7%94%a8%e6%83%85%e5%86%b5>#</a></h3><p>监控 pod 的 CPU、内存、磁盘等资源使用情况是告警规则中常见的一部分。这些指标有助于发现 pod 的资源瓶颈、过度使用或资源限制问题。</p><h4 id=示例-1cpu-使用率过高>示例 1：CPU 使用率过高
<a class=anchor href=#%e7%a4%ba%e4%be%8b-1cpu-%e4%bd%bf%e7%94%a8%e7%8e%87%e8%bf%87%e9%ab%98>#</a></h4><p>监控 pod 的 CPU 使用率，确保它不会超过设定的阈值。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>groups</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>name</span>: <span style=color:#e6db74>&#39;pod-resources&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>rules</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>alert</span>: <span style=color:#ae81ff>PodHighCPUUsage</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>expr</span>: <span style=color:#ae81ff>sum(rate(container_cpu_usage_seconds_total{pod=~&#34;your-business-pod-.*&#34;, container!=&#34;&#34;, image!=&#34;&#34;}[5m])) by (pod) / sum(kube_pod_container_resource_limits{pod=~&#34;your-business-pod-.*&#34;, resource=&#34;cpu&#34;}) by (pod) &gt; 0.8</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>for</span>: <span style=color:#ae81ff>1m</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>severity</span>: <span style=color:#ae81ff>critical</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>summary</span>: <span style=color:#e6db74>&#34;Pod &#39;{{ $labels.pod }}&#39; CPU usage is over 80% for the last 1 minute.&#34;</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>description</span>: <span style=color:#e6db74>&#34;The CPU usage of pod &#39;{{ $labels.pod }}&#39; has exceeded the threshold of 80%.&#34;</span>
</span></span></code></pre></div><p>此规则会触发告警，当 <code>your-business-pod</code> 中的 pod 的 CPU 使用率超过 80% 时。</p><h4 id=示例-2内存使用率过高>示例 2：内存使用率过高
<a class=anchor href=#%e7%a4%ba%e4%be%8b-2%e5%86%85%e5%ad%98%e4%bd%bf%e7%94%a8%e7%8e%87%e8%bf%87%e9%ab%98>#</a></h4><p>监控 pod 的内存使用情况，防止内存泄漏或内存资源不足。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>      - <span style=color:#f92672>alert</span>: <span style=color:#ae81ff>PodHighMemoryUsage</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>expr</span>: <span style=color:#ae81ff>sum(container_memory_usage_bytes{pod=~&#34;your-business-pod-.*&#34;, container!=&#34;&#34;, image!=&#34;&#34;}) by (pod) / sum(kube_pod_container_resource_limits{pod=~&#34;your-business-pod-.*&#34;, resource=&#34;memory&#34;}) by (pod) &gt; 0.8</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>for</span>: <span style=color:#ae81ff>1m</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>severity</span>: <span style=color:#ae81ff>critical</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>summary</span>: <span style=color:#e6db74>&#34;Pod &#39;{{ $labels.pod }}&#39; memory usage is over 80%.&#34;</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>description</span>: <span style=color:#e6db74>&#34;The memory usage of pod &#39;{{ $labels.pod }}&#39; is over 80% of the limit.&#34;</span>
</span></span></code></pre></div><p>此规则会触发告警，当 <code>your-business-pod</code> 中的 pod 的内存使用率超过 80% 时。</p><h3 id=2-pod-健康检查失败>2. <strong>Pod 健康检查失败</strong>
<a class=anchor href=#2-pod-%e5%81%a5%e5%ba%b7%e6%a3%80%e6%9f%a5%e5%a4%b1%e8%b4%a5>#</a></h3><p>健康检查失败的告警规则可以帮助你发现 pod 是否存在启动、连接或其他健康问题。</p><h4 id=示例-3pod-livenessprobe-失败>示例 3：Pod livenessProbe 失败
<a class=anchor href=#%e7%a4%ba%e4%be%8b-3pod-livenessprobe-%e5%a4%b1%e8%b4%a5>#</a></h4><p>监控业务 pod 的 <code>livenessProbe</code>，如果 pod 健康检查失败，说明 pod 可能需要重启。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>      - <span style=color:#f92672>alert</span>: <span style=color:#ae81ff>PodLivenessProbeFailed</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>expr</span>: <span style=color:#ae81ff>kube_pod_container_status_restarts_total{pod=~&#34;your-business-pod-.*&#34;, container!=&#34;&#34;, container!=&#34;POD&#34;} &gt; 3</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>for</span>: <span style=color:#ae81ff>5m</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>severity</span>: <span style=color:#ae81ff>critical</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>summary</span>: <span style=color:#e6db74>&#34;Pod &#39;{{ $labels.pod }}&#39; has failed livenessProbe more than 3 times in the last 5 minutes.&#34;</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>description</span>: <span style=color:#e6db74>&#34;Pod &#39;{{ $labels.pod }}&#39; is not healthy. It has failed the liveness probe more than 3 times in the last 5 minutes.&#34;</span>
</span></span></code></pre></div><p>此规则会触发告警，当 pod 的 <code>livenessProbe</code> 失败超过 3 次时。</p><h4 id=示例-4pod-readinessprobe-失败>示例 4：Pod readinessProbe 失败
<a class=anchor href=#%e7%a4%ba%e4%be%8b-4pod-readinessprobe-%e5%a4%b1%e8%b4%a5>#</a></h4><p>监控 pod 的 <code>readinessProbe</code>，当 <code>readinessProbe</code> 失败时，表示 pod 无法接收流量。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>      - <span style=color:#f92672>alert</span>: <span style=color:#ae81ff>PodReadinessProbeFailed</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>expr</span>: <span style=color:#ae81ff>kube_pod_container_status_ready{pod=~&#34;your-business-pod-.*&#34;, container!=&#34;&#34;, container!=&#34;POD&#34;} == 0</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>for</span>: <span style=color:#ae81ff>5m</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>severity</span>: <span style=color:#ae81ff>critical</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>summary</span>: <span style=color:#e6db74>&#34;Pod &#39;{{ $labels.pod }}&#39; is not ready.&#34;</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>description</span>: <span style=color:#e6db74>&#34;Pod &#39;{{ $labels.pod }}&#39; has failed the readiness probe or is not ready to receive traffic.&#34;</span>
</span></span></code></pre></div><p>此规则会触发告警，当 pod 的 <code>readinessProbe</code> 失败时，表示 pod 无法接收流量。</p><h3 id=3-pod-容器的重启>3. <strong>Pod 容器的重启</strong>
<a class=anchor href=#3-pod-%e5%ae%b9%e5%99%a8%e7%9a%84%e9%87%8d%e5%90%af>#</a></h3><p>容器频繁重启可能是由于应用崩溃、资源不足或者配置错误等问题。</p><h4 id=示例-5容器重启次数过多>示例 5：容器重启次数过多
<a class=anchor href=#%e7%a4%ba%e4%be%8b-5%e5%ae%b9%e5%99%a8%e9%87%8d%e5%90%af%e6%ac%a1%e6%95%b0%e8%bf%87%e5%a4%9a>#</a></h4><p>监控容器的重启次数，若重启次数过多，则说明可能存在潜在问题。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>      - <span style=color:#f92672>alert</span>: <span style=color:#ae81ff>PodContainerRestartingTooMuch</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>expr</span>: <span style=color:#ae81ff>kube_pod_container_status_restarts_total{pod=~&#34;your-business-pod-.*&#34;, container!=&#34;&#34;, container!=&#34;POD&#34;} &gt; 5</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>for</span>: <span style=color:#ae81ff>10m</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>severity</span>: <span style=color:#ae81ff>warning</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>summary</span>: <span style=color:#e6db74>&#34;Pod &#39;{{ $labels.pod }}&#39; container has restarted more than 5 times in the last 10 minutes.&#34;</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>description</span>: <span style=color:#e6db74>&#34;Pod &#39;{{ $labels.pod }}&#39; container has been restarted more than 5 times, which may indicate a problem.&#34;</span>
</span></span></code></pre></div><p>此规则会触发告警，当 pod 中的容器在 10 分钟内重启超过 5 次时。</p><h3 id=4-pod-调度和资源限制>4. <strong>Pod 调度和资源限制</strong>
<a class=anchor href=#4-pod-%e8%b0%83%e5%ba%a6%e5%92%8c%e8%b5%84%e6%ba%90%e9%99%90%e5%88%b6>#</a></h3><p>如果 pod 无法调度到节点上，可能是因为资源不足或者节点配置问题。</p><h4 id=示例-6pod-无法调度>示例 6：Pod 无法调度
<a class=anchor href=#%e7%a4%ba%e4%be%8b-6pod-%e6%97%a0%e6%b3%95%e8%b0%83%e5%ba%a6>#</a></h4><p>监控 pod 的调度情况，若 pod 无法调度，会触发告警。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>      - <span style=color:#f92672>alert</span>: <span style=color:#ae81ff>PodPending</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>expr</span>: <span style=color:#ae81ff>kube_pod_status_phase{pod=~&#34;your-business-pod-.*&#34;, phase=&#34;Pending&#34;} &gt; 0</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>for</span>: <span style=color:#ae81ff>5m</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>severity</span>: <span style=color:#ae81ff>critical</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>summary</span>: <span style=color:#e6db74>&#34;Pod &#39;{{ $labels.pod }}&#39; is in pending state.&#34;</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>description</span>: <span style=color:#e6db74>&#34;Pod &#39;{{ $labels.pod }}&#39; has been in pending state for more than 5 minutes and cannot be scheduled.&#34;</span>
</span></span></code></pre></div><p>此规则会触发告警，当 pod 处于 <code>Pending</code> 状态超过 5 分钟时。</p><h3 id=5-网络延迟或连接问题>5. <strong>网络延迟或连接问题</strong>
<a class=anchor href=#5-%e7%bd%91%e7%bb%9c%e5%bb%b6%e8%bf%9f%e6%88%96%e8%bf%9e%e6%8e%a5%e9%97%ae%e9%a2%98>#</a></h3><p>业务应用可能会遇到网络延迟或连接失败的问题，导致服务不可用。</p><h4 id=示例-7pod-网络延迟高>示例 7：Pod 网络延迟高
<a class=anchor href=#%e7%a4%ba%e4%be%8b-7pod-%e7%bd%91%e7%bb%9c%e5%bb%b6%e8%bf%9f%e9%ab%98>#</a></h4><p>监控 pod 的网络延迟，若延迟过高，可能会影响业务性能。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>      - <span style=color:#f92672>alert</span>: <span style=color:#ae81ff>PodHighNetworkLatency</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>expr</span>: <span style=color:#ae81ff>histogram_quantile(0.99, sum(rate(container_network_transmit_errors_total{pod=~&#34;your-business-pod-.*&#34;}[5m])) by (pod)) &gt; 100</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>for</span>: <span style=color:#ae81ff>5m</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>severity</span>: <span style=color:#ae81ff>warning</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>summary</span>: <span style=color:#e6db74>&#34;Pod &#39;{{ $labels.pod }}&#39; has high network latency.&#34;</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>description</span>: <span style=color:#e6db74>&#34;Pod &#39;{{ $labels.pod }}&#39; has network transmit errors higher than 100 in the last 5 minutes.&#34;</span>
</span></span></code></pre></div><p>此规则会触发告警，当 pod 的网络错误数超过 100 时，可能会影响应用的网络性能。</p><h3 id=总结-9>总结
<a class=anchor href=#%e6%80%bb%e7%bb%93-9>#</a></h3><p>业务 pod 的告警规则通常涉及以下几个方面：</p><ul><li><strong>资源使用情况</strong>：包括 CPU、内存、磁盘等的使用情况，确保 pod 不会超出资源限制。</li><li><strong>健康检查</strong>：包括 <code>livenessProbe</code> 和 <code>readinessProbe</code>，监控 pod 是否健康并能正常处理流量。</li><li><strong>容器重启</strong>：监控容器是否频繁重启，频繁重启可能表明系统存在问题。</li><li><strong>调度和资源限制</strong>：确保 pod 能够成功调度并分配到合适的节点上。</li><li><strong>网络问题</strong>：监控 pod 网络连接和延迟，确保应用能够正常通信。</li></ul><p>这些告警规则可以根据业务需求和实际情况进一步调整，确保及时发现和解决业务 pod 的问题。</p><p>要为业务 Pod 设置告警规则，可以根据以下常见指标配置 Prometheus 告警规则：</p><h3 id=1-cpu-使用率告警>1. <strong>CPU 使用率告警</strong>
<a class=anchor href=#1-cpu-%e4%bd%bf%e7%94%a8%e7%8e%87%e5%91%8a%e8%ad%a6>#</a></h3><p>当 Pod 的 CPU 使用率超过某个阈值时触发告警：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>groups</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>business-pod-alerts</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>rules</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>alert</span>: <span style=color:#ae81ff>HighCPUUsage</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>expr</span>: <span style=color:#ae81ff>sum(rate(container_cpu_usage_seconds_total{pod=~&#34;business-pod.*&#34;}[5m])) by (pod) &gt; 0.8</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>for</span>: <span style=color:#ae81ff>1m</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>severity</span>: <span style=color:#ae81ff>critical</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>description</span>: <span style=color:#e6db74>&#34;CPU usage exceeds 80% for Pod {{ $labels.pod }}&#34;</span>
</span></span></code></pre></div><h3 id=2-内存使用率告警>2. <strong>内存使用率告警</strong>
<a class=anchor href=#2-%e5%86%85%e5%ad%98%e4%bd%bf%e7%94%a8%e7%8e%87%e5%91%8a%e8%ad%a6>#</a></h3><p>当 Pod 的内存使用率超过某个阈值时触发告警：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>      - <span style=color:#f92672>alert</span>: <span style=color:#ae81ff>HighMemoryUsage</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>expr</span>: <span style=color:#ae81ff>sum(container_memory_usage_bytes{pod=~&#34;business-pod.*&#34;}) by (pod) / sum(container_spec_memory_limit_bytes{pod=~&#34;business-pod.*&#34;}) by (pod) &gt; 0.8</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>for</span>: <span style=color:#ae81ff>1m</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>severity</span>: <span style=color:#ae81ff>critical</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>description</span>: <span style=color:#e6db74>&#34;Memory usage exceeds 80% for Pod {{ $labels.pod }}&#34;</span>
</span></span></code></pre></div><h3 id=3-pod-失效告警>3. <strong>Pod 失效告警</strong>
<a class=anchor href=#3-pod-%e5%a4%b1%e6%95%88%e5%91%8a%e8%ad%a6>#</a></h3><p>当 Pod 的状态为失败时触发告警：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>      - <span style=color:#f92672>alert</span>: <span style=color:#ae81ff>PodFailed</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>expr</span>: <span style=color:#ae81ff>kube_pod_status_phase{pod=~&#34;business-pod.*&#34;, phase=&#34;Failed&#34;} == 1</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>for</span>: <span style=color:#ae81ff>5m</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>severity</span>: <span style=color:#ae81ff>critical</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>description</span>: <span style=color:#e6db74>&#34;Pod {{ $labels.pod }} has failed&#34;</span>
</span></span></code></pre></div><h3 id=4-pod-重启告警>4. <strong>Pod 重启告警</strong>
<a class=anchor href=#4-pod-%e9%87%8d%e5%90%af%e5%91%8a%e8%ad%a6>#</a></h3><p>当 Pod 的重启次数超过阈值时触发告警：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>      - <span style=color:#f92672>alert</span>: <span style=color:#ae81ff>PodRestarts</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>expr</span>: <span style=color:#ae81ff>increase(kube_pod_container_status_restarts_total{pod=~&#34;business-pod.*&#34;}[1h]) &gt; 3</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>for</span>: <span style=color:#ae81ff>10m</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>severity</span>: <span style=color:#ae81ff>warning</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>description</span>: <span style=color:#e6db74>&#34;Pod {{ $labels.pod }} has restarted more than 3 times in the last hour&#34;</span>
</span></span></code></pre></div><p>这些告警规则可以帮助你及时发现业务 Pod 的性能问题，确保系统稳定运行。</p><h6><a class=anchor href=#>#</a></h6><h6><a class=anchor href=#>#</a></h6><h2 id=请求成功率的监控怎么做的>请求成功率的监控怎么做的
<a class=anchor href=#%e8%af%b7%e6%b1%82%e6%88%90%e5%8a%9f%e7%8e%87%e7%9a%84%e7%9b%91%e6%8e%a7%e6%80%8e%e4%b9%88%e5%81%9a%e7%9a%84>#</a></h2><p>请求成功率的监控是保证服务可靠性和稳定性的重要指标。通常，计算请求成功率是通过计算请求成功的次数与总请求次数的比率。以下是如何通过 Prometheus 来监控和告警请求成功率的方法：</p><h3 id=1-监控请求成功率的基础指标>1. <strong>监控请求成功率的基础指标</strong>
<a class=anchor href=#1-%e7%9b%91%e6%8e%a7%e8%af%b7%e6%b1%82%e6%88%90%e5%8a%9f%e7%8e%87%e7%9a%84%e5%9f%ba%e7%a1%80%e6%8c%87%e6%a0%87>#</a></h3><p>为了计算请求成功率，你首先需要在应用程序或服务中暴露 HTTP 请求的相关指标，通常是通过 Prometheus 的 <code>http_requests_total</code> 之类的计数器指标。</p><p>假设你有以下两个指标：</p><ul><li><code>http_requests_total{status="200", job="myapp"}</code>：成功的请求数（HTTP 200 状态码）。</li><li><code>http_requests_total{job="myapp"}</code>：所有请求的总数（所有状态码）。</li></ul><h3 id=2-计算请求成功率>2. <strong>计算请求成功率</strong>
<a class=anchor href=#2-%e8%ae%a1%e7%ae%97%e8%af%b7%e6%b1%82%e6%88%90%e5%8a%9f%e7%8e%87>#</a></h3><p>你可以使用 Prometheus 查询语言（PromQL）来计算请求的成功率。假设成功请求数和总请求数的标签中包含 <code>job="myapp"</code>，可以按如下方式编写查询：</p><pre tabindex=0><code class=language-prometheus data-lang=prometheus>rate(http_requests_total{status=&#34;200&#34;, job=&#34;myapp&#34;}[5m]) / rate(http_requests_total{job=&#34;myapp&#34;}[5m]) * 100
</code></pre><p>这个查询的含义是：</p><ul><li><code>rate(http_requests_total{status="200", job="myapp"}[5m])</code>：计算过去 5 分钟内成功请求（状态码 200）的速率。</li><li><code>rate(http_requests_total{job="myapp"}[5m])</code>：计算过去 5 分钟内所有请求（包括状态码为 200 以外的请求）的速率。</li><li>用成功请求数除以总请求数并乘以 100，得到请求成功率。</li></ul><h3 id=3-设置告警规则>3. <strong>设置告警规则</strong>
<a class=anchor href=#3-%e8%ae%be%e7%bd%ae%e5%91%8a%e8%ad%a6%e8%a7%84%e5%88%99>#</a></h3><p>如果请求成功率低于某个阈值，你可以设置告警规则。以下是一个示例，表示当请求成功率低于 95% 时触发告警：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>groups</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>business-pod-alerts</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>rules</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>alert</span>: <span style=color:#ae81ff>LowRequestSuccessRate</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>expr</span>: <span style=color:#ae81ff>(rate(http_requests_total{status=&#34;200&#34;, job=&#34;myapp&#34;}[5m]) / rate(http_requests_total{job=&#34;myapp&#34;}[5m])) * 100 &lt; 95</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>for</span>: <span style=color:#ae81ff>2m</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>severity</span>: <span style=color:#ae81ff>critical</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>description</span>: <span style=color:#e6db74>&#34;Request success rate is below 95% for the service&#34;</span>
</span></span></code></pre></div><h3 id=4-监控失败的请求>4. <strong>监控失败的请求</strong>
<a class=anchor href=#4-%e7%9b%91%e6%8e%a7%e5%a4%b1%e8%b4%a5%e7%9a%84%e8%af%b7%e6%b1%82>#</a></h3><p>如果你还想专门监控失败请求的数量，可以针对其他 HTTP 状态码进行监控。例如，监控 500（服务器错误）状态码的请求数：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>      - <span style=color:#f92672>alert</span>: <span style=color:#ae81ff>HighErrorRate</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>expr</span>: <span style=color:#ae81ff>rate(http_requests_total{status=~&#34;5..&#34;, job=&#34;myapp&#34;}[5m]) / rate(http_requests_total{job=&#34;myapp&#34;}[5m]) * 100 &gt; 5</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>for</span>: <span style=color:#ae81ff>5m</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>severity</span>: <span style=color:#ae81ff>critical</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>description</span>: <span style=color:#e6db74>&#34;More than 5% of requests have failed (status code 5xx)&#34;</span>
</span></span></code></pre></div><h3 id=5-高级监控与告警>5. <strong>高级监控与告警</strong>
<a class=anchor href=#5-%e9%ab%98%e7%ba%a7%e7%9b%91%e6%8e%a7%e4%b8%8e%e5%91%8a%e8%ad%a6>#</a></h3><ul><li><p><strong>计算特定时间窗口内的成功率</strong>：你可以根据实际需求调整查询的时间窗口（如 <code>rate(...[10m])</code>），或者根据不同的服务路径（<code>path</code> 标签）设置不同的阈值。</p></li><li><p>使用分层告警</p><p>：通过告警规则中的</p><pre tabindex=0><code>severity
</code></pre><p>标签，可以设置不同级别的告警，例如：</p><ul><li><code>critical</code>：请求成功率低于某个临界值（如 90%）。</li><li><code>warning</code>：请求成功率稍微下降，可能需要进一步检查（如 95%）。</li></ul></li></ul><h3 id=总结-10>总结
<a class=anchor href=#%e6%80%bb%e7%bb%93-10>#</a></h3><p>通过 Prometheus 和 PromQL，你可以非常灵活地监控请求成功率并设定告警。关键步骤包括：</p><ol><li><strong>暴露 HTTP 请求的相关指标</strong>（如成功的请求和总请求数）。</li><li><strong>编写计算请求成功率的 PromQL 查询</strong>。</li><li><strong>根据请求成功率设置告警规则</strong>，及时发现问题并采取措施。</li></ol><h2 id=接口探活呢>接口探活呢
<a class=anchor href=#%e6%8e%a5%e5%8f%a3%e6%8e%a2%e6%b4%bb%e5%91%a2>#</a></h2><p>接口探活（Health Check）是为了确保服务和应用程序处于健康状态并能够正常处理请求的一种监控方式。通过 Prometheus 监控接口探活，通常可以通过暴露健康检查端点并结合相应的指标进行监控。</p><p>以下是如何使用 Prometheus 实现接口探活监控的步骤：</p><h3 id=1-暴露健康检查端点>1. <strong>暴露健康检查端点</strong>
<a class=anchor href=#1-%e6%9a%b4%e9%9c%b2%e5%81%a5%e5%ba%b7%e6%a3%80%e6%9f%a5%e7%ab%af%e7%82%b9>#</a></h3><p>通常，应用程序会提供一个 HTTP 健康检查端点（例如 <code>/health</code> 或 <code>/actuator/health</code>），返回应用的健康状态。你需要确保应用程序暴露了一个健康检查 API，该 API 会返回成功（HTTP 200）或失败（HTTP 5xx）状态码。</p><p>例如，在 Spring Boot 应用中，你可以暴露如下端点：</p><ul><li><code>/actuator/health</code>（Spring Boot 健康检查）</li></ul><p>在 Node.js 应用中，你可以设置一个简单的健康检查端点：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-javascript data-lang=javascript><span style=display:flex><span><span style=color:#a6e22e>app</span>.<span style=color:#a6e22e>get</span>(<span style=color:#e6db74>&#39;/health&#39;</span>, (<span style=color:#a6e22e>req</span>, <span style=color:#a6e22e>res</span>) =&gt; {
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>res</span>.<span style=color:#a6e22e>status</span>(<span style=color:#ae81ff>200</span>).<span style=color:#a6e22e>send</span>(<span style=color:#e6db74>&#39;OK&#39;</span>);
</span></span><span style=display:flex><span>});
</span></span></code></pre></div><h3 id=2-暴露健康检查指标>2. <strong>暴露健康检查指标</strong>
<a class=anchor href=#2-%e6%9a%b4%e9%9c%b2%e5%81%a5%e5%ba%b7%e6%a3%80%e6%9f%a5%e6%8c%87%e6%a0%87>#</a></h3><p>在 Prometheus 中，通常使用一个自定义的指标来暴露健康检查的状态。你可以暴露一个专门的健康检查指标，表示服务是否正常运行。例如：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plaintext data-lang=plaintext><span style=display:flex><span>up{job=&#34;myapp&#34;, status=&#34;healthy&#34;} 1
</span></span><span style=display:flex><span>up{job=&#34;myapp&#34;, status=&#34;unhealthy&#34;} 0
</span></span></code></pre></div><p>在 Prometheus 的配置中，<code>up</code> 是一个用于标识目标是否可用的内建指标。你可以自定义监控指标，比如暴露 <code>http_health_check_status</code> 作为健康检查的状态指标。</p><h3 id=3-通过-prometheus-查询健康检查状态>3. <strong>通过 Prometheus 查询健康检查状态</strong>
<a class=anchor href=#3-%e9%80%9a%e8%bf%87-prometheus-%e6%9f%a5%e8%af%a2%e5%81%a5%e5%ba%b7%e6%a3%80%e6%9f%a5%e7%8a%b6%e6%80%81>#</a></h3><p>在 Prometheus 中，你可以查询某个服务的健康检查状态，例如：</p><pre tabindex=0><code class=language-prometheus data-lang=prometheus>http_health_check_status{job=&#34;myapp&#34;} == 1
</code></pre><p>这个查询会返回 <code>1</code> 表示健康，<code>0</code> 表示不健康。</p><h3 id=4-设置告警规则>4. <strong>设置告警规则</strong>
<a class=anchor href=#4-%e8%ae%be%e7%bd%ae%e5%91%8a%e8%ad%a6%e8%a7%84%e5%88%99>#</a></h3><p>当健康检查状态不正常时，你可以通过 Prometheus 设置告警规则，及时发现问题。例如，当服务出现故障时（返回状态码 5xx 或健康检查失败），触发告警。</p><h4 id=示例健康检查失败时告警>示例：健康检查失败时告警
<a class=anchor href=#%e7%a4%ba%e4%be%8b%e5%81%a5%e5%ba%b7%e6%a3%80%e6%9f%a5%e5%a4%b1%e8%b4%a5%e6%97%b6%e5%91%8a%e8%ad%a6>#</a></h4><p>假设你有一个健康检查的指标 <code>http_health_check_status</code>，你可以编写如下告警规则：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>groups</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>health-check-alerts</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>rules</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>alert</span>: <span style=color:#ae81ff>ServiceUnhealthy</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>expr</span>: <span style=color:#ae81ff>http_health_check_status{job=&#34;myapp&#34;} == 0</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>for</span>: <span style=color:#ae81ff>2m</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>severity</span>: <span style=color:#ae81ff>critical</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>description</span>: <span style=color:#e6db74>&#34;The health check of the service {{ $labels.job }} failed&#34;</span>
</span></span></code></pre></div><h4 id=示例http-5xx-错误率过高时告警>示例：HTTP 5xx 错误率过高时告警
<a class=anchor href=#%e7%a4%ba%e4%be%8bhttp-5xx-%e9%94%99%e8%af%af%e7%8e%87%e8%bf%87%e9%ab%98%e6%97%b6%e5%91%8a%e8%ad%a6>#</a></h4><p>你也可以监控 HTTP 错误率，来作为接口探活的一个补充。比如，如果 HTTP 5xx 错误率超过 5% 时触发告警：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>      - <span style=color:#f92672>alert</span>: <span style=color:#ae81ff>HighErrorRate</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>expr</span>: <span style=color:#ae81ff>rate(http_requests_total{status=~&#34;5..&#34;, job=&#34;myapp&#34;}[5m]) / rate(http_requests_total{job=&#34;myapp&#34;}[5m]) * 100 &gt; 5</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>for</span>: <span style=color:#ae81ff>5m</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>severity</span>: <span style=color:#ae81ff>critical</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>description</span>: <span style=color:#e6db74>&#34;More than 5% of HTTP requests have failed (status code 5xx)&#34;</span>
</span></span></code></pre></div><h3 id=5-使用-kubernetes-探针livenessreadiness>5. <strong>使用 Kubernetes 探针（Liveness/Readiness）</strong>
<a class=anchor href=#5-%e4%bd%bf%e7%94%a8-kubernetes-%e6%8e%a2%e9%92%88livenessreadiness>#</a></h3><p>如果你的应用部署在 Kubernetes 上，可以利用 Kubernetes 提供的 <strong>Liveness Probe</strong> 和 <strong>Readiness Probe</strong> 来监控应用的健康状态。</p><ul><li><strong>Liveness Probe</strong>：判断应用是否仍然活着。如果此探针失败，Kubernetes 会重启容器。</li><li><strong>Readiness Probe</strong>：判断应用是否准备好接受流量。如果此探针失败，Kubernetes 会停止向该 Pod 分配流量。</li></ul><p>在 <code>deployment.yaml</code> 中，你可以定义如下探针：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>livenessProbe</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>httpGet</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>path</span>: <span style=color:#ae81ff>/health</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>port</span>: <span style=color:#ae81ff>8080</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>initialDelaySeconds</span>: <span style=color:#ae81ff>30</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>periodSeconds</span>: <span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>readinessProbe</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>httpGet</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>path</span>: <span style=color:#ae81ff>/health</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>port</span>: <span style=color:#ae81ff>8080</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>initialDelaySeconds</span>: <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>periodSeconds</span>: <span style=color:#ae81ff>10</span>
</span></span></code></pre></div><h3 id=6-总结>6. <strong>总结</strong>
<a class=anchor href=#6-%e6%80%bb%e7%bb%93>#</a></h3><p>通过以下几步，你可以实现接口探活监控：</p><ol><li><strong>暴露健康检查端点</strong>：确保应用提供一个健康检查 API，返回服务的健康状态。</li><li><strong>暴露健康检查指标</strong>：将健康检查状态暴露为 Prometheus 可监控的指标。</li><li><strong>Prometheus 查询</strong>：使用 PromQL 查询健康检查的状态。</li><li><strong>设置告警规则</strong>：当健康检查失败或错误率过高时，触发告警。</li><li><strong>Kubernetes 探针</strong>：如果在 Kubernetes 中部署，使用 Liveness 和 Readiness 探针监控 Pod 的健康状态。</li></ol><p>结合以上策略，你可以实现强大的接口探活监控，确保你的服务始终健康可用。</p><h2 id=一个微服务的业务流量通过外部进入集群内部的过程>一个微服务的业务，流量通过外部进入集群内部的过程
<a class=anchor href=#%e4%b8%80%e4%b8%aa%e5%be%ae%e6%9c%8d%e5%8a%a1%e7%9a%84%e4%b8%9a%e5%8a%a1%e6%b5%81%e9%87%8f%e9%80%9a%e8%bf%87%e5%a4%96%e9%83%a8%e8%bf%9b%e5%85%a5%e9%9b%86%e7%be%a4%e5%86%85%e9%83%a8%e7%9a%84%e8%bf%87%e7%a8%8b>#</a></h2><p>在微服务架构中，流量从外部进入集群并通过内部服务进行处理的过程，通常包括以下几个步骤：外部流量的接入、入口控制、路由和负载均衡、以及服务间的调用。下面是详细的流程：</p><h3 id=1-外部流量的接入>1. <strong>外部流量的接入</strong>
<a class=anchor href=#1-%e5%a4%96%e9%83%a8%e6%b5%81%e9%87%8f%e7%9a%84%e6%8e%a5%e5%85%a5>#</a></h3><p>外部流量一般通过以下方式进入 Kubernetes 集群内部：</p><ul><li><strong>Ingress Controller</strong>：Kubernetes 提供了 <code>Ingress</code> 资源来管理 HTTP 和 HTTPS 流量。Ingress Controller 是处理这些流量的组件，通常结合负载均衡器（如 Nginx、Traefik 或 HAProxy）来将流量引导到集群内部的服务。</li><li><strong>Load Balancer</strong>：通过外部负载均衡器（如云提供商的 ELB）将流量路由到 Kubernetes 集群中。负载均衡器将流量分发到不同的入口服务（通常是 <code>Ingress Controller</code> 或 Kubernetes 服务）。</li></ul><p>例如，在 Kubernetes 集群上配置一个 <code>Ingress</code> 资源：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>networking.k8s.io/v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Ingress</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>my-app-ingress</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>rules</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>host</span>: <span style=color:#ae81ff>myapp.example.com</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>http</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>paths</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>path</span>: <span style=color:#ae81ff>/</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>pathType</span>: <span style=color:#ae81ff>Prefix</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>backend</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>service</span>:
</span></span><span style=display:flex><span>            <span style=color:#f92672>name</span>: <span style=color:#ae81ff>my-service</span>
</span></span><span style=display:flex><span>            <span style=color:#f92672>port</span>:
</span></span><span style=display:flex><span>              <span style=color:#f92672>number</span>: <span style=color:#ae81ff>80</span>
</span></span></code></pre></div><h3 id=2-ingress-controller-处理流量>2. <strong>Ingress Controller 处理流量</strong>
<a class=anchor href=#2-ingress-controller-%e5%a4%84%e7%90%86%e6%b5%81%e9%87%8f>#</a></h3><p>Ingress Controller 监听到外部流量后，根据 <code>Ingress</code> 资源的定义，将流量转发到对应的内部服务。Ingress Controller 负责对流量进行路由、SSL/TLS 终止（即加密流量的解密）、负载均衡等操作。</p><ul><li><strong>负载均衡</strong>：Ingress Controller 会根据 <code>Ingress</code> 配置进行负载均衡，将流量均匀分发到对应的后端服务。</li><li><strong>TLS 终止</strong>：Ingress Controller 可以配置为支持 HTTPS，进行 SSL/TLS 终止，确保流量的加密和解密。</li></ul><h3 id=3-服务发现与流量路由>3. <strong>服务发现与流量路由</strong>
<a class=anchor href=#3-%e6%9c%8d%e5%8a%a1%e5%8f%91%e7%8e%b0%e4%b8%8e%e6%b5%81%e9%87%8f%e8%b7%af%e7%94%b1>#</a></h3><p>流量通过 Ingress Controller 后，通常会进入某个内部服务。这些服务在 Kubernetes 中是通过 <code>Service</code> 资源进行暴露的，<code>Service</code> 提供了服务发现的功能，并通过 DNS 或 IP 进行内部路由。</p><ul><li><strong>Service</strong>：Kubernetes 中的 <code>Service</code> 是一组 Pod 的抽象，通过 <code>ClusterIP</code>、<code>NodePort</code> 或 <code>LoadBalancer</code> 方式暴露服务。</li></ul><p>例如，一个简单的 <code>Service</code> 配置：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Service</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>my-service</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>selector</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>app</span>: <span style=color:#ae81ff>my-app</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>protocol</span>: <span style=color:#ae81ff>TCP</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>port</span>: <span style=color:#ae81ff>80</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>targetPort</span>: <span style=color:#ae81ff>8080</span>
</span></span></code></pre></div><h3 id=4-内部流量的路由与负载均衡>4. <strong>内部流量的路由与负载均衡</strong>
<a class=anchor href=#4-%e5%86%85%e9%83%a8%e6%b5%81%e9%87%8f%e7%9a%84%e8%b7%af%e7%94%b1%e4%b8%8e%e8%b4%9f%e8%bd%bd%e5%9d%87%e8%a1%a1>#</a></h3><p>内部流量的路由和负载均衡可以由以下几个组件完成：</p><ul><li><strong>Kubernetes Service</strong>：Kubernetes 的 <code>ClusterIP</code> 服务为流量提供自动的负载均衡。它会将流量分发到匹配的 Pod，确保流量均匀分配。</li><li><strong>Service Mesh（例如 Istio、Linkerd）</strong>：在更复杂的微服务架构中，使用 Service Mesh 提供更加细粒度的流量控制、可观察性、限流、熔断等功能。Service Mesh 会帮助你在微服务之间进行安全、高效的流量管理。</li></ul><h3 id=5-服务间通信>5. <strong>服务间通信</strong>
<a class=anchor href=#5-%e6%9c%8d%e5%8a%a1%e9%97%b4%e9%80%9a%e4%bf%a1>#</a></h3><p>在微服务架构中，内部服务（如 A 服务调用 B 服务）需要通过 <code>Service</code> 名称进行通信。这通常通过 DNS 实现，Kubernetes 会为每个服务提供 DNS 解析。</p><p>例如，A 服务需要调用 B 服务，A 服务只需要使用 B 服务的 DNS 名称：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>curl http://my-b-service.default.svc.cluster.local
</span></span></code></pre></div><p>如果你使用 Service Mesh，还可以定义更加复杂的路由规则，例如基于路径或请求头的路由。</p><h3 id=6-安全控制与认证>6. <strong>安全控制与认证</strong>
<a class=anchor href=#6-%e5%ae%89%e5%85%a8%e6%8e%a7%e5%88%b6%e4%b8%8e%e8%ae%a4%e8%af%81>#</a></h3><p>在微服务中，尤其是在多服务之间的通信中，通常会需要对流量进行安全控制，如身份验证和授权。可以通过以下几种方式来实现：</p><ul><li><strong>API Gateway</strong>：可以使用 API Gateway 作为外部流量的入口，负责处理认证、授权等功能。</li><li><strong>Service Mesh</strong>：Service Mesh（如 Istio）可以提供 mTLS（相互 TLS 认证）来保护服务之间的通信，确保只有经过认证的服务才能访问其他服务。</li></ul><h3 id=7-监控与日志收集>7. <strong>监控与日志收集</strong>
<a class=anchor href=#7-%e7%9b%91%e6%8e%a7%e4%b8%8e%e6%97%a5%e5%bf%97%e6%94%b6%e9%9b%86>#</a></h3><p>在整个流量进入和处理的过程中，监控和日志收集非常重要。Prometheus、Grafana、Jaeger、Elasticsearch 等工具常用于微服务架构中进行全链路监控、日志分析和性能追踪。</p><ul><li><strong>Prometheus</strong>：用于收集和监控服务的各种指标（如请求数、错误率、响应时间等）。</li><li><strong>Jaeger</strong>：用于分布式追踪，查看请求在多个微服务之间流转的情况。</li><li><strong>Fluentd/ELK Stack</strong>：用于收集和分析日志，帮助排查问题和监控服务的健康状态。</li></ul><h3 id=8-总结>8. <strong>总结</strong>
<a class=anchor href=#8-%e6%80%bb%e7%bb%93>#</a></h3><p>流量从外部进入 Kubernetes 集群内部，通常的流程如下：</p><ol><li><strong>外部流量进入</strong>：外部流量通过负载均衡器、Ingress Controller 等进入 Kubernetes 集群。</li><li><strong>路由与负载均衡</strong>：Ingress Controller 依据 <code>Ingress</code> 规则将流量路由到相应的服务。</li><li><strong>服务发现与请求转发</strong>：Kubernetes Service 通过 DNS 进行服务发现，并将请求转发到匹配的 Pod。</li><li><strong>服务间通信</strong>：微服务通过 Kubernetes 的 Service 进行通信，Service Mesh 可以提供更加灵活的流量管理。</li><li><strong>安全控制与监控</strong>：通过 API Gateway、Service Mesh 和监控工具，确保服务间的安全、可靠性和可观测性。</li></ol><p>通过这种流量进入和内部处理的流程，微服务架构能够高效、可靠地处理外部流量，并提供服务之间的安全、可扩展通信。</p><h2 id=elkfluentd-怎么收集pod的日志>ELK/fluentd 怎么收集pod的日志
<a class=anchor href=#elkfluentd-%e6%80%8e%e4%b9%88%e6%94%b6%e9%9b%86pod%e7%9a%84%e6%97%a5%e5%bf%97>#</a></h2><p>在 Kubernetes 集群中，收集 Pod 的日志可以通过 <strong>ELK Stack（Elasticsearch, Logstash, Kibana）</strong> 或 <strong>Fluentd</strong> 来实现。以下是如何使用 ELK 和 Fluentd 来收集和处理 Kubernetes Pod 日志的方案。</p><h3 id=1-使用-fluentd-收集-pod-日志>1. <strong>使用 Fluentd 收集 Pod 日志</strong>
<a class=anchor href=#1-%e4%bd%bf%e7%94%a8-fluentd-%e6%94%b6%e9%9b%86-pod-%e6%97%a5%e5%bf%97>#</a></h3><p>Fluentd 是一个开源的日志收集和处理工具，能够将日志从多个来源（如 Pod）收集，并将它们推送到不同的后端系统（如 Elasticsearch、Kafka、HDFS 等）。</p><h4 id=步骤>步骤：
<a class=anchor href=#%e6%ad%a5%e9%aa%a4>#</a></h4><ol><li><p><strong>安装 Fluentd DaemonSet</strong>： Fluentd 在 Kubernetes 中通常作为 DaemonSet 部署，这样它可以在每个节点上运行，并收集该节点上所有 Pod 的日志。你可以通过以下步骤部署 Fluentd。</p><p>创建一个 Fluentd 配置文件 <code>fluentd-configmap.yaml</code>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>ConfigMap</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>fluentd-config</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>kube-system</span>
</span></span><span style=display:flex><span><span style=color:#f92672>data</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>fluentd.conf</span>: |<span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &lt;source&gt;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      @type tail
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      format json
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      path /var/log/containers/*.log
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      pos_file /var/log/fluentd.pos
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      tag kube.*
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &lt;/source&gt;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &lt;match kube.**&gt;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      @type elasticsearch
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      host elasticsearch.example.com
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      port 9200
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      logstash_format true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      flush_interval 5s
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &lt;/match&gt;</span>
</span></span></code></pre></div><p>这个配置文件做了以下几件事情：</p><ul><li>它从 <code>/var/log/containers/*.log</code> 读取容器日志。</li><li>使用 <code>tail</code> 插件实时获取日志数据。</li><li>将日志数据转发到 Elasticsearch（<code>elasticsearch.example.com:9200</code>）进行存储。</li></ul></li><li><p><strong>创建 Fluentd DaemonSet</strong>： 创建一个 Fluentd DaemonSet 使其在所有节点上运行，并将日志数据发送到 Elasticsearch。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>apps/v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>DaemonSet</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>fluentd</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>kube-system</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>selector</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>matchLabels</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>app</span>: <span style=color:#ae81ff>fluentd</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>template</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>app</span>: <span style=color:#ae81ff>fluentd</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>containers</span>:
</span></span><span style=display:flex><span>        - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>fluentd</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>image</span>: <span style=color:#ae81ff>fluent/fluentd:v1.12-debian-1.0</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>volumeMounts</span>:
</span></span><span style=display:flex><span>            - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>fluentd-config</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>mountPath</span>: <span style=color:#ae81ff>/fluentd/etc</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>volumes</span>:
</span></span><span style=display:flex><span>        - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>fluentd-config</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>configMap</span>:
</span></span><span style=display:flex><span>            <span style=color:#f92672>name</span>: <span style=color:#ae81ff>fluentd-config</span>
</span></span></code></pre></div></li><li><p><strong>访问和查询日志</strong>： 通过 Elasticsearch 存储的日志，您可以使用 Kibana 来访问和查询日志。Kibana 提供了丰富的日志查询、过滤和可视化功能。</p></li></ol><h4 id=fluentd-处理日志的流程>Fluentd 处理日志的流程：
<a class=anchor href=#fluentd-%e5%a4%84%e7%90%86%e6%97%a5%e5%bf%97%e7%9a%84%e6%b5%81%e7%a8%8b>#</a></h4><ol><li><strong>收集</strong>：Fluentd 会从 <code>/var/log/containers/*.log</code> 中收集容器日志。</li><li><strong>解析和过滤</strong>：Fluentd 可能会解析日志并根据标签（例如 <code>kube.*</code>）进行筛选和过滤。</li><li><strong>传输</strong>：日志会被发送到 Elasticsearch 或其他后端存储。</li><li><strong>展示</strong>：通过 Kibana 等工具进行日志的展示和查询。</li></ol><h3 id=2-使用-elk-stackelasticsearch-logstash-kibana收集-pod-日志>2. <strong>使用 ELK Stack（Elasticsearch, Logstash, Kibana）收集 Pod 日志</strong>
<a class=anchor href=#2-%e4%bd%bf%e7%94%a8-elk-stackelasticsearch-logstash-kibana%e6%94%b6%e9%9b%86-pod-%e6%97%a5%e5%bf%97>#</a></h3><p>ELK Stack（Elasticsearch、Logstash、Kibana）是日志管理的经典工具，广泛应用于收集、分析和可视化日志数据。</p><h4 id=步骤-1>步骤：
<a class=anchor href=#%e6%ad%a5%e9%aa%a4-1>#</a></h4><ol><li><p><strong>安装 Elasticsearch</strong>： 你需要先部署 Elasticsearch，用于存储日志数据。可以通过 Helm 或 YAML 文件进行安装。</p><p>示例安装 Elasticsearch：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>helm install elasticsearch elastic/elasticsearch
</span></span></code></pre></div></li><li><p><strong>安装 Logstash（可选）</strong>： Logstash 可以用来接收来自 Fluentd 的日志数据，并进行处理（例如解析和过滤）。如果你已经通过 Fluentd 直接将日志发送到 Elasticsearch，可以跳过这个步骤。</p><p>安装 Logstash：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>helm install logstash elastic/logstash
</span></span></code></pre></div></li><li><p><strong>配置 Fluentd 转发日志到 Elasticsearch</strong>： 你可以将 Fluentd 配置为将日志发送到 Elasticsearch，如前述步骤中所述。Fluentd 作为一个轻量级的日志收集器，在集群中处理日志转发，能够与 Logstash 和 Elasticsearch 集成。</p></li><li><p><strong>使用 Kibana 查询日志</strong>： 使用 Kibana 连接到 Elasticsearch，创建索引并进行日志查询。Kibana 提供了强大的日志分析和可视化功能，可以根据需求创建仪表盘，监控应用程序和 Kubernetes 集群的运行状况。</p></li></ol><h3 id=3-通过-fluentd-与-elk-集成>3. <strong>通过 Fluentd 与 ELK 集成</strong>
<a class=anchor href=#3-%e9%80%9a%e8%bf%87-fluentd-%e4%b8%8e-elk-%e9%9b%86%e6%88%90>#</a></h3><p>Fluentd 可以与 ELK Stack 集成，作为日志收集的前端工具，负责将日志从 Kubernetes 集群中的 Pod 转发到 Elasticsearch。</p><h4 id=配置示例>配置示例：
<a class=anchor href=#%e9%85%8d%e7%bd%ae%e7%a4%ba%e4%be%8b>#</a></h4><ol><li><p><strong>Fluentd 配置</strong>： 例如，将 Kubernetes 的日志通过 Fluentd 转发到 Elasticsearch。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#ae81ff>&lt;match kubernetes.**&gt;</span>
</span></span><span style=display:flex><span>  @<span style=color:#ae81ff>type elasticsearch</span>
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>host elasticsearch.example.com</span>
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>port 9200</span>
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>logstash_format true</span>
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>flush_interval 5s</span>
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>index_name fluentd-logs</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>&lt;/match&gt;</span>
</span></span></code></pre></div></li><li><p><strong>Elasticsearch 存储</strong>： Fluentd 会将日志传送到 Elasticsearch，ES 会将日志数据存储在指定的索引中（如 <code>fluentd-logs</code>）。</p></li><li><p><strong>Kibana 可视化</strong>： 在 Kibana 中，你可以使用索引模式来查看和分析日志。你可以创建图表、仪表盘和报警规则来分析和监控日志。</p></li></ol><h3 id=4-总结-1>4. <strong>总结</strong>
<a class=anchor href=#4-%e6%80%bb%e7%bb%93-1>#</a></h3><ul><li><strong>Fluentd 收集日志</strong>：Fluentd 是一个强大的日志收集工具，可以通过配置 DaemonSet 部署在 Kubernetes 集群中，收集并转发容器日志到 Elasticsearch 或其他存储系统。</li><li><strong>ELK Stack（Elasticsearch + Logstash + Kibana）</strong>：作为日志存储和可视化工具，ELK Stack 可以与 Fluentd 配合使用，将日志收集、存储和分析的功能结合在一起。</li><li><strong>Kubernetes 集群日志收集</strong>：通过 Fluentd 收集 Kubernetes Pod 的日志，然后推送到 Elasticsearch 存储，最后使用 Kibana 来查询和展示这些日志。</li></ul><p>这种组合提供了一种完整的日志收集和分析解决方案，能够帮助你高效地监控和排查 Kubernetes 集群中的应用日志。</p><h2 id=pod的标准输出日志在这哪>pod的标准输出日志在这哪
<a class=anchor href=#pod%e7%9a%84%e6%a0%87%e5%87%86%e8%be%93%e5%87%ba%e6%97%a5%e5%bf%97%e5%9c%a8%e8%bf%99%e5%93%aa>#</a></h2><p>Pod 的标准输出日志通常存储在 Kubernetes 节点上的容器日志文件中，而不是与网络相关的环境变量中。</p><p>在 Kubernetes 中，每个容器的日志都被保存为文件，这些日志文件通常存储在以下路径：</p><h3 id=pod-标准输出日志路径><strong>Pod 标准输出日志路径</strong>
<a class=anchor href=#pod-%e6%a0%87%e5%87%86%e8%be%93%e5%87%ba%e6%97%a5%e5%bf%97%e8%b7%af%e5%be%84>#</a></h3><p>日志文件通常存储在节点的 <code>/var/log/containers/</code> 目录中。具体路径格式如下：</p><pre tabindex=0><code>/var/log/containers/&lt;pod-name&gt;_&lt;namespace&gt;_&lt;container-name&gt;-&lt;container-id&gt;.log
</code></pre><p>例如，如果你有一个名为 <code>my-pod</code>，在 <code>default</code> 命名空间下，容器名称是 <code>my-container</code> 的 Pod，那么容器的日志文件可能会是：</p><pre tabindex=0><code>/var/log/containers/my-pod_default_my-container-&lt;container-id&gt;.log
</code></pre><h3 id=如何查看-pod-的标准输出日志><strong>如何查看 Pod 的标准输出日志</strong>
<a class=anchor href=#%e5%a6%82%e4%bd%95%e6%9f%a5%e7%9c%8b-pod-%e7%9a%84%e6%a0%87%e5%87%86%e8%be%93%e5%87%ba%e6%97%a5%e5%bf%97>#</a></h3><p>你可以使用 <code>kubectl logs</code> 命令直接查看 Pod 的日志：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl logs &lt;pod-name&gt; -n &lt;namespace&gt;
</span></span></code></pre></div><p>如果 Pod 中有多个容器，可以使用 <code>-c</code> 参数指定容器：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl logs &lt;pod-name&gt; -n &lt;namespace&gt; -c &lt;container-name&gt;
</span></span></code></pre></div><h3 id=日志收集与存储><strong>日志收集与存储</strong>
<a class=anchor href=#%e6%97%a5%e5%bf%97%e6%94%b6%e9%9b%86%e4%b8%8e%e5%ad%98%e5%82%a8>#</a></h3><p>在生产环境中，日志通常不会仅保留在本地磁盘上，而是通过日志收集工具（如 Fluentd、ELK Stack 等）进行集中化管理和存储。这些工具能够将日志从各个节点收集并发送到后端存储（如 Elasticsearch）中，方便日后查询和分析。</p><h3 id=总结-11>总结
<a class=anchor href=#%e6%80%bb%e7%bb%93-11>#</a></h3><ul><li><strong>Pod 的标准输出日志</strong> 通常存储在 <code>/var/log/containers/</code> 目录中。</li><li>使用 <code>kubectl logs</code> 命令可以直接查看 Pod 的日志。</li><li>如果你使用日志收集系统（如 Fluentd、ELK Stack），日志会被转发到集中式存储中进行管理和查询。</li></ul><p>如果你有特定的日志收集配置，日志可能通过其他方式（如 Fluentd）发送到集中式日志平台。</p><h6><a class=anchor href=#>#</a></h6></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#排查cpu使用率过高-linux>排查cpu使用率过高 linux</a><ul><li><a href=#1-查看当前-cpu-使用情况>1. <strong>查看当前 CPU 使用情况</strong></a></li><li><a href=#2-使用>2. <strong>使用 <code>ps</code> 查看具体进程</strong></a></li><li><a href=#3-检查系统负载>3. <strong>检查系统负载</strong></a></li><li><a href=#4-查看硬件性能>4. <strong>查看硬件性能</strong></a></li><li><a href=#5-查看-io-和进程状态>5. <strong>查看 I/O 和进程状态</strong></a></li><li><a href=#6-检查系统日志>6. <strong>检查系统日志</strong></a></li><li><a href=#7-分析具体进程>7. <strong>分析具体进程</strong></a></li><li><a href=#8-检查僵尸进程>8. <strong>检查僵尸进程</strong></a></li><li><a href=#9-优化配置>9. <strong>优化配置</strong></a></li><li><a href=#10-检查是否有恶意软件>10. <strong>检查是否有恶意软件</strong></a></li></ul></li><li><a href=#排查内存使用率过高-linux>排查内存使用率过高 linux</a><ul><li><a href=#1-查看系统内存使用情况>1. <strong>查看系统内存使用情况</strong></a></li><li><a href=#2-使用-1>2. <strong>使用 <code>top</code> 或 <code>htop</code> 查看内存占用进程</strong></a></li><li><a href=#3-使用>3. <strong>使用 <code>ps</code> 查看内存使用的前几个进程</strong></a></li><li><a href=#4-查看内存的具体细节>4. <strong>查看内存的具体细节（<code>vmstat</code>）</strong></a></li><li><a href=#5-查看交换空间的使用情况>5. <strong>查看交换空间的使用情况</strong></a></li><li><a href=#6-检查是否有内存泄漏>6. <strong>检查是否有内存泄漏</strong></a></li><li><a href=#7-使用>7. <strong>使用 <code>smem</code> 查看内存使用情况</strong></a></li><li><a href=#8-查看缓存和缓冲区的使用情况>8. <strong>查看缓存和缓冲区的使用情况</strong></a></li><li><a href=#9-分析内存的分配情况>9. <strong>分析内存的分配情况（<code>/proc/meminfo</code>）</strong></a></li><li><a href=#10-检查进程的内存使用情况>10. <strong>检查进程的内存使用情况（<code>pmap</code>）</strong></a></li><li><a href=#11-检查系统的-oom-out-of-memory-事件>11. <strong>检查系统的 OOM (Out of Memory) 事件</strong></a></li><li><a href=#12-使用>12. <strong>使用 <code>lsof</code> 查找打开的文件</strong></a></li><li><a href=#13-内存优化和限制>13. <strong>内存优化和限制</strong></a></li></ul></li><li><a href=#echo-devmappervgdocker-lvapp-apps--------------------xfs----rwpquota--------0-0--etcfstabpquota-啥意思-不加这个参数会导致docker容器根磁盘限额失效吗或者说导致docker起不来-导致kubelet起不来>echo &ldquo;#/dev/mapper/vg&ndash;docker-lvapp /apps xfs rw,pquota 0 0&rdquo; &#187; /etc/fstab，pquota 啥意思 不加这个参数会导致docker容器根磁盘限额失效吗，或者说导致docker起不来 导致kubelet起不来</a><ul><li><a href=#1-配额的作用>1. <strong>配额的作用</strong></a></li><li><a href=#2-不加>2. <strong>不加 <code>pquota</code> 会有什么影响？</strong></a></li><li><a href=#3-可能的风险>3. <strong>可能的风险</strong></a></li><li><a href=#4-总结>4. <strong>总结</strong></a></li><li><a href=#1-检查挂载是否正确>1. <strong>检查挂载是否正确</strong></a></li><li><a href=#2-检查磁盘配额是否启用>2. <strong>检查磁盘配额是否启用</strong></a></li><li><a href=#3-检查系统日志>3. <strong>检查系统日志</strong></a></li><li><a href=#4-检查-docker-和-kubelet-配置>4. <strong>检查 Docker 和 Kubelet 配置</strong></a></li><li><a href=#5-确认磁盘是否满>5. <strong>确认磁盘是否满</strong></a></li><li><a href=#6-尝试移除>6. <strong>尝试移除 <code>pquota</code> 选项</strong></a></li><li><a href=#7-重新启动-docker-和-kubelet>7. <strong>重新启动 Docker 和 Kubelet</strong></a></li></ul></li><li><a href=#修改calico的默认的vxlan的端口号>修改calico的默认的vxlan的端口号</a><ul><li><a href=#1-修改-calico-配置>1. <strong>修改 Calico 配置</strong></a></li><li><a href=#2-验证配置>2. <strong>验证配置</strong></a></li><li><a href=#3-注意事项>3. <strong>注意事项</strong></a></li><li><a href=#修改-felix-配置来更改-vxlan-端口号>修改 Felix 配置来更改 VXLAN 端口号</a></li><li><a href=#总结>总结</a></li></ul></li><li><a href=#没有启用配额但docker的daemonjson的opt有限制磁盘大小的参数docker起不来的吧>没有启用配额，但docker的daemon.json的opt有限制磁盘大小的参数，docker起不来的吧</a><ul><li><a href=#1-daemonjson>1. <strong><code>daemon.json</code> 配置示例</strong></a></li><li><a href=#2-可能的错误>2. <strong>可能的错误</strong></a></li><li><a href=#3-如何避免-docker-启动失败>3. <strong>如何避免 Docker 启动失败</strong></a></li><li><a href=#4-解决方法>4. <strong>解决方法</strong></a></li><li><a href=#5-排查-docker-启动问题>5. <strong>排查 Docker 启动问题</strong></a></li></ul></li><li><a href=#单etcd单master拓展为3master3etcdmaster节点挂上vip做高可用证书重新生成etcd之前数据保留>单etcd单master拓展为3master3etcd，master节点挂上vip，做高可用，证书重新生成，etcd之前数据保留</a><ul><li><a href=#1-准备工作>1. <strong>准备工作</strong></a></li><li><a href=#2-部署-3-master-节点>2. <strong>部署 3 Master 节点</strong></a></li><li><a href=#3-部署-3-etcd-节点>3. <strong>部署 3 ETCD 节点</strong></a></li><li><a href=#4-更新证书>4. <strong>更新证书</strong></a></li><li><a href=#5-恢复-etcd-数据>5. <strong>恢复 ETCD 数据</strong></a></li><li><a href=#6-验证集群>6. <strong>验证集群</strong></a></li><li><a href=#总结-1>总结</a></li></ul></li><li><a href=#跨网段的机器组成k8s集群不同网段机器上的pod之间无法相互访问用calico的vxlan模式修改默认的vxlan的端口号因为之前的4789被物理网关设备占用了>跨网段的机器组成k8s集群，不同网段机器上的pod之间无法相互访问，用calico的vxlan模式，修改默认的vxlan的端口号，因为之前的4789被物理网关设备占用了</a><ul><li><a href=#步骤-1-修改-felix-配置修改-vxlan-端口>步骤 1: 修改 Felix 配置（修改 VXLAN 端口）</a></li><li><a href=#步骤-2-修改-kubernetes-api-server-和节点配置>步骤 2: 修改 Kubernetes API Server 和节点配置</a></li><li><a href=#步骤-3-验证配置>步骤 3: 验证配置</a></li><li><a href=#总结-2>总结</a></li></ul></li><li><a href=#envoy的版本过低导致流量被拦截升级版本解决了>envoy的版本过低导致流量被拦截，升级版本解决了</a><ul><li><a href=#1-过时的协议支持>1. <strong>过时的协议支持</strong></a></li><li><a href=#2-安全性问题>2. <strong>安全性问题</strong></a></li><li><a href=#3-代理和路由问题>3. <strong>代理和路由问题</strong></a></li><li><a href=#4-性能优化和-bug-修复>4. <strong>性能优化和 bug 修复</strong></a></li><li><a href=#如何升级-envoy>如何升级 Envoy</a></li><li><a href=#总结-3>总结</a></li></ul></li><li><a href=#节点noteready-恢复>节点noteready 恢复</a><ul><li><a href=#1-查看节点状态>1. <strong>查看节点状态</strong></a></li><li><a href=#2-检查-kubelet-状态>2. <strong>检查 Kubelet 状态</strong></a></li><li><a href=#3-检查网络配置>3. <strong>检查网络配置</strong></a></li><li><a href=#4-资源使用情况>4. <strong>资源使用情况</strong></a></li><li><a href=#5-检查-api-server-与节点连接>5. <strong>检查 API Server 与节点连接</strong></a></li><li><a href=#6-重新加入节点到集群>6. <strong>重新加入节点到集群</strong></a></li><li><a href=#7-检查-kubelet-配置文件>7. <strong>检查 Kubelet 配置文件</strong></a></li><li><a href=#8-节点恢复后的验证>8. <strong>节点恢复后的验证</strong></a></li><li><a href=#总结-4>总结</a></li></ul></li><li><a href=#数据库磁盘使用超过85导致数据库只读>数据库磁盘使用超过85%导致数据库只读</a><ul><li><a href=#解决方案>解决方案</a></li></ul></li><li><a href=#prometheus指标拆分解决oom的问题>prometheus指标拆分解决oom的问题</a><ul><li><a href=#1-拆分大型指标>1. <strong>拆分大型指标</strong></a></li><li><a href=#2-限制-prometheus-存储使用>2. <strong>限制 Prometheus 存储使用</strong></a></li><li><a href=#3-调整指标采集频率>3. <strong>调整指标采集频率</strong></a></li><li><a href=#4-分布式-prometheus-部署sharding>4. <strong>分布式 Prometheus 部署（Sharding）</strong></a></li><li><a href=#5-优化查询>5. <strong>优化查询</strong></a></li><li><a href=#6-使用外部存储远程存储>6. <strong>使用外部存储（远程存储）</strong></a></li><li><a href=#总结-6>总结</a></li></ul></li><li><a href=#prometheus的告警延迟问题>prometheus的告警延迟问题</a><ul><li><a href=#1-告警规则的评估间隔>1. <strong>告警规则的评估间隔</strong></a></li><li><a href=#2-告警规则的评估条件过于宽松>2. <strong>告警规则的评估条件过于宽松</strong></a></li><li><a href=#3-prometheus-数据采集频率>3. <strong>Prometheus 数据采集频率</strong></a></li><li><a href=#4-alertmanager-配置问题>4. <strong>Alertmanager 配置问题</strong></a></li><li><a href=#5-prometheus-存储问题>5. <strong>Prometheus 存储问题</strong></a></li><li><a href=#6-复杂的-prometheus-查询>6. <strong>复杂的 Prometheus 查询</strong></a></li><li><a href=#7-网络延迟或-dns-解析问题>7. <strong>网络延迟或 DNS 解析问题</strong></a></li><li><a href=#8-alertmanager-缓存问题>8. <strong>Alertmanager 缓存问题</strong></a></li><li><a href=#总结-7>总结</a></li></ul></li><li><a href=#告警抑制和收敛>告警抑制和收敛</a><ul><li><a href=#1-告警抑制alert-suppression>1. <strong>告警抑制（Alert Suppression）</strong></a></li><li><a href=#2-告警收敛alert-aggregation>2. <strong>告警收敛（Alert Aggregation）</strong></a></li><li><a href=#3-告警收敛与告警抑制的区别>3. <strong>告警收敛与告警抑制的区别</strong></a></li><li><a href=#4-告警收敛和抑制的配置实践>4. <strong>告警收敛和抑制的配置实践</strong></a></li><li><a href=#总结-8>总结</a></li></ul></li><li><a href=#业务pod的告警规则>业务pod的告警规则</a><ul><li><a href=#1-pod-资源使用情况>1. <strong>Pod 资源使用情况</strong></a></li><li><a href=#2-pod-健康检查失败>2. <strong>Pod 健康检查失败</strong></a></li><li><a href=#3-pod-容器的重启>3. <strong>Pod 容器的重启</strong></a></li><li><a href=#4-pod-调度和资源限制>4. <strong>Pod 调度和资源限制</strong></a></li><li><a href=#5-网络延迟或连接问题>5. <strong>网络延迟或连接问题</strong></a></li><li><a href=#总结-9>总结</a></li><li><a href=#1-cpu-使用率告警>1. <strong>CPU 使用率告警</strong></a></li><li><a href=#2-内存使用率告警>2. <strong>内存使用率告警</strong></a></li><li><a href=#3-pod-失效告警>3. <strong>Pod 失效告警</strong></a></li><li><a href=#4-pod-重启告警>4. <strong>Pod 重启告警</strong></a></li></ul></li><li><a href=#请求成功率的监控怎么做的>请求成功率的监控怎么做的</a><ul><li><a href=#1-监控请求成功率的基础指标>1. <strong>监控请求成功率的基础指标</strong></a></li><li><a href=#2-计算请求成功率>2. <strong>计算请求成功率</strong></a></li><li><a href=#3-设置告警规则>3. <strong>设置告警规则</strong></a></li><li><a href=#4-监控失败的请求>4. <strong>监控失败的请求</strong></a></li><li><a href=#5-高级监控与告警>5. <strong>高级监控与告警</strong></a></li><li><a href=#总结-10>总结</a></li></ul></li><li><a href=#接口探活呢>接口探活呢</a><ul><li><a href=#1-暴露健康检查端点>1. <strong>暴露健康检查端点</strong></a></li><li><a href=#2-暴露健康检查指标>2. <strong>暴露健康检查指标</strong></a></li><li><a href=#3-通过-prometheus-查询健康检查状态>3. <strong>通过 Prometheus 查询健康检查状态</strong></a></li><li><a href=#4-设置告警规则>4. <strong>设置告警规则</strong></a></li><li><a href=#5-使用-kubernetes-探针livenessreadiness>5. <strong>使用 Kubernetes 探针（Liveness/Readiness）</strong></a></li><li><a href=#6-总结>6. <strong>总结</strong></a></li></ul></li><li><a href=#一个微服务的业务流量通过外部进入集群内部的过程>一个微服务的业务，流量通过外部进入集群内部的过程</a><ul><li><a href=#1-外部流量的接入>1. <strong>外部流量的接入</strong></a></li><li><a href=#2-ingress-controller-处理流量>2. <strong>Ingress Controller 处理流量</strong></a></li><li><a href=#3-服务发现与流量路由>3. <strong>服务发现与流量路由</strong></a></li><li><a href=#4-内部流量的路由与负载均衡>4. <strong>内部流量的路由与负载均衡</strong></a></li><li><a href=#5-服务间通信>5. <strong>服务间通信</strong></a></li><li><a href=#6-安全控制与认证>6. <strong>安全控制与认证</strong></a></li><li><a href=#7-监控与日志收集>7. <strong>监控与日志收集</strong></a></li><li><a href=#8-总结>8. <strong>总结</strong></a></li></ul></li><li><a href=#elkfluentd-怎么收集pod的日志>ELK/fluentd 怎么收集pod的日志</a><ul><li><a href=#1-使用-fluentd-收集-pod-日志>1. <strong>使用 Fluentd 收集 Pod 日志</strong></a></li><li><a href=#2-使用-elk-stackelasticsearch-logstash-kibana收集-pod-日志>2. <strong>使用 ELK Stack（Elasticsearch, Logstash, Kibana）收集 Pod 日志</strong></a></li><li><a href=#3-通过-fluentd-与-elk-集成>3. <strong>通过 Fluentd 与 ELK 集成</strong></a></li><li><a href=#4-总结-1>4. <strong>总结</strong></a></li></ul></li><li><a href=#pod的标准输出日志在这哪>pod的标准输出日志在这哪</a><ul><li><a href=#pod-标准输出日志路径><strong>Pod 标准输出日志路径</strong></a></li><li><a href=#如何查看-pod-的标准输出日志><strong>如何查看 Pod 的标准输出日志</strong></a></li><li><a href=#日志收集与存储><strong>日志收集与存储</strong></a></li><li><a href=#总结-11>总结</a></li></ul></li></ul></nav></div></aside></main></body></html>