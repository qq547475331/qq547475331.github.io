<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content='/*
Copyright 2014 The Kubernetes Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package scheduler

import (
	"context"
	"errors"
	"fmt"
	"time"

	v1 "k8s.io/api/core/v1"
	"k8s.io/apimachinery/pkg/api/meta"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/util/wait"
	utilfeature "k8s.io/apiserver/pkg/util/feature"
	"k8s.io/client-go/dynamic/dynamicinformer"
	"k8s.io/client-go/informers"
	coreinformers "k8s.io/client-go/informers/core/v1"
	clientset "k8s.io/client-go/kubernetes"
	restclient "k8s.io/client-go/rest"
	"k8s.io/client-go/tools/cache"
	configv1 "k8s.io/kube-scheduler/config/v1"
	"k8s.io/kubernetes/pkg/features"
	schedulerapi "k8s.io/kubernetes/pkg/scheduler/apis/config"
	"k8s.io/kubernetes/pkg/scheduler/apis/config/scheme"
	"k8s.io/kubernetes/pkg/scheduler/framework"
	"k8s.io/kubernetes/pkg/scheduler/framework/parallelize"
	frameworkplugins "k8s.io/kubernetes/pkg/scheduler/framework/plugins"
	"k8s.io/kubernetes/pkg/scheduler/framework/plugins/noderesources"
	frameworkruntime "k8s.io/kubernetes/pkg/scheduler/framework/runtime"
	internalcache "k8s.io/kubernetes/pkg/scheduler/internal/cache"
	cachedebugger "k8s.io/kubernetes/pkg/scheduler/internal/cache/debugger"
	internalqueue "k8s.io/kubernetes/pkg/scheduler/internal/queue"
	"k8s.io/kubernetes/pkg/scheduler/metrics"
	"k8s.io/kubernetes/pkg/scheduler/profile"
)

const (
	// Duration the scheduler will wait before expiring an assumed pod.
	// See issue #106361 for more details about this parameter and its value.
	durationToExpireAssumedPod time.Duration = 0
)

// ErrNoNodesAvailable is used to describe the error that no nodes available to schedule pods.
var ErrNoNodesAvailable = fmt.Errorf("no nodes available to schedule pods")

// Scheduler watches for new unscheduled pods. It attempts to find
// nodes that they fit on and writes bindings back to the api server.
type Scheduler struct {
	// It is expected that changes made via Cache will be observed
	// by NodeLister and Algorithm.
	Cache internalcache.Cache

	Extenders []framework.Extender

	// NextPod should be a function that blocks until the next pod
	// is available. We don&#39;t use a channel for this, because scheduling
	// a pod may take some amount of time and we don&#39;t want pods to get
	// stale while they sit in a channel.
	NextPod func(logger klog.Logger) (*framework.QueuedPodInfo, error)

	// FailureHandler is called upon a scheduling failure.
	FailureHandler FailureHandlerFn

	// SchedulePod tries to schedule the given pod to one of the nodes in the node list.
	// Return a struct of ScheduleResult with the name of suggested host on success,
	// otherwise will return a FitError with reasons.
	SchedulePod func(ctx context.Context, fwk framework.Framework, state *framework.CycleState, pod *v1.Pod) (ScheduleResult, error)

	// Close this to shut down the scheduler.
	StopEverything <-chan struct{}

	// SchedulingQueue holds pods to be scheduled
	SchedulingQueue internalqueue.SchedulingQueue

	// Profiles are the scheduling profiles.
	Profiles profile.Map

	client clientset.Interface

	nodeInfoSnapshot *internalcache.Snapshot

	percentageOfNodesToScore int32

	nextStartNodeIndex int

	// logger *must* be initialized when creating a Scheduler,
	// otherwise logging functions will access a nil sink and
	// panic.
	logger klog.Logger

	// registeredHandlers contains the registrations of all handlers. It&#39;s used to check if all handlers have finished syncing before the scheduling cycles start.
	registeredHandlers []cache.ResourceEventHandlerRegistration
}

//该Go代码定义了一个名为Scheduler的结构体，用于管理Pod的调度过程。
//它包含多个字段，用于配置调度器的行为，
//例如Cache、Extenders、NextPod、FailureHandler、SchedulePod、StopEverything、SchedulingQueue、Profiles、
//client、nodeInfoSnapshot、percentageOfNodesToScore、nextStartNodeIndex、logger和registeredHandlers。
//这些字段的作用如下：
//- Cache：用于存储集群的状态信息， 以便Scheduler能够快速访问。
//- Extenders：是一组扩展程序，可以自定义Pod的调度逻辑。
//- NextPod：是一个函数，用于获取下一个待调度的Pod。 -
//FailureHandler：是一个函数，用于处理调度失败的情况。
//- SchedulePod：是一个函数，用于尝试将给定的Pod调度到节点列表中的一个节点上。
//成功时返回建议的主机名，失败时返回FitError错误。
//- StopEverything：是一个通道，用于关闭Scheduler。
//- SchedulingQueue：用于存储待调度的Pod。
//- Profiles：是一组调度配置文件，用于定义不同的调度策略。
//- client：是用于与Kubernetes API服务器交互的客户端。
//- nodeInfoSnapshot：是集群节点的快照，包含节点的状态信息。
//- percentageOfNodesToScore：用于指定参与评分的节点百分比。
//- nextStartNodeIndex：用于指定下一个开始调度的节点索引。
//- logger：用于记录日志信息。
//- registeredHandlers：包含所有处理器的注册信息，用于检查处理器是否已同步完成。
//总的来说，这个Scheduler结构体定义了一个调度器所需的各种配置和功能，
//包括节点和Pod的缓存、扩展程序、日志记录、失败处理、调度逻辑等。它提供了一种灵活的方式来定制和管理Pod的调度过程。

func (sched *Scheduler) applyDefaultHandlers() {
	sched.SchedulePod = sched.schedulePod
	sched.FailureHandler = sched.handleSchedulingFailure
}

//该函数为一个go语言函数，作用是为Scheduler结构体实例sched设置默认的处理函数。
//具体操作是将sched.schedulePod赋值给sched.SchedulePod，将sched.handleSchedulingFailure赋值给sched.FailureHandler。

type schedulerOptions struct {
	componentConfigVersion string
	kubeConfig             *restclient.Config
	// Overridden by profile level percentageOfNodesToScore if set in v1.
	percentageOfNodesToScore          int32
	podInitialBackoffSeconds          int64
	podMaxBackoffSeconds              int64
	podMaxInUnschedulablePodsDuration time.Duration
	// Contains out-of-tree plugins to be merged with the in-tree registry.
	frameworkOutOfTreeRegistry frameworkruntime.Registry
	profiles                   []schedulerapi.KubeSchedulerProfile
	extenders                  []schedulerapi.Extender
	frameworkCapturer          FrameworkCapturer
	parallelism                int32
	applyDefaultProfile        bool
}

//该代码定义了一个名为schedulerOptions的结构体，用于配置调度器的参数。
//其中包括了组件配置版本、kubeconfig配置、节点打分百分比、Pod初始退避时间、Pod最大退避时间、
//Pod在不可调度状态下的最大持续时间、外部插件注册表、调度器配置文件、扩展器、框架捕获器和并行度等参数。

// Option configures a Scheduler
type Option func(*schedulerOptions)

// ScheduleResult represents the result of scheduling a pod.
type ScheduleResult struct {
	// Name of the selected node.
	SuggestedHost string
	// The number of nodes the scheduler evaluated the pod against in the filtering
	// phase and beyond.
	// Note that it contains the number of nodes that filtered out by PreFilterResult.
	EvaluatedNodes int
	// The number of nodes out of the evaluated ones that fit the pod.
	FeasibleNodes int
	// The nominating info for scheduling cycle.
	nominatingInfo *framework.NominatingInfo
}

//这段代码定义了Go语言中的两个类型和一个函数：
//1. Option 是一个函数类型，其参数为一个 *schedulerOptions 指针，用于配置一个 Scheduler。
//2. ScheduleResult 是一个结构体类型，代表调度 Pod 的结果。它包含以下字段：
//- SuggestedHost：被选中的节点名称。
//- EvaluatedNodes：在过滤阶段及之后对 Pod 进行评估的节点数量。
//- FeasibleNodes：在评估节点中适合 Pod 的节点数量。
//- nominatingInfo：提名信息，用于记录调度周期的提名情况。
//这段代码没有定义函数的具体实现，因此无法对其复杂度进行评估。

// WithComponentConfigVersion sets the component config version to the
// KubeSchedulerConfiguration version used. The string should be the full
// scheme group/version of the external type we converted from (for example
// "kubescheduler.config.k8s.io/v1")
func WithComponentConfigVersion(apiVersion string) Option {
	return func(o *schedulerOptions) {
		o.componentConfigVersion = apiVersion
	}
}

// WithKubeConfig sets the kube config for Scheduler.
func WithKubeConfig(cfg *restclient.Config) Option {
	return func(o *schedulerOptions) {
		o.kubeConfig = cfg
	}
}

// WithProfiles sets profiles for Scheduler. By default, there is one profile
// with the name "default-scheduler".
func WithProfiles(p ...schedulerapi.KubeSchedulerProfile) Option {
	return func(o *schedulerOptions) {
		o.profiles = p
		o.applyDefaultProfile = false
	}
}

// WithParallelism sets the parallelism for all scheduler algorithms. Default is 16.
func WithParallelism(threads int32) Option {
	return func(o *schedulerOptions) {
		o.parallelism = threads
	}
}

// WithPercentageOfNodesToScore sets percentageOfNodesToScore for Scheduler.
// The default value of 0 will use an adaptive percentage: 50 - (num of nodes)/125.
func WithPercentageOfNodesToScore(percentageOfNodesToScore *int32) Option {
	return func(o *schedulerOptions) {
		if percentageOfNodesToScore != nil {
			o.percentageOfNodesToScore = *percentageOfNodesToScore
		}
	}
}

//这些函数是Go语言中的函数，用于设置调度器（scheduler）的配置选项。
//- WithComponentConfigVersion 函数用于设置组件配置的版本。
//它接受一个字符串参数 apiVersion，该参数应该是外部类型转换而来的完整方案组/版本（例如 "kubescheduler.config.k8s.io/v1"）。
//- WithKubeConfig 函数用于设置调度器的kube配置。
//- WithProfiles 函数用于设置调度器的配置文件。默认情况下，有一个名为 "default-scheduler" 的配置文件。
//- WithParallelism 函数用于设置所有调度算法的并行度。默认值为16。
//- WithPercentageOfNodesToScore 函数用于设置Scheduler的 percentageOfNodesToScore。
//默认值为0，使用自适应百分比：50 - (节点数)/125。

// WithFrameworkOutOfTreeRegistry sets the registry for out-of-tree plugins. Those plugins
// will be appended to the default registry.
func WithFrameworkOutOfTreeRegistry(registry frameworkruntime.Registry) Option {
	return func(o *schedulerOptions) {
		o.frameworkOutOfTreeRegistry = registry
	}
}

// WithPodInitialBackoffSeconds sets podInitialBackoffSeconds for Scheduler, the default value is 1
func WithPodInitialBackoffSeconds(podInitialBackoffSeconds int64) Option {
	return func(o *schedulerOptions) {
		o.podInitialBackoffSeconds = podInitialBackoffSeconds
	}
}

// WithPodMaxBackoffSeconds sets podMaxBackoffSeconds for Scheduler, the default value is 10
func WithPodMaxBackoffSeconds(podMaxBackoffSeconds int64) Option {
	return func(o *schedulerOptions) {
		o.podMaxBackoffSeconds = podMaxBackoffSeconds
	}
}

// WithPodMaxInUnschedulablePodsDuration sets podMaxInUnschedulablePodsDuration for PriorityQueue.
func WithPodMaxInUnschedulablePodsDuration(duration time.Duration) Option {
	return func(o *schedulerOptions) {
		o.podMaxInUnschedulablePodsDuration = duration
	}
}

//这些函数是Go语言中的函数，用于设置调度器的配置选项。
//- WithFrameworkOutOfTreeRegistry 函数用于设置外部插件的注册表，将这些插件追加到默认的注册表中。
//- WithPodInitialBackoffSeconds 函数用于设置 Scheduler 的 podInitialBackoffSeconds，其默认值为 1。
//- WithPodMaxBackoffSeconds 函数用于设置 Scheduler 的 podMaxBackoffSeconds，其默认值为 10。
//- WithPodMaxInUnschedulablePodsDuration 函数用于设置 PriorityQueue 的 podMaxInUnschedulablePodsDuration。

// WithExtenders sets extenders for the Scheduler
func WithExtenders(e ...schedulerapi.Extender) Option {
	return func(o *schedulerOptions) {
		o.extenders = e
	}
}

//该函数为Go语言中的函数，名为WithExtenders，接收一个变长参数e，类型为schedulerapi.Extender的切片。
//函数返回一个Option类型的函数，该函数接收一个schedulerOptions类型的指针o，将e赋值给o.extenders。

// FrameworkCapturer is used for registering a notify function in building framework.
type FrameworkCapturer func(schedulerapi.KubeSchedulerProfile)

// WithBuildFrameworkCapturer sets a notify function for getting buildFramework details.
func WithBuildFrameworkCapturer(fc FrameworkCapturer) Option {
	return func(o *schedulerOptions) {
		o.frameworkCapturer = fc
	}
}

//该函数是一个名为WithBuildFrameworkCapturer的函数，
//它接收一个FrameworkCapturer类型的参数fc，并返回一个Option类型的函数。
//返回的函数将传入的fc赋值给o.frameworkCapturer。

var defaultSchedulerOptions = schedulerOptions{
	percentageOfNodesToScore:          schedulerapi.DefaultPercentageOfNodesToScore,
	podInitialBackoffSeconds:          int64(internalqueue.DefaultPodInitialBackoffDuration.Seconds()),
	podMaxBackoffSeconds:              int64(internalqueue.DefaultPodMaxBackoffDuration.Seconds()),
	podMaxInUnschedulablePodsDuration: internalqueue.DefaultPodMaxInUnschedulablePodsDuration,
	parallelism:                       int32(parallelize.DefaultParallelism),
	// Ideally we would statically set the default profile here, but we can&#39;t because
	// creating the default profile may require testing feature gates, which may get
	// set dynamically in tests. Therefore, we delay creating it until New is actually
	// invoked.
	applyDefaultProfile: true,
}

//这段Go代码定义了一个名为defaultSchedulerOptions的变量，它是一个schedulerOptions类型的结构体。
//这个结构体用于设置调度器的默认选项，包括以下字段：
//- percentageOfNodesToScore：表示要进行打分的节点的百分比，默认值为schedulerapi.DefaultPercentageOfNodesToScore。
//- podInitialBackoffSeconds：表示Pod初始退避时间的秒数，默认值为internalqueue.DefaultPodInitialBackoffDuration的秒数。
//- podMaxBackoffSeconds：表示Pod最大退避时间的秒数，默认值为internalqueue.DefaultPodMaxBackoffDuration的秒数。
//- podMaxInUnschedulablePodsDuration：表示Pod在不可调度状态下允许的最大持续时间，
//默认值为internalqueue.DefaultPodMaxInUnschedulablePodsDuration。
//- parallelism：表示并行处理任务的数量，默认值为parallelize.DefaultParallelism。
//- applyDefaultProfile：表示是否应用默认的调度配置文件，默认值为true。
//这些选项用于配置调度器的行为，例如决定多少节点需要进行打分、设置Pod的退避策略等。

// New returns a Scheduler
func New(ctx context.Context,
	client clientset.Interface,
	informerFactory informers.SharedInformerFactory,
	dynInformerFactory dynamicinformer.DynamicSharedInformerFactory,
	recorderFactory profile.RecorderFactory,
	opts ...Option) (*Scheduler, error) {

	logger := klog.FromContext(ctx)
	stopEverything := ctx.Done()

	options := defaultSchedulerOptions
	for _, opt := range opts {
		opt(&amp;options)
	}
	//该函数名为New，返回一个Scheduler类型指针和一个错误类型。
	//函数参数包括上下文ctx、客户端接口client、共享informer工厂informerFactory、动态共享informer工厂dynInformerFactory、
	//记录器工厂recorderFactory以及可选参数opts。
	//函数首先从上下文中获取日志记录器logger和停止信号stopEverything。
	//然后定义默认的调度器选项options，并遍历opts对options进行配置。
	//最后返回一个Scheduler实例和错误类型。

	if options.applyDefaultProfile {
		var versionedCfg configv1.KubeSchedulerConfiguration
		scheme.Scheme.Default(&amp;versionedCfg)
		cfg := schedulerapi.KubeSchedulerConfiguration{}
		if err := scheme.Scheme.Convert(&amp;versionedCfg, &amp;cfg, nil); err != nil {
			return nil, err
		}
		options.profiles = cfg.Profiles
	}
	//这段Go代码主要功能是应用默认配置到调度器配置中。
	//首先，它创建了一个configv1.KubeSchedulerConfiguration类型的变量versionedCfg，
	//并使用scheme.Scheme.Default函数为其应用默认值。
	//接着，它创建了一个schedulerapi.KubeSchedulerConfiguration类型的变量cfg，
	//并将versionedCfg中的值通过scheme.Scheme.Convert函数转换并赋值给cfg。
	//最后，将cfg.Profiles赋值给options.profiles。

	registry := frameworkplugins.NewInTreeRegistry()
	if err := registry.Merge(options.frameworkOutOfTreeRegistry); err != nil {
		return nil, err
	}

	metrics.Register()

	extenders, err := buildExtenders(logger, options.extenders, options.profiles)
	if err != nil {
		return nil, fmt.Errorf("couldn&#39;t build extenders: %w", err)
	}

	podLister := informerFactory.Core().V1().Pods().Lister()
	nodeLister := informerFactory.Core().V1().Nodes().Lister()

	snapshot := internalcache.NewEmptySnapshot()
	metricsRecorder := metrics.NewMetricsAsyncRecorder(1000, time.Second, stopEverything)

	profiles, err := profile.NewMap(ctx, options.profiles, registry, recorderFactory,
		frameworkruntime.WithComponentConfigVersion(options.componentConfigVersion),
		frameworkruntime.WithClientSet(client),
		frameworkruntime.WithKubeConfig(options.kubeConfig),
		frameworkruntime.WithInformerFactory(informerFactory),
		frameworkruntime.WithSnapshotSharedLister(snapshot),
		frameworkruntime.WithCaptureProfile(frameworkruntime.CaptureProfile(options.frameworkCapturer)),
		frameworkruntime.WithParallelism(int(options.parallelism)),
		frameworkruntime.WithExtenders(extenders),
		frameworkruntime.WithMetricsRecorder(metricsRecorder),
	)
	if err != nil {
		return nil, fmt.Errorf("initializing profiles: %v", err)
	}
	//这段Go代码的功能是初始化一个调度器配置。
	//1. 首先创建一个in-tree注册表registry。
	//2. 将options.frameworkOutOfTreeRegistry合并到registry中，如果合并失败则返回错误。
	//3. 注册指标收集。
	//4. 构建扩展程序extenders，如果构建失败则返回错误。
	//5. 获取Pod和Node的列表器。
	//6. 创建一个空的快照snapshot。
	//7. 创建一个异步指标记录器metricsRecorder。
	//8. 使用给定的参数初始化调度器配置profiles，如果初始化失败则返回错误。
	//其中，buildExtenders函数用于构建扩展程序，informFactory是一个informers工厂，用于创建Pod和Node的列表器。internalcache.NewEmptySnapshot()创建一个空的快照，metrics.NewMetricsAsyncRecorder创建一个异步指标记录器。profile.NewMap用于初始化调度器配置。

	if len(profiles) == 0 {
		return nil, errors.New("at least one profile is required")
	}

	preEnqueuePluginMap := make(map[string][]framework.PreEnqueuePlugin)
	queueingHintsPerProfile := make(internalqueue.QueueingHintMapPerProfile)
	for profileName, profile := range profiles {
		preEnqueuePluginMap[profileName] = profile.PreEnqueuePlugins()
		queueingHintsPerProfile[profileName] = buildQueueingHintMap(profile.EnqueueExtensions())
	}

	podQueue := internalqueue.NewSchedulingQueue(
		profiles[options.profiles[0].SchedulerName].QueueSortFunc(),
		informerFactory,
		internalqueue.WithPodInitialBackoffDuration(time.Duration(options.podInitialBackoffSeconds)*time.Second),
		internalqueue.WithPodMaxBackoffDuration(time.Duration(options.podMaxBackoffSeconds)*time.Second),
		internalqueue.WithPodLister(podLister),
		internalqueue.WithPodMaxInUnschedulablePodsDuration(options.podMaxInUnschedulablePodsDuration),
		internalqueue.WithPreEnqueuePluginMap(preEnqueuePluginMap),
		internalqueue.WithQueueingHintMapPerProfile(queueingHintsPerProfile),
		internalqueue.WithPluginMetricsSamplePercent(pluginMetricsSamplePercent),
		internalqueue.WithMetricsRecorder(*metricsRecorder),
	)

	for _, fwk := range profiles {
		fwk.SetPodNominator(podQueue)
	}

	schedulerCache := internalcache.New(ctx, durationToExpireAssumedPod)

	// Setup cache debugger.
	debugger := cachedebugger.New(nodeLister, podLister, schedulerCache, podQueue)
	debugger.ListenForSignal(ctx)

	sched := &amp;Scheduler{
		Cache:                    schedulerCache,
		client:                   client,
		nodeInfoSnapshot:         snapshot,
		percentageOfNodesToScore: options.percentageOfNodesToScore,
		Extenders:                extenders,
		StopEverything:           stopEverything,
		SchedulingQueue:          podQueue,
		Profiles:                 profiles,
		logger:                   logger,
	}
	sched.NextPod = podQueue.Pop
	sched.applyDefaultHandlers()

	if err = addAllEventHandlers(sched, informerFactory, dynInformerFactory, unionedGVKs(queueingHintsPerProfile)); err != nil {
		return nil, fmt.Errorf("adding event handlers: %w", err)
	}

	return sched, nil
}

//该函数主要实现了以下功能：
//1. 检查传入的profiles是否为空，如果为空则返回错误。
//2. 根据profiles创建preEnqueuePluginMap和queueingHintsPerProfile。
//3. 使用profiles中指定的SchedulerName创建一个SchedulingQueue对象，该对象用于管理待调度的Pod。
//4. 为每个profile设置PodNominator。
//5. 创建一个schedulerCache对象，用于缓存节点和Pod的信息。
//6. 创建一个debugger对象，用于调试缓存。
//7. 创建一个Scheduler对象，并设置其属性。
//8. 设置Scheduler的NextPod方法。
//9. 应用默认的处理程序。
//10. 添加所有事件处理程序。
//综上所述，该函数的主要功能是创建一个Scheduler对象，并对其进行初始化。

// defaultQueueingHintFn is the default queueing hint function.
// It always returns Queue as the queueing hint.
var defaultQueueingHintFn = func(_ klog.Logger, _ *v1.Pod, _, _ interface{}) (framework.QueueingHint, error) {
	return framework.Queue, nil
}

func buildQueueingHintMap(es []framework.EnqueueExtensions) internalqueue.QueueingHintMap {
	queueingHintMap := make(internalqueue.QueueingHintMap)
	for _, e := range es {
		events := e.EventsToRegister()
		//该函数的功能是构建一个队列提示映射（QueueingHintMap），它将事件注册到队列中。
		//1. 函数接收一个[]framework.EnqueueExtensions参数，它是一个调度器扩展点的集合，这些扩展点可以注册事件。
		//2. 创建一个空的internalqueue.QueueingHintMap用于存储队列提示映射。
		//3. 遍历扩展点集合es中的每个扩展点e。
		//4. 调用扩展点e的EventsToRegister()方法，获取该扩展点需要注册的事件。
		//5. 将事件添加到队列提示映射queueingHintMap中。
		//最终，函数返回构建完成的队列提示映射queueingHintMap。

		// This will happen when plugin registers with empty events, it&#39;s usually the case a pod
		// will become reschedulable only for self-update, e.g. schedulingGates plugin, the pod
		// will enter into the activeQ via priorityQueue.Update().
		if len(events) == 0 {
			continue
		}

		// Note: Rarely, a plugin implements EnqueueExtensions but returns nil.
		// We treat it as: the plugin is not interested in any event, and hence pod failed by that plugin
		// cannot be moved by any regular cluster event.
		// So, we can just ignore such EventsToRegister here.

		registerNodeAdded := false
		registerNodeTaintUpdated := false
		for _, event := range events {
			fn := event.QueueingHintFn
			if fn == nil || !utilfeature.DefaultFeatureGate.Enabled(features.SchedulerQueueingHints) {
				fn = defaultQueueingHintFn
			}

			if event.Event.Resource == framework.Node {
				if event.Event.ActionType&amp;framework.Add != 0 {
					registerNodeAdded = true
				}
				if event.Event.ActionType&amp;framework.UpdateNodeTaint != 0 {
					registerNodeTaintUpdated = true
				}
			}
			//这段Go代码中的函数是一个循环，用于遍历一组事件（events），
			//并根据这些事件的类型来更新两个布尔变量registerNodeAdded和registerNodeTaintUpdated。
			//具体来说，函数首先检查事件是否启用了调度队列提示功能
			//（通过utilfeature.DefaultFeatureGate.Enabled(features.SchedulerQueueingHints)来判断），
			//如果没有启用，则使用默认的队列提示函数defaultQueueingHintFn
			//。然后，如果事件资源类型为framework.Node，并且事件动作类型包含framework.Add或framework.UpdateNodeTaint，
			//则分别将registerNodeAdded和registerNodeTaintUpdated设置为true。
			//这段代码的主要目的是为了根据事件的类型来决定是否需要注册节点添加或节点污点更新的操作。

			queueingHintMap[event.Event] = append(queueingHintMap[event.Event], &amp;internalqueue.QueueingHintFunction{
				PluginName:     e.Name(),
				QueueingHintFn: fn,
			})
		}
		if registerNodeAdded && !registerNodeTaintUpdated {
			// Temporally fix for the issue https://github.com/kubernetes/kubernetes/issues/109437
			// NodeAdded QueueingHint isn&#39;t always called because of preCheck.
			// It&#39;s definitely not something expected for plugin developers,
			// and registering UpdateNodeTaint event is the only mitigation for now.
			//
			// So, here registers UpdateNodeTaint event for plugins that has NodeAdded event, but don&#39;t have UpdateNodeTaint event.
			// It has a bad impact for the requeuing efficiency though, a lot better than some Pods being stuch in the
			// unschedulable pod pool.
			// This behavior will be removed when we remove the preCheck feature.
			// See: https://github.com/kubernetes/kubernetes/issues/110175
			queueingHintMap[framework.ClusterEvent{Resource: framework.Node, ActionType: framework.UpdateNodeTaint}] =
				append(queueingHintMap[framework.ClusterEvent{Resource: framework.Node, ActionType: framework.UpdateNodeTaint}],
					&amp;internalqueue.QueueingHintFunction{
						PluginName:     e.Name(),
						QueueingHintFn: defaultQueueingHintFn,
					},
				)
		}
	}
	return queueingHintMap
}

//这段Go代码是一个函数，它根据传入的事件列表和注册选项生成一个队列提示映射。
//该映射将事件与相应的队列提示函数进行关联。
//如果注册了NodeAdded事件但未注册UpdateNodeTaint事件，则会临时修复一个Kubernetes问题，
//通过为这些插件注册UpdateNodeTaint事件来避免某些Pod被卡在不可调度的Pod池中。
//该函数返回生成的队列提示映射。

// Run begins watching and scheduling. It starts scheduling and blocked until the context is done.
func (sched *Scheduler) Run(ctx context.Context) {
	logger := klog.FromContext(ctx)
	sched.SchedulingQueue.Run(logger)

	// We need to start scheduleOne loop in a dedicated goroutine,
	// because scheduleOne function hangs on getting the next item
	// from the SchedulingQueue.
	// If there are no new pods to schedule, it will be hanging there
	// and if done in this goroutine it will be blocking closing
	// SchedulingQueue, in effect causing a deadlock on shutdown.
	go wait.UntilWithContext(ctx, sched.ScheduleOne, 0)

	<-ctx.Done()
	sched.SchedulingQueue.Close()

	// If the plugins satisfy the io.Closer interface, they are closed.
	err := sched.Profiles.Close()
	if err != nil {
		logger.Error(err, "Failed to close plugins")
	}
}

//该函数是Scheduler类型的Run方法，用于开始监控和调度。
//它启动调度并阻塞，直到上下文完成。具体步骤如下：
//1. 从上下文中获取日志记录器logger。
//2. 调用SchedulingQueue的Run方法，开始监控调度队列。
//3. 在一个独立的goroutine中启动scheduleOne循环，因为scheduleOne函数会在从SchedulingQueue获取下一个项目时挂起。
//如果没有任何新Pod需要调度，它将一直挂起。
//如果在当前goroutine中执行，它将阻塞关闭SchedulingQueue，从而在关闭时导致死锁。
//4. 等待上下文完成。
//5. 调用SchedulingQueue的Close方法，关闭调度队列。
//6. 尝试关闭满足io.Closer接口的插件。如果关闭失败，记录错误日志。

// NewInformerFactory creates a SharedInformerFactory and initializes a scheduler specific
// in-place podInformer.
func NewInformerFactory(cs clientset.Interface, resyncPeriod time.Duration) informers.SharedInformerFactory {
	informerFactory := informers.NewSharedInformerFactory(cs, resyncPeriod)
	informerFactory.InformerFor(&amp;v1.Pod{}, newPodInformer)
	return informerFactory
}

//该函数创建一个SharedInformerFactory，并为特定的调度程序初始化一个就地podInformer。
//函数接收一个clientset.Interface类型和一个时间周期作为参数，返回一个SharedInformerFactory。
//内部通过调用informers.NewSharedInformerFactory创建一个新的SharedInformerFactory实例，
//并使用InformerFor方法为v1.Pod类型创建一个新的podInformer。
//最后返回创建的SharedInformerFactory实例。

func buildExtenders(logger klog.Logger, extenders []schedulerapi.Extender, profiles []schedulerapi.KubeSchedulerProfile) ([]framework.Extender, error) {
	var fExtenders []framework.Extender
	if len(extenders) == 0 {
		return nil, nil
	}

	var ignoredExtendedResources []string
	var ignorableExtenders []framework.Extender
	for i := range extenders {
		logger.V(2).Info("Creating extender", "extender", extenders[i])
		extender, err := NewHTTPExtender(&amp;extenders[i])
		if err != nil {
			return nil, err
		}
		if !extender.IsIgnorable() {
			fExtenders = append(fExtenders, extender)
		} else {
			ignorableExtenders = append(ignorableExtenders, extender)
		}
		for _, r := range extenders[i].ManagedResources {
			if r.IgnoredByScheduler {
				ignoredExtendedResources = append(ignoredExtendedResources, r.Name)
			}
		}
	}
	// place ignorable extenders to the tail of extenders
	fExtenders = append(fExtenders, ignorableExtenders...)
	//该函数主要负责根据传入的extenders参数构建一个framework.Extender类型的切片fExtenders。具体流程如下：
	//1. 首先判断extenders切片的长度是否为0，如果是则直接返回nil和nil。
	//2. 初始化两个切片ignoredExtendedResources和ignorableExtenders，分别用于存储被忽略的扩展资源名称和可忽略的扩展器。
	//3. 遍历extenders切片，对每个扩展器进行如下操作：
	//- 使用klog.Logger记录日志信息。
	//- 调用NewHTTPExtender函数创建一个新的HTTPExtender对象。
	//- 如果该扩展器不可忽略，则将其添加到fExtenders切片中。
	//- 如果该扩展器可忽略，则将其添加到ignorableExtenders切片中。
	//- 遍历该扩展器的ManagedResources字段，将被忽略的资源名称添加到ignoredExtendedResources切片中。
	//4. 将ignorableExtenders切片追加到fExtenders切片的末尾。
	//最终，函数返回构建好的fExtenders切片和可能出现的错误。

	// If there are any extended resources found from the Extenders, append them to the pluginConfig for each profile.
	// This should only have an effect on ComponentConfig, where it is possible to configure Extenders and
	// plugin args (and in which case the extender ignored resources take precedence).
	if len(ignoredExtendedResources) == 0 {
		return fExtenders, nil
	}

	for i := range profiles {
		prof := &amp;profiles[i]
		var found = false
		for k := range prof.PluginConfig {
			if prof.PluginConfig[k].Name == noderesources.Name {
				// Update the existing args
				pc := &amp;prof.PluginConfig[k]
				args, ok := pc.Args.(*schedulerapi.NodeResourcesFitArgs)
				if !ok {
					return nil, fmt.Errorf("want args to be of type NodeResourcesFitArgs, got %T", pc.Args)
				}
				args.IgnoredResources = ignoredExtendedResources
				found = true
				break
			}
		}
		if !found {
			return nil, fmt.Errorf("can&#39;t find NodeResourcesFitArgs in plugin config")
		}
	}
	return fExtenders, nil
}

//该函数首先检查ignoredExtendedResources是否为空，如果为空则直接返回fExtenders和nil。
//如果不为空，则遍历profiles中的每一个元素，然后遍历该元素的PluginConfig。
//当找到PluginConfig中的Name等于noderesources.Name时，将ignoredExtendedResources赋值给Args的IgnoredResources字段，
//并将found设为true。 如果遍历完所有PluginConfig后仍未找到符合条件的元素，则返回nil和错误信息。
//最后返回fExtenders和nil。

type FailureHandlerFn func(ctx context.Context, fwk framework.Framework, podInfo *framework.QueuedPodInfo, status *framework.Status, nominatingInfo *framework.NominatingInfo, start time.Time)

func unionedGVKs(queueingHintsPerProfile internalqueue.QueueingHintMapPerProfile) map[framework.GVK]framework.ActionType {
	gvkMap := make(map[framework.GVK]framework.ActionType)
	for _, queueingHints := range queueingHintsPerProfile {
		for evt := range queueingHints {
			if _, ok := gvkMap[evt.Resource]; ok {
				gvkMap[evt.Resource] |= evt.ActionType
			} else {
				gvkMap[evt.Resource] = evt.ActionType
			}
		}
	}
	return gvkMap
}

//该函数用于将一个internalqueue.QueueingHintMapPerProfile类型的参数转换为一个map[framework.GVK]framework.ActionType类型的结果。
//具体实现过程为：遍历输入参数中的每个queueingHints，再遍历queueingHints中的每个事件evt，将evt.Resource作为键，
//evt.ActionType作为值存入gvkMap中。如果gvkMap中已经存在该键，则将该键对应的值与evt.ActionType进行按位或运算后再存入gvkMap中。
//最后返回gvkMap作为结果。

// newPodInformer creates a shared index informer that returns only non-terminal pods.
// The PodInformer allows indexers to be added, but note that only non-conflict indexers are allowed.
func newPodInformer(cs clientset.Interface, resyncPeriod time.Duration) cache.SharedIndexInformer {
	selector := fmt.Sprintf("status.phase!=%v,status.phase!=%v", v1.PodSucceeded, v1.PodFailed)
	tweakListOptions := func(options *metav1.ListOptions) {
		options.FieldSelector = selector
	}
	informer := coreinformers.NewFilteredPodInformer(cs, metav1.NamespaceAll, resyncPeriod, cache.Indexers{}, tweakListOptions)

	// Dropping `.metadata.managedFields` to improve memory usage.
	// The Extract workflow (i.e. `ExtractPod`) should be unused.
	trim := func(obj interface{}) (interface{}, error) {
		if accessor, err := meta.Accessor(obj); err == nil {
			accessor.SetManagedFields(nil)
		}
		return obj, nil
	}
	informer.SetTransform(trim)
	return informer
}

//该函数创建一个共享索引 informer，用于返回非终止状态的 pod。
//它通过设置筛选条件，使得 informer 只能获取到状态不是 "Succeeded" 或 "Failed" 的 pod。
//此外，函数还通过设置 transform 函数来删除 pod 的 .metadata.managedFields 字段，以减少内存使用。
//该函数返回一个经过筛选和转换的 pod informer 实例。
'><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://qq547475331.github.io/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8B-schedulergo-%E8%B0%83%E5%BA%A6%E5%99%A8-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-schedulergo-diao-du-qi-yuan-ma-jie-du/"><meta property="og:site_name" content="Guichen's Blog"><meta property="og:title" content="2024-04-09 K8S控制器之 scheduler.go 调度器 源码解读"><meta property="og:description" content='/* Copyright 2014 The Kubernetes Authors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. */ package scheduler import ( "context" "errors" "fmt" "time" v1 "k8s.io/api/core/v1" "k8s.io/apimachinery/pkg/api/meta" metav1 "k8s.io/apimachinery/pkg/apis/meta/v1" "k8s.io/apimachinery/pkg/util/wait" utilfeature "k8s.io/apiserver/pkg/util/feature" "k8s.io/client-go/dynamic/dynamicinformer" "k8s.io/client-go/informers" coreinformers "k8s.io/client-go/informers/core/v1" clientset "k8s.io/client-go/kubernetes" restclient "k8s.io/client-go/rest" "k8s.io/client-go/tools/cache" configv1 "k8s.io/kube-scheduler/config/v1" "k8s.io/kubernetes/pkg/features" schedulerapi "k8s.io/kubernetes/pkg/scheduler/apis/config" "k8s.io/kubernetes/pkg/scheduler/apis/config/scheme" "k8s.io/kubernetes/pkg/scheduler/framework" "k8s.io/kubernetes/pkg/scheduler/framework/parallelize" frameworkplugins "k8s.io/kubernetes/pkg/scheduler/framework/plugins" "k8s.io/kubernetes/pkg/scheduler/framework/plugins/noderesources" frameworkruntime "k8s.io/kubernetes/pkg/scheduler/framework/runtime" internalcache "k8s.io/kubernetes/pkg/scheduler/internal/cache" cachedebugger "k8s.io/kubernetes/pkg/scheduler/internal/cache/debugger" internalqueue "k8s.io/kubernetes/pkg/scheduler/internal/queue" "k8s.io/kubernetes/pkg/scheduler/metrics" "k8s.io/kubernetes/pkg/scheduler/profile" ) const ( // Duration the scheduler will wait before expiring an assumed pod. // See issue #106361 for more details about this parameter and its value. durationToExpireAssumedPod time.Duration = 0 ) // ErrNoNodesAvailable is used to describe the error that no nodes available to schedule pods. var ErrNoNodesAvailable = fmt.Errorf("no nodes available to schedule pods") // Scheduler watches for new unscheduled pods. It attempts to find // nodes that they fit on and writes bindings back to the api server. type Scheduler struct { // It is expected that changes made via Cache will be observed // by NodeLister and Algorithm. Cache internalcache.Cache Extenders []framework.Extender // NextPod should be a function that blocks until the next pod // is available. We don&#39;t use a channel for this, because scheduling // a pod may take some amount of time and we don&#39;t want pods to get // stale while they sit in a channel. NextPod func(logger klog.Logger) (*framework.QueuedPodInfo, error) // FailureHandler is called upon a scheduling failure. FailureHandler FailureHandlerFn // SchedulePod tries to schedule the given pod to one of the nodes in the node list. // Return a struct of ScheduleResult with the name of suggested host on success, // otherwise will return a FitError with reasons. SchedulePod func(ctx context.Context, fwk framework.Framework, state *framework.CycleState, pod *v1.Pod) (ScheduleResult, error) // Close this to shut down the scheduler. StopEverything <-chan struct{} // SchedulingQueue holds pods to be scheduled SchedulingQueue internalqueue.SchedulingQueue // Profiles are the scheduling profiles. Profiles profile.Map client clientset.Interface nodeInfoSnapshot *internalcache.Snapshot percentageOfNodesToScore int32 nextStartNodeIndex int // logger *must* be initialized when creating a Scheduler, // otherwise logging functions will access a nil sink and // panic. logger klog.Logger // registeredHandlers contains the registrations of all handlers. It&#39;s used to check if all handlers have finished syncing before the scheduling cycles start. registeredHandlers []cache.ResourceEventHandlerRegistration } //该Go代码定义了一个名为Scheduler的结构体，用于管理Pod的调度过程。 //它包含多个字段，用于配置调度器的行为， //例如Cache、Extenders、NextPod、FailureHandler、SchedulePod、StopEverything、SchedulingQueue、Profiles、 //client、nodeInfoSnapshot、percentageOfNodesToScore、nextStartNodeIndex、logger和registeredHandlers。 //这些字段的作用如下： //- Cache：用于存储集群的状态信息， 以便Scheduler能够快速访问。 //- Extenders：是一组扩展程序，可以自定义Pod的调度逻辑。 //- NextPod：是一个函数，用于获取下一个待调度的Pod。 - //FailureHandler：是一个函数，用于处理调度失败的情况。 //- SchedulePod：是一个函数，用于尝试将给定的Pod调度到节点列表中的一个节点上。 //成功时返回建议的主机名，失败时返回FitError错误。 //- StopEverything：是一个通道，用于关闭Scheduler。 //- SchedulingQueue：用于存储待调度的Pod。 //- Profiles：是一组调度配置文件，用于定义不同的调度策略。 //- client：是用于与Kubernetes API服务器交互的客户端。 //- nodeInfoSnapshot：是集群节点的快照，包含节点的状态信息。 //- percentageOfNodesToScore：用于指定参与评分的节点百分比。 //- nextStartNodeIndex：用于指定下一个开始调度的节点索引。 //- logger：用于记录日志信息。 //- registeredHandlers：包含所有处理器的注册信息，用于检查处理器是否已同步完成。 //总的来说，这个Scheduler结构体定义了一个调度器所需的各种配置和功能， //包括节点和Pod的缓存、扩展程序、日志记录、失败处理、调度逻辑等。它提供了一种灵活的方式来定制和管理Pod的调度过程。 func (sched *Scheduler) applyDefaultHandlers() { sched.SchedulePod = sched.schedulePod sched.FailureHandler = sched.handleSchedulingFailure } //该函数为一个go语言函数，作用是为Scheduler结构体实例sched设置默认的处理函数。 //具体操作是将sched.schedulePod赋值给sched.SchedulePod，将sched.handleSchedulingFailure赋值给sched.FailureHandler。 type schedulerOptions struct { componentConfigVersion string kubeConfig *restclient.Config // Overridden by profile level percentageOfNodesToScore if set in v1. percentageOfNodesToScore int32 podInitialBackoffSeconds int64 podMaxBackoffSeconds int64 podMaxInUnschedulablePodsDuration time.Duration // Contains out-of-tree plugins to be merged with the in-tree registry. frameworkOutOfTreeRegistry frameworkruntime.Registry profiles []schedulerapi.KubeSchedulerProfile extenders []schedulerapi.Extender frameworkCapturer FrameworkCapturer parallelism int32 applyDefaultProfile bool } //该代码定义了一个名为schedulerOptions的结构体，用于配置调度器的参数。 //其中包括了组件配置版本、kubeconfig配置、节点打分百分比、Pod初始退避时间、Pod最大退避时间、 //Pod在不可调度状态下的最大持续时间、外部插件注册表、调度器配置文件、扩展器、框架捕获器和并行度等参数。 // Option configures a Scheduler type Option func(*schedulerOptions) // ScheduleResult represents the result of scheduling a pod. type ScheduleResult struct { // Name of the selected node. SuggestedHost string // The number of nodes the scheduler evaluated the pod against in the filtering // phase and beyond. // Note that it contains the number of nodes that filtered out by PreFilterResult. EvaluatedNodes int // The number of nodes out of the evaluated ones that fit the pod. FeasibleNodes int // The nominating info for scheduling cycle. nominatingInfo *framework.NominatingInfo } //这段代码定义了Go语言中的两个类型和一个函数： //1. Option 是一个函数类型，其参数为一个 *schedulerOptions 指针，用于配置一个 Scheduler。 //2. ScheduleResult 是一个结构体类型，代表调度 Pod 的结果。它包含以下字段： //- SuggestedHost：被选中的节点名称。 //- EvaluatedNodes：在过滤阶段及之后对 Pod 进行评估的节点数量。 //- FeasibleNodes：在评估节点中适合 Pod 的节点数量。 //- nominatingInfo：提名信息，用于记录调度周期的提名情况。 //这段代码没有定义函数的具体实现，因此无法对其复杂度进行评估。 // WithComponentConfigVersion sets the component config version to the // KubeSchedulerConfiguration version used. The string should be the full // scheme group/version of the external type we converted from (for example // "kubescheduler.config.k8s.io/v1") func WithComponentConfigVersion(apiVersion string) Option { return func(o *schedulerOptions) { o.componentConfigVersion = apiVersion } } // WithKubeConfig sets the kube config for Scheduler. func WithKubeConfig(cfg *restclient.Config) Option { return func(o *schedulerOptions) { o.kubeConfig = cfg } } // WithProfiles sets profiles for Scheduler. By default, there is one profile // with the name "default-scheduler". func WithProfiles(p ...schedulerapi.KubeSchedulerProfile) Option { return func(o *schedulerOptions) { o.profiles = p o.applyDefaultProfile = false } } // WithParallelism sets the parallelism for all scheduler algorithms. Default is 16. func WithParallelism(threads int32) Option { return func(o *schedulerOptions) { o.parallelism = threads } } // WithPercentageOfNodesToScore sets percentageOfNodesToScore for Scheduler. // The default value of 0 will use an adaptive percentage: 50 - (num of nodes)/125. func WithPercentageOfNodesToScore(percentageOfNodesToScore *int32) Option { return func(o *schedulerOptions) { if percentageOfNodesToScore != nil { o.percentageOfNodesToScore = *percentageOfNodesToScore } } } //这些函数是Go语言中的函数，用于设置调度器（scheduler）的配置选项。 //- WithComponentConfigVersion 函数用于设置组件配置的版本。 //它接受一个字符串参数 apiVersion，该参数应该是外部类型转换而来的完整方案组/版本（例如 "kubescheduler.config.k8s.io/v1"）。 //- WithKubeConfig 函数用于设置调度器的kube配置。 //- WithProfiles 函数用于设置调度器的配置文件。默认情况下，有一个名为 "default-scheduler" 的配置文件。 //- WithParallelism 函数用于设置所有调度算法的并行度。默认值为16。 //- WithPercentageOfNodesToScore 函数用于设置Scheduler的 percentageOfNodesToScore。 //默认值为0，使用自适应百分比：50 - (节点数)/125。 // WithFrameworkOutOfTreeRegistry sets the registry for out-of-tree plugins. Those plugins // will be appended to the default registry. func WithFrameworkOutOfTreeRegistry(registry frameworkruntime.Registry) Option { return func(o *schedulerOptions) { o.frameworkOutOfTreeRegistry = registry } } // WithPodInitialBackoffSeconds sets podInitialBackoffSeconds for Scheduler, the default value is 1 func WithPodInitialBackoffSeconds(podInitialBackoffSeconds int64) Option { return func(o *schedulerOptions) { o.podInitialBackoffSeconds = podInitialBackoffSeconds } } // WithPodMaxBackoffSeconds sets podMaxBackoffSeconds for Scheduler, the default value is 10 func WithPodMaxBackoffSeconds(podMaxBackoffSeconds int64) Option { return func(o *schedulerOptions) { o.podMaxBackoffSeconds = podMaxBackoffSeconds } } // WithPodMaxInUnschedulablePodsDuration sets podMaxInUnschedulablePodsDuration for PriorityQueue. func WithPodMaxInUnschedulablePodsDuration(duration time.Duration) Option { return func(o *schedulerOptions) { o.podMaxInUnschedulablePodsDuration = duration } } //这些函数是Go语言中的函数，用于设置调度器的配置选项。 //- WithFrameworkOutOfTreeRegistry 函数用于设置外部插件的注册表，将这些插件追加到默认的注册表中。 //- WithPodInitialBackoffSeconds 函数用于设置 Scheduler 的 podInitialBackoffSeconds，其默认值为 1。 //- WithPodMaxBackoffSeconds 函数用于设置 Scheduler 的 podMaxBackoffSeconds，其默认值为 10。 //- WithPodMaxInUnschedulablePodsDuration 函数用于设置 PriorityQueue 的 podMaxInUnschedulablePodsDuration。 // WithExtenders sets extenders for the Scheduler func WithExtenders(e ...schedulerapi.Extender) Option { return func(o *schedulerOptions) { o.extenders = e } } //该函数为Go语言中的函数，名为WithExtenders，接收一个变长参数e，类型为schedulerapi.Extender的切片。 //函数返回一个Option类型的函数，该函数接收一个schedulerOptions类型的指针o，将e赋值给o.extenders。 // FrameworkCapturer is used for registering a notify function in building framework. type FrameworkCapturer func(schedulerapi.KubeSchedulerProfile) // WithBuildFrameworkCapturer sets a notify function for getting buildFramework details. func WithBuildFrameworkCapturer(fc FrameworkCapturer) Option { return func(o *schedulerOptions) { o.frameworkCapturer = fc } } //该函数是一个名为WithBuildFrameworkCapturer的函数， //它接收一个FrameworkCapturer类型的参数fc，并返回一个Option类型的函数。 //返回的函数将传入的fc赋值给o.frameworkCapturer。 var defaultSchedulerOptions = schedulerOptions{ percentageOfNodesToScore: schedulerapi.DefaultPercentageOfNodesToScore, podInitialBackoffSeconds: int64(internalqueue.DefaultPodInitialBackoffDuration.Seconds()), podMaxBackoffSeconds: int64(internalqueue.DefaultPodMaxBackoffDuration.Seconds()), podMaxInUnschedulablePodsDuration: internalqueue.DefaultPodMaxInUnschedulablePodsDuration, parallelism: int32(parallelize.DefaultParallelism), // Ideally we would statically set the default profile here, but we can&#39;t because // creating the default profile may require testing feature gates, which may get // set dynamically in tests. Therefore, we delay creating it until New is actually // invoked. applyDefaultProfile: true, } //这段Go代码定义了一个名为defaultSchedulerOptions的变量，它是一个schedulerOptions类型的结构体。 //这个结构体用于设置调度器的默认选项，包括以下字段： //- percentageOfNodesToScore：表示要进行打分的节点的百分比，默认值为schedulerapi.DefaultPercentageOfNodesToScore。 //- podInitialBackoffSeconds：表示Pod初始退避时间的秒数，默认值为internalqueue.DefaultPodInitialBackoffDuration的秒数。 //- podMaxBackoffSeconds：表示Pod最大退避时间的秒数，默认值为internalqueue.DefaultPodMaxBackoffDuration的秒数。 //- podMaxInUnschedulablePodsDuration：表示Pod在不可调度状态下允许的最大持续时间， //默认值为internalqueue.DefaultPodMaxInUnschedulablePodsDuration。 //- parallelism：表示并行处理任务的数量，默认值为parallelize.DefaultParallelism。 //- applyDefaultProfile：表示是否应用默认的调度配置文件，默认值为true。 //这些选项用于配置调度器的行为，例如决定多少节点需要进行打分、设置Pod的退避策略等。 // New returns a Scheduler func New(ctx context.Context, client clientset.Interface, informerFactory informers.SharedInformerFactory, dynInformerFactory dynamicinformer.DynamicSharedInformerFactory, recorderFactory profile.RecorderFactory, opts ...Option) (*Scheduler, error) { logger := klog.FromContext(ctx) stopEverything := ctx.Done() options := defaultSchedulerOptions for _, opt := range opts { opt(&amp;options) } //该函数名为New，返回一个Scheduler类型指针和一个错误类型。 //函数参数包括上下文ctx、客户端接口client、共享informer工厂informerFactory、动态共享informer工厂dynInformerFactory、 //记录器工厂recorderFactory以及可选参数opts。 //函数首先从上下文中获取日志记录器logger和停止信号stopEverything。 //然后定义默认的调度器选项options，并遍历opts对options进行配置。 //最后返回一个Scheduler实例和错误类型。 if options.applyDefaultProfile { var versionedCfg configv1.KubeSchedulerConfiguration scheme.Scheme.Default(&amp;versionedCfg) cfg := schedulerapi.KubeSchedulerConfiguration{} if err := scheme.Scheme.Convert(&amp;versionedCfg, &amp;cfg, nil); err != nil { return nil, err } options.profiles = cfg.Profiles } //这段Go代码主要功能是应用默认配置到调度器配置中。 //首先，它创建了一个configv1.KubeSchedulerConfiguration类型的变量versionedCfg， //并使用scheme.Scheme.Default函数为其应用默认值。 //接着，它创建了一个schedulerapi.KubeSchedulerConfiguration类型的变量cfg， //并将versionedCfg中的值通过scheme.Scheme.Convert函数转换并赋值给cfg。 //最后，将cfg.Profiles赋值给options.profiles。 registry := frameworkplugins.NewInTreeRegistry() if err := registry.Merge(options.frameworkOutOfTreeRegistry); err != nil { return nil, err } metrics.Register() extenders, err := buildExtenders(logger, options.extenders, options.profiles) if err != nil { return nil, fmt.Errorf("couldn&#39;t build extenders: %w", err) } podLister := informerFactory.Core().V1().Pods().Lister() nodeLister := informerFactory.Core().V1().Nodes().Lister() snapshot := internalcache.NewEmptySnapshot() metricsRecorder := metrics.NewMetricsAsyncRecorder(1000, time.Second, stopEverything) profiles, err := profile.NewMap(ctx, options.profiles, registry, recorderFactory, frameworkruntime.WithComponentConfigVersion(options.componentConfigVersion), frameworkruntime.WithClientSet(client), frameworkruntime.WithKubeConfig(options.kubeConfig), frameworkruntime.WithInformerFactory(informerFactory), frameworkruntime.WithSnapshotSharedLister(snapshot), frameworkruntime.WithCaptureProfile(frameworkruntime.CaptureProfile(options.frameworkCapturer)), frameworkruntime.WithParallelism(int(options.parallelism)), frameworkruntime.WithExtenders(extenders), frameworkruntime.WithMetricsRecorder(metricsRecorder), ) if err != nil { return nil, fmt.Errorf("initializing profiles: %v", err) } //这段Go代码的功能是初始化一个调度器配置。 //1. 首先创建一个in-tree注册表registry。 //2. 将options.frameworkOutOfTreeRegistry合并到registry中，如果合并失败则返回错误。 //3. 注册指标收集。 //4. 构建扩展程序extenders，如果构建失败则返回错误。 //5. 获取Pod和Node的列表器。 //6. 创建一个空的快照snapshot。 //7. 创建一个异步指标记录器metricsRecorder。 //8. 使用给定的参数初始化调度器配置profiles，如果初始化失败则返回错误。 //其中，buildExtenders函数用于构建扩展程序，informFactory是一个informers工厂，用于创建Pod和Node的列表器。internalcache.NewEmptySnapshot()创建一个空的快照，metrics.NewMetricsAsyncRecorder创建一个异步指标记录器。profile.NewMap用于初始化调度器配置。 if len(profiles) == 0 { return nil, errors.New("at least one profile is required") } preEnqueuePluginMap := make(map[string][]framework.PreEnqueuePlugin) queueingHintsPerProfile := make(internalqueue.QueueingHintMapPerProfile) for profileName, profile := range profiles { preEnqueuePluginMap[profileName] = profile.PreEnqueuePlugins() queueingHintsPerProfile[profileName] = buildQueueingHintMap(profile.EnqueueExtensions()) } podQueue := internalqueue.NewSchedulingQueue( profiles[options.profiles[0].SchedulerName].QueueSortFunc(), informerFactory, internalqueue.WithPodInitialBackoffDuration(time.Duration(options.podInitialBackoffSeconds)*time.Second), internalqueue.WithPodMaxBackoffDuration(time.Duration(options.podMaxBackoffSeconds)*time.Second), internalqueue.WithPodLister(podLister), internalqueue.WithPodMaxInUnschedulablePodsDuration(options.podMaxInUnschedulablePodsDuration), internalqueue.WithPreEnqueuePluginMap(preEnqueuePluginMap), internalqueue.WithQueueingHintMapPerProfile(queueingHintsPerProfile), internalqueue.WithPluginMetricsSamplePercent(pluginMetricsSamplePercent), internalqueue.WithMetricsRecorder(*metricsRecorder), ) for _, fwk := range profiles { fwk.SetPodNominator(podQueue) } schedulerCache := internalcache.New(ctx, durationToExpireAssumedPod) // Setup cache debugger. debugger := cachedebugger.New(nodeLister, podLister, schedulerCache, podQueue) debugger.ListenForSignal(ctx) sched := &amp;Scheduler{ Cache: schedulerCache, client: client, nodeInfoSnapshot: snapshot, percentageOfNodesToScore: options.percentageOfNodesToScore, Extenders: extenders, StopEverything: stopEverything, SchedulingQueue: podQueue, Profiles: profiles, logger: logger, } sched.NextPod = podQueue.Pop sched.applyDefaultHandlers() if err = addAllEventHandlers(sched, informerFactory, dynInformerFactory, unionedGVKs(queueingHintsPerProfile)); err != nil { return nil, fmt.Errorf("adding event handlers: %w", err) } return sched, nil } //该函数主要实现了以下功能： //1. 检查传入的profiles是否为空，如果为空则返回错误。 //2. 根据profiles创建preEnqueuePluginMap和queueingHintsPerProfile。 //3. 使用profiles中指定的SchedulerName创建一个SchedulingQueue对象，该对象用于管理待调度的Pod。 //4. 为每个profile设置PodNominator。 //5. 创建一个schedulerCache对象，用于缓存节点和Pod的信息。 //6. 创建一个debugger对象，用于调试缓存。 //7. 创建一个Scheduler对象，并设置其属性。 //8. 设置Scheduler的NextPod方法。 //9. 应用默认的处理程序。 //10. 添加所有事件处理程序。 //综上所述，该函数的主要功能是创建一个Scheduler对象，并对其进行初始化。 // defaultQueueingHintFn is the default queueing hint function. // It always returns Queue as the queueing hint. var defaultQueueingHintFn = func(_ klog.Logger, _ *v1.Pod, _, _ interface{}) (framework.QueueingHint, error) { return framework.Queue, nil } func buildQueueingHintMap(es []framework.EnqueueExtensions) internalqueue.QueueingHintMap { queueingHintMap := make(internalqueue.QueueingHintMap) for _, e := range es { events := e.EventsToRegister() //该函数的功能是构建一个队列提示映射（QueueingHintMap），它将事件注册到队列中。 //1. 函数接收一个[]framework.EnqueueExtensions参数，它是一个调度器扩展点的集合，这些扩展点可以注册事件。 //2. 创建一个空的internalqueue.QueueingHintMap用于存储队列提示映射。 //3. 遍历扩展点集合es中的每个扩展点e。 //4. 调用扩展点e的EventsToRegister()方法，获取该扩展点需要注册的事件。 //5. 将事件添加到队列提示映射queueingHintMap中。 //最终，函数返回构建完成的队列提示映射queueingHintMap。 // This will happen when plugin registers with empty events, it&#39;s usually the case a pod // will become reschedulable only for self-update, e.g. schedulingGates plugin, the pod // will enter into the activeQ via priorityQueue.Update(). if len(events) == 0 { continue } // Note: Rarely, a plugin implements EnqueueExtensions but returns nil. // We treat it as: the plugin is not interested in any event, and hence pod failed by that plugin // cannot be moved by any regular cluster event. // So, we can just ignore such EventsToRegister here. registerNodeAdded := false registerNodeTaintUpdated := false for _, event := range events { fn := event.QueueingHintFn if fn == nil || !utilfeature.DefaultFeatureGate.Enabled(features.SchedulerQueueingHints) { fn = defaultQueueingHintFn } if event.Event.Resource == framework.Node { if event.Event.ActionType&amp;framework.Add != 0 { registerNodeAdded = true } if event.Event.ActionType&amp;framework.UpdateNodeTaint != 0 { registerNodeTaintUpdated = true } } //这段Go代码中的函数是一个循环，用于遍历一组事件（events）， //并根据这些事件的类型来更新两个布尔变量registerNodeAdded和registerNodeTaintUpdated。 //具体来说，函数首先检查事件是否启用了调度队列提示功能 //（通过utilfeature.DefaultFeatureGate.Enabled(features.SchedulerQueueingHints)来判断）， //如果没有启用，则使用默认的队列提示函数defaultQueueingHintFn //。然后，如果事件资源类型为framework.Node，并且事件动作类型包含framework.Add或framework.UpdateNodeTaint， //则分别将registerNodeAdded和registerNodeTaintUpdated设置为true。 //这段代码的主要目的是为了根据事件的类型来决定是否需要注册节点添加或节点污点更新的操作。 queueingHintMap[event.Event] = append(queueingHintMap[event.Event], &amp;internalqueue.QueueingHintFunction{ PluginName: e.Name(), QueueingHintFn: fn, }) } if registerNodeAdded && !registerNodeTaintUpdated { // Temporally fix for the issue https://github.com/kubernetes/kubernetes/issues/109437 // NodeAdded QueueingHint isn&#39;t always called because of preCheck. // It&#39;s definitely not something expected for plugin developers, // and registering UpdateNodeTaint event is the only mitigation for now. // // So, here registers UpdateNodeTaint event for plugins that has NodeAdded event, but don&#39;t have UpdateNodeTaint event. // It has a bad impact for the requeuing efficiency though, a lot better than some Pods being stuch in the // unschedulable pod pool. // This behavior will be removed when we remove the preCheck feature. // See: https://github.com/kubernetes/kubernetes/issues/110175 queueingHintMap[framework.ClusterEvent{Resource: framework.Node, ActionType: framework.UpdateNodeTaint}] = append(queueingHintMap[framework.ClusterEvent{Resource: framework.Node, ActionType: framework.UpdateNodeTaint}], &amp;internalqueue.QueueingHintFunction{ PluginName: e.Name(), QueueingHintFn: defaultQueueingHintFn, }, ) } } return queueingHintMap } //这段Go代码是一个函数，它根据传入的事件列表和注册选项生成一个队列提示映射。 //该映射将事件与相应的队列提示函数进行关联。 //如果注册了NodeAdded事件但未注册UpdateNodeTaint事件，则会临时修复一个Kubernetes问题， //通过为这些插件注册UpdateNodeTaint事件来避免某些Pod被卡在不可调度的Pod池中。 //该函数返回生成的队列提示映射。 // Run begins watching and scheduling. It starts scheduling and blocked until the context is done. func (sched *Scheduler) Run(ctx context.Context) { logger := klog.FromContext(ctx) sched.SchedulingQueue.Run(logger) // We need to start scheduleOne loop in a dedicated goroutine, // because scheduleOne function hangs on getting the next item // from the SchedulingQueue. // If there are no new pods to schedule, it will be hanging there // and if done in this goroutine it will be blocking closing // SchedulingQueue, in effect causing a deadlock on shutdown. go wait.UntilWithContext(ctx, sched.ScheduleOne, 0) <-ctx.Done() sched.SchedulingQueue.Close() // If the plugins satisfy the io.Closer interface, they are closed. err := sched.Profiles.Close() if err != nil { logger.Error(err, "Failed to close plugins") } } //该函数是Scheduler类型的Run方法，用于开始监控和调度。 //它启动调度并阻塞，直到上下文完成。具体步骤如下： //1. 从上下文中获取日志记录器logger。 //2. 调用SchedulingQueue的Run方法，开始监控调度队列。 //3. 在一个独立的goroutine中启动scheduleOne循环，因为scheduleOne函数会在从SchedulingQueue获取下一个项目时挂起。 //如果没有任何新Pod需要调度，它将一直挂起。 //如果在当前goroutine中执行，它将阻塞关闭SchedulingQueue，从而在关闭时导致死锁。 //4. 等待上下文完成。 //5. 调用SchedulingQueue的Close方法，关闭调度队列。 //6. 尝试关闭满足io.Closer接口的插件。如果关闭失败，记录错误日志。 // NewInformerFactory creates a SharedInformerFactory and initializes a scheduler specific // in-place podInformer. func NewInformerFactory(cs clientset.Interface, resyncPeriod time.Duration) informers.SharedInformerFactory { informerFactory := informers.NewSharedInformerFactory(cs, resyncPeriod) informerFactory.InformerFor(&amp;v1.Pod{}, newPodInformer) return informerFactory } //该函数创建一个SharedInformerFactory，并为特定的调度程序初始化一个就地podInformer。 //函数接收一个clientset.Interface类型和一个时间周期作为参数，返回一个SharedInformerFactory。 //内部通过调用informers.NewSharedInformerFactory创建一个新的SharedInformerFactory实例， //并使用InformerFor方法为v1.Pod类型创建一个新的podInformer。 //最后返回创建的SharedInformerFactory实例。 func buildExtenders(logger klog.Logger, extenders []schedulerapi.Extender, profiles []schedulerapi.KubeSchedulerProfile) ([]framework.Extender, error) { var fExtenders []framework.Extender if len(extenders) == 0 { return nil, nil } var ignoredExtendedResources []string var ignorableExtenders []framework.Extender for i := range extenders { logger.V(2).Info("Creating extender", "extender", extenders[i]) extender, err := NewHTTPExtender(&amp;extenders[i]) if err != nil { return nil, err } if !extender.IsIgnorable() { fExtenders = append(fExtenders, extender) } else { ignorableExtenders = append(ignorableExtenders, extender) } for _, r := range extenders[i].ManagedResources { if r.IgnoredByScheduler { ignoredExtendedResources = append(ignoredExtendedResources, r.Name) } } } // place ignorable extenders to the tail of extenders fExtenders = append(fExtenders, ignorableExtenders...) //该函数主要负责根据传入的extenders参数构建一个framework.Extender类型的切片fExtenders。具体流程如下： //1. 首先判断extenders切片的长度是否为0，如果是则直接返回nil和nil。 //2. 初始化两个切片ignoredExtendedResources和ignorableExtenders，分别用于存储被忽略的扩展资源名称和可忽略的扩展器。 //3. 遍历extenders切片，对每个扩展器进行如下操作： //- 使用klog.Logger记录日志信息。 //- 调用NewHTTPExtender函数创建一个新的HTTPExtender对象。 //- 如果该扩展器不可忽略，则将其添加到fExtenders切片中。 //- 如果该扩展器可忽略，则将其添加到ignorableExtenders切片中。 //- 遍历该扩展器的ManagedResources字段，将被忽略的资源名称添加到ignoredExtendedResources切片中。 //4. 将ignorableExtenders切片追加到fExtenders切片的末尾。 //最终，函数返回构建好的fExtenders切片和可能出现的错误。 // If there are any extended resources found from the Extenders, append them to the pluginConfig for each profile. // This should only have an effect on ComponentConfig, where it is possible to configure Extenders and // plugin args (and in which case the extender ignored resources take precedence). if len(ignoredExtendedResources) == 0 { return fExtenders, nil } for i := range profiles { prof := &amp;profiles[i] var found = false for k := range prof.PluginConfig { if prof.PluginConfig[k].Name == noderesources.Name { // Update the existing args pc := &amp;prof.PluginConfig[k] args, ok := pc.Args.(*schedulerapi.NodeResourcesFitArgs) if !ok { return nil, fmt.Errorf("want args to be of type NodeResourcesFitArgs, got %T", pc.Args) } args.IgnoredResources = ignoredExtendedResources found = true break } } if !found { return nil, fmt.Errorf("can&#39;t find NodeResourcesFitArgs in plugin config") } } return fExtenders, nil } //该函数首先检查ignoredExtendedResources是否为空，如果为空则直接返回fExtenders和nil。 //如果不为空，则遍历profiles中的每一个元素，然后遍历该元素的PluginConfig。 //当找到PluginConfig中的Name等于noderesources.Name时，将ignoredExtendedResources赋值给Args的IgnoredResources字段， //并将found设为true。 如果遍历完所有PluginConfig后仍未找到符合条件的元素，则返回nil和错误信息。 //最后返回fExtenders和nil。 type FailureHandlerFn func(ctx context.Context, fwk framework.Framework, podInfo *framework.QueuedPodInfo, status *framework.Status, nominatingInfo *framework.NominatingInfo, start time.Time) func unionedGVKs(queueingHintsPerProfile internalqueue.QueueingHintMapPerProfile) map[framework.GVK]framework.ActionType { gvkMap := make(map[framework.GVK]framework.ActionType) for _, queueingHints := range queueingHintsPerProfile { for evt := range queueingHints { if _, ok := gvkMap[evt.Resource]; ok { gvkMap[evt.Resource] |= evt.ActionType } else { gvkMap[evt.Resource] = evt.ActionType } } } return gvkMap } //该函数用于将一个internalqueue.QueueingHintMapPerProfile类型的参数转换为一个map[framework.GVK]framework.ActionType类型的结果。 //具体实现过程为：遍历输入参数中的每个queueingHints，再遍历queueingHints中的每个事件evt，将evt.Resource作为键， //evt.ActionType作为值存入gvkMap中。如果gvkMap中已经存在该键，则将该键对应的值与evt.ActionType进行按位或运算后再存入gvkMap中。 //最后返回gvkMap作为结果。 // newPodInformer creates a shared index informer that returns only non-terminal pods. // The PodInformer allows indexers to be added, but note that only non-conflict indexers are allowed. func newPodInformer(cs clientset.Interface, resyncPeriod time.Duration) cache.SharedIndexInformer { selector := fmt.Sprintf("status.phase!=%v,status.phase!=%v", v1.PodSucceeded, v1.PodFailed) tweakListOptions := func(options *metav1.ListOptions) { options.FieldSelector = selector } informer := coreinformers.NewFilteredPodInformer(cs, metav1.NamespaceAll, resyncPeriod, cache.Indexers{}, tweakListOptions) // Dropping `.metadata.managedFields` to improve memory usage. // The Extract workflow (i.e. `ExtractPod`) should be unused. trim := func(obj interface{}) (interface{}, error) { if accessor, err := meta.Accessor(obj); err == nil { accessor.SetManagedFields(nil) } return obj, nil } informer.SetTransform(trim) return informer } //该函数创建一个共享索引 informer，用于返回非终止状态的 pod。 //它通过设置筛选条件，使得 informer 只能获取到状态不是 "Succeeded" 或 "Failed" 的 pod。 //此外，函数还通过设置 transform 函数来删除 pod 的 .metadata.managedFields 字段，以减少内存使用。 //该函数返回一个经过筛选和转换的 pod informer 实例。'><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><title>2024-04-09 K8S控制器之 scheduler.go 调度器 源码解读 | Guichen's Blog</title>
<link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://qq547475331.github.io/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8B-schedulergo-%E8%B0%83%E5%BA%A6%E5%99%A8-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-schedulergo-diao-du-qi-yuan-ma-jie-du/><link rel=stylesheet href=/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.62e641c9f3322f2ad7718686ee65b5b68950f3de9d8614456185deb4d99bbc55.js integrity="sha256-YuZByfMyLyrXcYaG7mW1tolQ896dhhRFYYXetNmbvFU=" crossorigin=anonymous></script></head><script src=https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.2.3/mermaid.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){mermaid.initialize({startOnLoad:!0});let e=document.querySelectorAll("pre > code.language-mermaid");e.forEach(e=>{let t=document.createElement("div");t.classList.add("mermaid"),t.innerHTML=e.innerText,e.parentNode.replaceWith(t)}),mermaid.init(void 0,document.querySelectorAll(".mermaid"))})</script><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>Guichen's Blog</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><a href=/docs/2025-9-29-vercel%E5%88%9B%E5%A7%8B%E4%BA%BA%E5%AF%B9%E8%AF%9D/>2025-9-29 Vercel创始人对话</a></li><li><a href=/docs/2025-9-28-spec-workflow-mcp/>2025-9-28 spec-workflow-mcp</a></li><li><a href=/docs/2025-9-28-chrome-mcp-tools/>2025-9-28 chrome-devtools-mcp</a></li><li><a href=/docs/2025-9-19-%E7%90%86%E8%A7%A3/>2025-9-19 理解</a></li><li><a href=/docs/2025-9-10-%E6%8F%90%E7%A4%BA%E8%AF%8D/>2025-9-10 提示词</a></li><li><a href=/docs/2025-9-9-music/>2025-9-09 music资源</a></li><li><a href=/docs/2025-8-29-%E8%A1%A8%E5%8D%95%E5%88%B0%E9%9B%86%E7%BE%A4/>2025-8-28 表单到集群</a></li><li><a href=/docs/2025-6-27-geminicli/>2025-6-27 geminicli</a></li><li><a href=/docs/2025-6-23-ingress-nginx-contrller-%E5%88%86%E6%9E%90/>2025-6-23 ingress nginx contrller 内存使用过高分析</a></li><li><a href=/docs/2025-6-20-oom/>2025-6-20 oom排查思路</a></li><li><a href=/docs/2025-6-16-fire%E8%A7%84%E5%88%99/>2025-6-16 Cursor RIPER-5规则</a></li><li><a href=/docs/2025-6-12-karmada/>2025-6-12 karmada介绍</a></li><li><a href=/docs/2025-6-12-flutter%E8%A7%84%E5%88%99/>2025-6-12 flutter规则</a></li><li><a href=/docs/2025-6-10-%E7%8B%AC%E7%AB%8B%E5%BC%80%E5%8F%91/>2025-6-10 独立开发</a></li><li><a href=/docs/2025-5-21-ingress%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90/>2025-5-21 主Ingress副本变为0后报503问题分析</a></li><li><a href=/docs/2025-5-7-%E6%8E%A5%E5%8D%95app/>2025-5-07 接单app设计</a></li><li><a href=/docs/2025-5-7-%E5%A5%BD%E5%BF%83%E6%80%81-app/>2025-5-07 好心态app</a></li><li><a href=/docs/2025-4-28-cursor-agent-%E6%8F%90%E7%A4%BA%E5%99%A8/>2025-4-28 cursor agent 提示器</a></li><li><a href=/docs/2025-4-16-%E8%87%AA%E7%A0%94k8s%E5%B9%B3%E5%8F%B0/>2025-4-16 自研k8s平台</a></li><li><a href=/docs/2025-4-16-sleep%E7%9D%A1%E7%9C%A0%E5%BA%94%E7%94%A8/>2025-4-16 sleep睡眠应用</a></li><li><a href=/docs/2025-4-16-paas%E8%AE%BE%E8%AE%A1/>2025-4-16 paas开发记录</a></li><li><a href=/docs/2025-4-16-cursoe-free-vip/>2025-4-16 Cursor Free VIP</a></li><li><a href=/docs/2025-4-16-boss%E7%9B%B4%E8%81%98%E8%87%AA%E5%8A%A8%E6%8A%95%E9%80%92/>2025-4-16 BOSS直聘自动投递</a></li><li><a href=/docs/2025-4-14-github%E6%8E%A8%E9%80%81/>2025-4-14 github推送</a></li><li><a href=/docs/2025-3-30-metallb/>2025-3-30 metallb</a></li><li><a href=/docs/2025-3-24-%E8%87%AA%E6%88%91%E4%BB%8B%E7%BB%8D/>2025-3-24 自我介绍</a></li><li><a href=/docs/2025-3-20-victoriametrics-%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84/>2025-3-20 victoriametrics高可用架构</a></li><li><a href=/docs/2025-3-20-victoriametrics%E6%9E%B6%E6%9E%84/>2025-3-20 victoriametrics 架构</a></li><li><a href=/docs/2025-3-20-victoriametrics%E5%92%8Cthanos%E5%AF%B9%E6%AF%94/>2025-3-20 VictoriaMetrics 和 Thanos 对比</a></li><li><a href=/docs/2025-3-20-thanos%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84/>2025-3-20 thanos高可用架构</a></li><li><a href=/docs/2025-3-20-thanos%E6%9E%B6%E6%9E%84/>2025-3-20 thanos架构</a></li><li><a href=/docs/2025-3-18-5w-pod%E5%8E%8B%E6%B5%8B%E5%A4%8D%E7%9B%98/>2025-3-18 5w pod压测复盘</a></li><li><a href=/docs/2025-3-14-%E7%81%AB%E5%B1%B1%E4%BA%91%E8%BF%81%E7%A7%BB%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/>2025-3-14 火山云迁移工程师面试记录</a></li><li><a href=/docs/2025-3-14-vivo%E9%9D%A2%E8%AF%95/>2025-3-14 vivo面试</a></li><li><a href=/docs/2025-3-13-istio%E6%B5%81%E9%87%8F%E5%88%86%E6%9E%90/>2025-3-13 istio流量分析</a></li><li><a href=/docs/2025-3-13-calico%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F%E4%B8%8B%E6%B5%81%E9%87%8F%E4%BC%A0%E8%BE%93%E8%B7%AF%E5%BE%84%E5%88%86%E6%9E%90/>2025-3-13 calico三种模式下流量传输</a></li><li><a href=/docs/2025-3-12-%E5%A1%94%E8%B5%9E%E9%9D%A2%E8%AF%95/>2025-3-12 塔赞面试</a></li><li><a href=/docs/2025-3-12-%E8%BF%BD%E8%A7%85%E9%9D%A2%E8%AF%95/>2025-3-12 追觅面试</a></li><li><a href=/docs/2025-3-8-k8s%E5%88%A0%E9%99%A4pod-deployment%E7%9A%84%E6%B5%81%E7%A8%8B%E5%9B%BE%E8%AF%A6%E8%A7%A3/>2025-3-08 k8s删除pod或deployment的流程图详解</a></li><li><a href=/docs/2025-3-8-k8s%E5%88%9B%E5%BB%BApod-deployment%E6%B5%81%E7%A8%8B%E5%9B%BE%E8%AF%A6%E8%A7%A3/>2025-3-08 k8s创建pod流程图详解</a></li><li><a href=/docs/2025-2-28-prometheus%E9%A2%98%E7%9B%AE/>2025-2-28 prometheus面试题</a></li><li><a href=/docs/2025-2-26-%E9%9D%A2%E8%AF%950225/>2025-2-25 面试0225</a></li><li><a href=/docs/2025-2-24-%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4%E9%9D%A2%E8%AF%95%E9%A2%98_ai_linux%E9%83%A8%E5%88%86/>2025-2-24 高级运维面试题-linux部分</a></li><li><a href=/docs/2025-2-24-%E4%B8%AD%E7%BA%A7%E8%BF%90%E7%BB%B4%E9%9D%A2%E8%AF%95%E9%A2%98_%E9%A2%98%E7%9B%AE/>2025-2-24 中级运维面试题</a></li><li><a href=/docs/2025-2-24-%E9%9D%A2%E8%AF%950224/>2025-2-24 0224面试</a></li><li><a href=/docs/2025-2-20-%E9%9D%A2%E8%AF%950220/>2025-2-20 面试0220</a></li><li><a href=/docs/2025-2-19-%E9%9D%A2%E8%AF%950219/>2025-2-19 面试0219</a></li><li><a href=/docs/2025-2-18-%E9%9D%A2%E8%AF%95/>2025-2-18 面试2025-0218</a></li><li><a href=/docs/2025-2-26-k8s%E7%9B%B8%E5%85%B3/>2025-2-16 k8s题目</a></li><li><a href=/docs/2025-2-12-%E9%9D%A2%E8%AF%950212/>2025-2-12 面试0212</a></li><li><a href=/docs/2025-2-11-%E9%9D%A2%E8%AF%950211/>2025-2-11 面试2025-02-11</a></li><li><a href=/docs/2025-2-7-%E8%AE%A1%E5%88%922/>2025-2-07 美国码农计划</a></li><li><a href=/docs/2025-2-7-%E8%AE%A1%E5%88%92/>2025-2-07 美国码农薪酬</a></li><li><a href=/docs/2025-2-7-k8s%E7%BB%84%E4%BB%B6/>2025-2-07 k8s组件</a></li><li><a href=/docs/2025-10-27-reconciler%E6%A8%A1%E5%BC%8F/>2025-10-27 informer模式3</a></li><li><a href=/docs/2025-10-23-informer3/>2025-10-23 informer模式3</a></li><li><a href=/docs/2025-10-23-informer2/>2025-10-23 informer模式2</a></li><li><a href=/docs/2025-10-23-informer/>2025-10-23 informer模式</a></li><li><a href=/docs/2025-1-16-k8s%E5%B8%B8%E8%A7%81%E6%95%85%E9%9A%9C%E6%8C%87%E5%8D%97/>2025-1-16 k8s常见故障指南</a></li><li><a href=/docs/2025-1-1-%E8%A6%81%E4%B8%8D%E8%A6%81%E5%88%9B%E4%B8%9A/>2025-1-1 要不要创业</a></li><li><a href=/docs/2025-1-1-%E6%97%A9%E6%9C%9F%E6%A8%A1%E5%BC%8F/>2025-1-1 早期模式</a></li><li><a href=/docs/2025-1-1-%E5%A4%A7%E5%A0%B0%E6%B2%B3-%E6%88%91%E7%9A%84%E4%BF%9D%E5%A7%86/>2025-1-1 大堰河-我的保姆</a></li><li><a href=/docs/2025-1-1-%E5%88%9D%E5%88%9B%E5%85%AC%E5%8F%B8/>2025-1-1 初创公司</a></li><li><a href=/docs/2025-1-1-%E5%88%9B%E4%B8%9A%E8%80%85%E4%BA%A4%E6%B5%81/>2025-1-1 创业者交流</a></li><li><a href=/docs/2025-1-1-%E5%88%9B%E4%B8%9A%E7%82%B9%E5%AD%90/>2025-1-1 创业点子</a></li><li><a href=/docs/2025-1-1-sealos%E8%8E%B7%E6%8A%95/>2025-1-1 sealos获投</a></li><li><a href=/docs/2024-12-10-docker-registrry/>2024-12-10 docker registrry</a></li><li><a href=/docs/2024-12-09-openstack-ssh%E8%BF%9E%E6%8E%A5/>2024-12-09 openstack ssh连接</a></li><li><a href=/docs/2024-12-08-mutilpass%E9%83%A8%E7%BD%B2openstack/>2024-12-09 mutilpass部署openstack devstack形式</a></li><li><a href=/docs/2024-12-09-helmchart-%E9%83%A8%E7%BD%B2flask%E5%BA%94%E7%94%A8/>2024-12-09 helmchart 部署flask应用</a></li><li><a href=/docs/2024-12-09-docker-daemon.json/>2024-12-09 docker daemon.json</a></li><li><a href=/docs/2024-12-08-%E5%9D%97%E5%AD%98%E5%82%A8%E5%92%8C%E5%AF%B9%E8%B1%A1%E5%82%A8%E5%AD%98%E5%8C%BA%E5%88%AB/>2024-12-08 块存储和对象储存区别</a></li><li><a href=/docs/2024-12-08-openstack%E9%9C%80%E8%A6%81%E5%87%A0%E5%8F%B0%E8%99%9A%E6%8B%9F%E6%9C%BA/>2024-12-08 openstack需要几台虚拟机</a></li><li><a href=/docs/2024-12-08-openstack%E5%92%8Ckubernetes%E5%8C%BA%E5%88%AB/>2024-12-08 openstack和kubernetes区别</a></li><li><a href=/docs/2024-12-08-nano%E6%93%8D%E4%BD%9C/>2024-12-08 nano操作</a></li><li><a href=/docs/2024-12-08-mutilpass%E6%93%8D%E4%BD%9C/>2024-12-08 mutilpass操作</a></li><li><a href=/docs/2024-12-08-devstack/>2024-12-08 devstack</a></li><li><a href=/docs/2024-12-07-microk8s/>2024-12-07 microk8s</a></li><li><a href=/docs/2024-12-05-kubeasz%E9%83%A8%E7%BD%B2k8s/>2024-12-05 kubeasz部署k8s</a></li><li><a href=/docs/2024-10-20-%E5%88%9B%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/>2024-10-20 使用 Keepalived 和 HAproxy 创建高可用 Kubernetes 集群</a></li><li><a href=/docs/%E9%A1%B6%E7%BA%A7devops%E5%B7%A5%E5%85%B7%E5%A4%A7%E7%9B%98%E7%82%B9-ding-ji-devops-gong-ju-da-pan-dian/>2024-08-02 顶级devops工具大盘点</a></li><li><a href=/docs/%E6%B8%85%E7%90%86docker%E9%95%9C%E5%83%8F-qing-li-docker-jing-xiang/>2024-08-02 清理docker镜像</a></li><li><a href=/docs/%E6%9E%84%E5%BB%BA%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E5%88%A9%E5%99%A8buildkit-gou-jian-rong-qi-jing-xiang-li-qi-buildkit/>2024-08-02 构建容器镜像利器buildkit</a></li><li><a href=/docs/%E6%98%AF%E6%8A%80%E6%9C%AF%E5%A4%A7%E7%A5%9E%E8%BF%98%E6%98%AF%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E9%83%A8%E7%9A%84%E7%A5%B8%E5%AE%B3-shi-ji-shu-da-shen-hai-shi-ji-chu-jia-gou-bu-de-huo-hai/>2024-08-02 是技术大神还是基础架构部的祸害</a></li><li><a href=/docs/%E6%90%AD%E4%B8%AA%E6%97%A5%E5%BF%97%E6%89%8B%E6%9C%BA%E7%B3%BB%E7%BB%9F%E4%B8%8D%E9%A6%99%E5%90%97-da-ge-ri-zhi-shou-ji-xi-tong-bu-xiang-ma/>2024-08-02 搭个日志手机系统不香吗</a></li><li><a href=/docs/%E6%88%91%E5%8F%AA%E6%83%B3%E5%81%9A%E6%8A%80%E6%9C%AF-%E8%B5%B0%E6%8A%80%E6%9C%AF%E8%B7%AF%E7%BA%BF-wo-zhi-xiang-zuo-ji-shu-zou-ji-shu-lu-xian/>2024-08-02 我只想做技术 走技术路线</a></li><li><a href=/docs/%E5%B8%B8%E8%A7%81linux%E8%BF%90%E7%BB%B4%E9%9D%A2%E8%AF%95%E9%A2%98-chang-jian-linux-yun-wei-mian-shi-ti/>2024-08-02 常见linux运维面试题</a></li><li><a href=/docs/%E5%A4%A7%E5%8E%82%E6%80%BB%E7%BB%93nginx%E9%AB%98%E5%B9%B6%E5%8F%91%E4%BC%98%E5%8C%96%E7%AC%94%E8%AE%B0-da-chang-zong-jie-nginx-gao-bing-fa-you-hua-bi-ji/>2024-08-02 大厂总结nginx高并发优化笔记</a></li><li><a href=/docs/%E5%8F%B2%E4%B8%8A%E6%9C%80%E7%89%9Bjenkins-pipeline%E6%B5%81%E6%B0%B4%E7%BA%BF%E8%AF%A6%E8%A7%A3-shi-shang-zui-niu-jenkinspipeline-liu-shui-xian-xiang-jie/>2024-08-02 史上最牛jenkins pipeline流水线详解</a></li><li><a href=/docs/teg%E4%B8%8Eistio%E9%9B%86%E6%88%90-teg-yu-istio-ji-cheng/>2024-08-02 TEG与istio集成</a></li><li><a href=/docs/prometheus-stack-prometheus-stack/>2024-08-02 prometheus-stack</a></li><li><a href=/docs/pixie-pixie/>2024-08-02 pixie</a></li><li><a href=/docs/nginx%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E6%83%8A%E7%BE%A4%E6%95%88%E5%BA%94-nginx-ru-he-jie-jue-jing-qun-xiao-ying/>2024-08-02 nginx如何解决惊群效应</a></li><li><a href=/docs/netctl%E6%A3%80%E6%B5%8B%E9%9B%86%E7%BE%A4pod%E9%97%B4%E8%BF%9E%E9%80%9A%E6%80%A7-netctl-jian-ce-ji-qun-pod-jian-lian-tong-xing/>2024-08-02 netctl检测集群pod间连通性</a></li><li><a href=/docs/linux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%8850%E4%B8%AA%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98-linux-yun-wei-gong-cheng-shi-50-ge-chang-jian-mian-shi-ti/>2024-08-02 linux运维工程师50个常见面试题</a></li><li><a href=/docs/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-%E4%B8%83%E4%B8%AA%E5%AE%9E%E6%88%98%E7%BB%8F%E9%AA%8C-linux-xi-tong-xing-neng-you-hua-qi-ge-shi-zhan-jing-yan/>2024-08-02 linux系统性能优化 七个实战经验</a></li><li><a href=/docs/linux-awk%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%99%A8-8%E4%B8%AA%E6%A1%88%E4%BE%8B-linuxawk-wen-ben-chu-li-qi-8-ge-an-li/>2024-08-02 linux awk文本处理器 8个案例</a></li><li><a href=/docs/kubewharf-kubewharf/>2024-08-02 kubewharf</a></li><li><a href=/docs/kruise%E5%8E%9F%E5%9C%B0%E5%8D%87%E7%BA%A7%E8%A7%A3%E6%9E%90-kruise-yuan-de-sheng-ji-jie-xi/>2024-08-02 kruise原地升级解析</a></li><li><a href=/docs/k8s%E9%9D%A2%E8%AF%95%E9%A2%98-k8s-mian-shi-ti/>2024-08-02 K8S面试题</a></li><li><a href=/docs/k8s%E8%83%8C%E5%90%8Eservice%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84-k8s-bei-hou-service-shi-ru-he-gong-zuo-de/>2024-08-02 k8s背后service是如何工作的</a></li><li><a href=/docs/k8s%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E5%9D%97%E6%8B%BC%E5%9B%BE-dbpaas-k8s-de-zui-hou-yi-kuai-pin-tu-dbpaas/>2024-08-02 K8S的最后一块拼图</a></li><li><a href=/docs/istio%E9%83%A8%E7%BD%B2-istio-bu-shu/>2024-08-02 istio部署</a></li><li><a href=/docs/istio-ingress-gateway-istio-ingress-gateway/>2024-08-02 istio-ingress-gateway</a></li><li><a href=/docs/godel-scheduler-godel-scheduler/>2024-08-02 godel-scheduler</a></li><li><a href=/docs/dockerfile%E5%AE%9A%E5%88%B6%E4%B8%93%E5%B1%9E%E9%95%9C%E5%83%8F-dockerfile-ding-zhi-zhuan-shu-jing-xiang/>2024-08-02 dockerfile定制专属镜像</a></li><li><a href=/docs/33%E6%AC%BEgitops%E4%B8%8Edevops%E4%B8%BB%E6%B5%81%E7%B3%BB%E7%BB%9F-33-kuan-gitops-yu-devops-zhu-liu-xi-tong/>2024-08-02 33款gitops与devops主流系统</a></li><li><a href=/docs/2024-8-1-linux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%8850%E4%B8%AA%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/>2024-08-01 linux面试题</a></li><li><a href=/docs/2024-8-1-%E5%B8%B8%E8%A7%81linux%E8%BF%90%E7%BB%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%BF%85%E7%9C%8B/>2024-08-01 linux运维面试题</a></li><li><a href=/docs/2024-8-1-kubernetes%E9%9D%A2%E8%AF%95%E9%A2%98/>2024-08-01 k8s面试题</a></li><li><a href=/docs/openkruise%E8%AF%A6%E7%BB%86%E8%A7%A3%E9%87%8A%E4%BB%A5%E5%8F%8A%E5%8E%9F%E5%9C%B0%E5%8D%87%E7%BA%A7%E5%8F%8A%E5%85%A8%E9%93%BE%E8%B7%AF%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83%E6%96%B9%E6%A1%88-openkruise-xiang-xi-jie-shi-yi-ji-yuan-de-sheng-ji-ji-quan-lian-lu-hui-du-fa-bu-fang-an/>2024-07-22 OpenKruise详细解释以及原地升级及全链路灰度发布方案</a></li><li><a href=/docs/k8s%E4%B9%8Bingress-nginx%E5%8E%9F%E7%90%86%E5%8F%8A%E9%85%8D%E7%BD%AE-k8s-zhi-ingress-nginx-yuan-li-ji-pei-zhi/>2024-07-05 K8S之ingress-nginx原理及配置</a></li><li><a href=/docs/%E4%BD%BF%E7%94%A8cloudflarecf%E6%90%AD%E5%BB%BAdockerhub%E4%BB%A3%E7%90%86-shi-yong-cloudflarecf-da-jian-dockerhub-dai-li/>2024-06-28 使用cloudflare(CF)搭建dockerhub代理</a></li><li><a href=/docs/2024-5-14-%E5%8D%95master%E5%8D%95etcd%E6%94%B9%E9%80%A0/>2024-05-01 单master单etcd改造为3master3etcd</a></li><li><a href=/docs/2024-4-17-%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/>2024-04-17 面试总结</a></li><li><a href=/docs/%E5%A6%82%E4%BD%95%E4%B8%BAk8s%E4%BF%9D%E9%A9%BE%E6%8A%A4%E8%88%AA-ru-he-wei-k8s-bao-jia-hu-hang/>2024-04-16 如何为K8S保驾护航</a></li><li><a href=/docs/k8s%E5%A6%82%E4%BD%95%E8%8E%B7%E5%BE%97-ip-k8s-ru-he-huo-de-ip/>2024-04-16 K8S如何获得 IP</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Bstateful_setgo%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-statefulsetgo-yuan-ma-jie-du/>2024-04-10 K8S控制器之stateful_set.go源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Bstateful_set_status_updatego%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-statefulsetstatusupdatego-yuan-ma-jie-du/>2024-04-10 K8S控制器之stateful_set_status_update.go源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Bstateful_set_controlgo%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-statefulsetcontrolgo-yuan-ma-jie-du/>2024-04-10 K8S控制器之stateful_set_control.go源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Bstateful_pod_controlgo%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-statefulpodcontrolgo-yuan-ma-jie-du/>2024-04-10 K8S控制器之stateful_pod_control.go源码解读</a></li><li><a href=/docs/k8s%E8%B0%83%E5%BA%A6%E5%99%A8-extendergo-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-diao-du-qi-extendergo-yuan-ma-jie-du/>2024-04-09 K8S调度器 extender.go 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Bsyncgo-%E5%90%8C%E6%AD%A5-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-syncgo-tong-bu-yuan-ma-jie-du/>2024-04-09 K8S控制器之sync.go 同步 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Brollbackgo-%E5%9B%9E%E6%BB%9A-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-rollbackgo-hui-gun-yuan-ma-jie-du/>2024-04-09 K8S控制器之rollback.go 回滚 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Brecreatego-%E9%87%8D%E5%BB%BA-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-recreatego-zhong-jian-yuan-ma-jie-du/>2024-04-09 K8S控制器之recreate.go 重建 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8B-schedulergo-%E8%B0%83%E5%BA%A6%E5%99%A8-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-schedulergo-diao-du-qi-yuan-ma-jie-du/ class=active>2024-04-09 K8S控制器之 scheduler.go 调度器 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8B-rollinggo-%E6%BB%9A%E5%8A%A8%E6%9B%B4%E6%96%B0-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-rollinggo-gun-dong-geng-xin-yuan-ma-jie-du/>2024-04-09 K8S控制器之 rolling.go 滚动更新 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8B-progressgo-%E8%BF%9B%E5%BA%A6-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-progressgo-jin-du-yuan-ma-jie-du/>2024-04-09 K8S控制器之 progress.go 进度 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8B-deployment_controllergo%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-deploymentcontrollergo-yuan-ma-jie-du/>2024-04-09 K8S控制器之 deployment_controller.go源码解读</a></li><li><a href=/docs/k8s-%E8%B0%83%E5%BA%A6%E5%99%A8-scheduler_onego-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-diao-du-qi-scheduleronego-yuan-ma-jie-du/>2024-04-09 K8S 调度器 scheduler_one.go 源码解读</a></li><li><a href=/docs/%E5%BD%BB%E6%82%9F%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C-che-wu-rong-qi-wang-luo/>2024-04-07 彻悟容器网络</a></li><li><a href=/docs/%E9%9D%A2%E8%AF%95%E7%94%A8-golang-%E6%89%8B%E6%92%B8-lru-mian-shi-yong-golang-shou-lu-lru/>2024-04-03 面试用 Golang 手撸 LRU</a></li><li><a href=/docs/%E8%87%AA%E5%8A%A8%E5%B1%8F%E8%94%BDip%E6%94%BB%E5%87%BB-zi-dong-ping-bi-ip-gong-ji/>2024-04-03 自动屏蔽IP攻击</a></li><li><a href=/docs/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85kubephere-li-xian-an-zhuang-kubephere/>2024-04-03 离线安装kubephere</a></li><li><a href=/docs/%E7%A3%81%E7%9B%98%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D-ci-pan-shu-ju-hui-fu/>2024-04-03 磁盘数据恢复</a></li><li><a href=/docs/%E6%B8%85%E7%90%86%E6%AE%8B%E7%95%99%E7%9A%84calico%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6-qing-li-can-liu-de-calico-wang-luo/>2024-04-03 清理残留的calico网络插件</a></li><li><a href=/docs/%E6%B5%81%E9%87%8F%E4%BD%95%E5%A4%84%E6%9D%A5%E4%BD%95%E5%A4%84%E5%8E%BB-liu-liang-he-chu-lai-he-chu-qu/>2024-04-03 流量何处来何处去</a></li><li><a href=/docs/%E6%9E%81%E5%A4%A7%E6%8F%90%E9%AB%98%E5%B7%A5%E4%BD%9C%E6%95%88%E7%8E%87%E7%9A%84-linux-%E5%91%BD%E4%BB%A4-ji-da-ti-gao-gong-zuo-xiao-lv-de-linux-ming-ling/>2024-04-03 极大提高工作效率的 Linux 命令</a></li><li><a href=/docs/%E6%96%87%E5%AD%A6%E7%9A%84%E6%95%85%E4%B9%A1-wen-xue-de-gu-xiang/>2024-04-03 文学的故乡</a></li><li><a href=/docs/%E6%90%9E%E6%87%82k8s%E9%89%B4%E6%9D%83-gao-dong-k8s-jian-quan/>2024-04-03 搞懂K8S鉴权</a></li><li><a href=/docs/%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86-rong-qi-wang-luo-yuan-li/>2024-04-03 容器网络原理</a></li><li><a href=/docs/%E5%AE%B9%E5%99%A8%E7%9A%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%80-overlayfs-%E5%8E%9F%E7%90%86-rong-qi-de-wen-jian-xi-tong--yi-overlayfs-yuan-li/>2024-04-03 容器的文件系统 OverlayFS 原理</a></li><li><a href=/docs/%E5%AE%B9%E5%99%A8%E5%8E%9F%E7%90%86-rong-qi-yuan-li/>2024-04-03 容器原理</a></li><li><a href=/docs/%E5%AE%B9%E5%99%A8%E5%86%85%E7%9A%84-1-%E5%8F%B7%E8%BF%9B%E7%A8%8B-rong-qi-nei-de-1-hao-jin-cheng/>2024-04-03 容器内的 1 号进程</a></li><li><a href=/docs/%E5%AE%B9%E5%99%A8%E4%B8%AD%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E4%BB%A5%E5%8F%8A%E4%B8%8D%E5%90%8Cdnspolicy%E5%AF%B9%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E7%9A%84%E5%BD%B1%E5%93%8D-rong-qi-zhong-yu-ming-jie-xi-yi-ji-bu-tong-dnspolicy-dui-yu-ming-jie-xi-de-ying-xiang/>2024-04-03 容器中域名解析以及不同dnspolicy对域名解析的影响</a></li><li><a href=/docs/%E5%A6%82%E4%BD%95%E8%B0%83%E8%AF%95-crash-%E5%AE%B9%E5%99%A8%E7%9A%84%E7%BD%91%E7%BB%9C-ru-he-diao-shi-crash-rong-qi-de-wang-luo/>2024-04-03 如何调试 crash 容器的网络</a></li><li><a href=/docs/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8tekton%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAcicd%E5%B9%B3%E5%8F%B0-ru-he-shi-yong-tekton-kuai-su-da-jian-cicd-ping-tai/>2024-04-03 如何使用tekton快速搭建CI/CD平台</a></li><li><a href=/docs/%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%B9%B6%E5%8F%91%E4%B8%8B%E5%A6%82%E4%BD%95%E5%8A%A0%E5%BF%AB-pod-%E5%90%AF%E5%8A%A8%E9%80%9F%E5%BA%A6-da-gui-mo-bing-fa-xia-ru-he-jia-kuai-pod-qi-dong-su-du/>2024-04-03 大规模并发下如何加快 Pod 启动速度</a></li><li><a href=/docs/%E4%BD%BF%E7%94%A8kubernees-leases-%E8%BD%BB%E6%9D%BE%E5%AE%9E%E7%8E%B0leader-election-shi-yong-kuberneesleases-qing-song-shi-xian-leaderelection/>2024-04-03 使用kubernees leases 轻松实现leader election</a></li><li><a href=/docs/%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2k8s%E5%8A%A0%E8%8A%82%E7%82%B9%E6%93%8D%E4%BD%9C-er-jin-zhi-bu-shu-k8s-jia-jie-dian-cao-zuo/>2024-04-03 二进制部署K8S加节点操作</a></li><li><a href=/docs/%E4%B8%A4%E5%BC%A0%E5%9B%BE%E5%85%A8%E9%9D%A2%E7%90%86%E8%A7%A3k8s%E5%8E%9F%E7%90%86-liang-zhang-tu-quan-mian-li-jie-k8s-yuan-li/>2024-04-03 两张图全面理解K8S原理</a></li><li><a href=/docs/ssl%E8%AF%81%E4%B9%A6%E8%87%AA%E7%AD%BE%E5%8F%91-ssl-zheng-shu-zi-qian-fa/>2024-04-03 ssl证书自签发</a></li><li><a href=/docs/prometheus%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9B%91%E6%8E%A7%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93-prometheus-qi-ye-ji-jian-kong-shi-yong-zong-jie/>2024-04-03 prometheus企业级监控使用总结</a></li><li><a href=/docs/metallb-l2-%E5%8E%9F%E7%90%86-metallbl2-yuan-li/>2024-04-03 MetalLB L2 原理</a></li><li><a href=/docs/linux-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%A4%A7%E5%85%A8-linux-xing-neng-you-hua-da-quan/>2024-04-03 Linux 性能优化大全</a></li><li><a href=/docs/kubernetes-%E8%AF%81%E4%B9%A6%E8%AF%A6%E8%A7%A3%E9%89%B4%E6%9D%83-kubernetes-zheng-shu-xiang-jie--jian-quan-/>2024-04-03 Kubernetes 证书详解(鉴权)</a></li><li><a href=/docs/kubernetes-%E8%AF%81%E4%B9%A6%E8%AF%A6%E8%A7%A3%E8%AE%A4%E8%AF%81-kubernetes-zheng-shu-xiang-jie--ren-zheng-/>2024-04-03 Kubernetes 证书详解(认证)</a></li><li><a href=/docs/kubernetes-%E6%BA%90%E7%A0%81%E7%BB%93%E6%9E%84-kubernetes-yuan-ma-jie-gou/>2024-04-03 Kubernetes 源码结构</a></li><li><a href=/docs/kubernetes-api-kubernetesapi/>2024-04-03 Kubernetes API</a></li><li><a href=/docs/kubekey%E6%B7%BB%E5%8A%A0%E6%96%B0%E8%8A%82%E7%82%B9-kubekey-tian-jia-xin-jie-dian/>2024-04-03 kubekey添加新节点</a></li><li><a href=/docs/k8s%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8-k8s-mian-shi-bao-dian/>2024-04-03 K8S面试宝典</a></li><li><a href=/docs/k8s%E9%9D%A2%E8%AF%95%E5%A4%A7%E5%85%A8-k8s-mian-shi-da-quan/>2024-04-03 K8S面试大全</a></li><li><a href=/docs/k8s%E8%BF%90%E7%BB%B4%E4%B9%8B%E6%B8%85%E7%90%86%E7%A3%81%E7%9B%98-k8s-yun-wei-zhi-qing-li-ci-pan/>2024-04-03 k8s运维之清理磁盘</a></li><li><a href=/docs/k8s%E8%B0%83%E8%AF%95pod-k8s-diao-shi-pod/>2024-04-03 K8S调试POD</a></li><li><a href=/docs/k8s%E7%9A%84pod%E7%B1%BB%E5%9E%8B-k8s-de-pod-lei-xing/>2024-04-03 K8S的POD类型</a></li><li><a href=/docs/k8s%E5%BA%94%E7%94%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5-k8s-ying-yong-de-zui-jia-shi-jian/>2024-04-03 k8s应用的最佳实践</a></li><li><a href=/docs/k8s%E5%91%BD%E4%BB%A4%E6%8C%87%E5%8D%97-k8s-ming-ling-zhi-nan/>2024-04-03 K8S命令指南</a></li><li><a href=/docs/k8s%E5%8E%9F%E5%9C%B0%E5%8D%87%E7%BA%A7-k8s-yuan-de-sheng-ji/>2024-04-03 K8S原地升级</a></li><li><a href=/docs/k8s-%E6%8E%A2%E9%92%88%E5%8E%9F%E7%90%86-k8s-tan-zhen-yuan-li/>2024-04-03 K8S 探针原理</a></li><li><a href=/docs/k8s-%E5%BC%80%E5%8F%91%E5%8F%AF%E4%B8%8D%E6%AD%A2-crud-k8s-kai-fa-ke-bu-zhi-crud/>2024-04-03 K8S 开发可不止 CRUD</a></li><li><a href=/docs/k8s-gpt-k8sgpt/>2024-04-03 K8S GPT</a></li><li><a href=/docs/k8s-csi-openebs%E5%8E%9F%E7%90%86-k8scsiopenebs-yuan-li/>2024-04-03 K8S csi openebs原理</a></li><li><a href=/docs/helm-chart%E5%92%8Crepo-helmchart-he-repo/>2024-04-03 helm chart和repo</a></li><li><a href=/docs/flanel%E7%BD%91%E7%BB%9C-flanel-wang-luo/>2024-04-03 flanel网络</a></li><li><a href=/docs/etcd%E7%A8%B3%E5%AE%9A%E6%80%A7%E5%8F%8A%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5-etcd-wen-ding-xing-ji-xing-neng-you-hua-shi-jian/>2024-04-03 ETCD稳定性及性能优化实践</a></li><li><a href=/docs/etcd%E5%A4%87%E4%BB%BD-etcd-bei-fen/>2024-04-03 ETCD备份</a></li><li><a href=/docs/docker%E9%87%8D%E8%A6%81%E7%9A%84%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E7%82%B9-docker-zhong-yao-de-wang-luo-zhi-shi-dian/>2024-04-03 Docker重要的网络知识点</a></li><li><a href=/docs/dockerfile%E7%9A%84copy%E5%92%8Cadd%E7%9A%84%E5%8C%BA%E5%88%AB-dockerfile-de-copy-he-add-de-qu-bie/>2024-04-03 dockerfile的copy和add的区别</a></li><li><a href=/docs/coredns%E4%B9%8B%E5%85%89-coredns-zhi-guang/>2024-04-03 COREDNS之光</a></li><li><a href=/docs/containerd-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C-containerd-ji-ben-cao-zuo/>2024-04-03 Containerd 基本操作</a></li><li><a href=/docs/cni%E6%8F%92%E4%BB%B6%E9%80%89%E5%9E%8B-cni-cha-jian-xuan-xing/>2024-04-03 CNI插件选型</a></li><li><a href=/docs/client-go-%E6%9E%B6%E6%9E%84-client-go-jia-gou/>2024-04-03 Client-go 架构</a></li><li><a href=/docs/client-go-%E5%9B%9B%E7%A7%8D%E5%AE%A2%E6%88%B7%E7%AB%AF-client-go-si-zhong-ke-hu-duan/>2024-04-03 Client-go 四种客户端</a></li><li><a href=/docs/cicd%E6%80%9D%E8%80%83-cicd-si-kao/>2024-04-03 CICD思考</a></li><li><a href=/docs/calico%E7%BD%91%E7%BB%9C%E8%87%AA%E5%AE%9A%E4%B9%89-calico-wang-luo-zi-ding-yi/>2024-04-03 Calico网络自定义</a></li><li><a href=/docs/acme%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0%E8%AF%81%E4%B9%A6-acme-zi-dong-geng-xin-zheng-shu/>2024-04-03 acme自动更新证书</a></li><li><a href=/docs/16%E4%B8%AA%E6%A6%82%E5%BF%B5%E5%B8%A6%E4%BD%A0%E5%85%A5%E9%97%A8-kubernetes-16-ge-gai-nian-dai-ni-ru-men-kubernetes/>2024-04-03 16个概念带你入门 Kubernetes</a></li><li><a href=/docs/%E9%9D%A2%E8%AF%950308-mian-shi-0308/>2024-04-03 面试0308</a></li><li><a href=/docs/600%E6%9D%A1%E6%9C%80%E5%BC%BAlinux%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93-600-tiao-zui-qiang-linux-ming-ling-zong-jie/>2024-04-03 600条最强linux命令总结</a></li><li><a href=/docs/16%E5%BC%A0%E7%A1%AC%E6%A0%B8%E5%9B%BE%E8%A7%A3k8s%E7%BD%91%E7%BB%9C-16-zhang-ying-he-tu-jie-k8s-wang-luo/>2024-04-03 16张硬核图解k8s网络</a></li><li><a href=/docs/k8s%E4%B9%8Bkubelet%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-zhi-kubelet-yuan-ma-jie-du/>2024-03-28 k8s之kubelet源码解读</a></li><li><a href=/docs/2024-3-19-%E4%B8%A4%E5%BC%A0%E5%9B%BE%E5%85%A8%E9%9D%A2%E7%90%86%E8%A7%A3k8s%E5%8E%9F%E7%90%86/>2024-03-19 两张图全面理解k8s原理</a></li><li><a href=/docs/2024-3-8-%E9%9D%A2%E8%AF%950308/>2024-03-08 面试</a></li><li><a href=/docs/2024-3-4-k8s%E6%B5%81%E9%87%8F%E9%93%BE%E8%B7%AF%E5%89%96%E6%9E%90/>2024-03-04 k8s流量链路剖析</a></li><li><a href=/docs/k8s-%E6%B5%81%E9%87%8F%E9%93%BE%E8%B7%AF%E5%89%96%E6%9E%90-k8s-liu-liang-lian-lu-pou-xi/>2024-03-04 K8S 流量链路剖析</a></li><li><a href=/docs/k8s-csi%E5%89%96%E6%9E%90%E6%BC%94%E8%BF%9B-k8scsi-pou-xi-yan-jin/>2024-03-04 K8S CSI剖析演进</a></li><li><a href=/docs/k8s-cni%E5%89%96%E6%9E%90%E6%BC%94%E8%BF%9B-k8scni-pou-xi-yan-jin/>2024-03-04 K8S CNI剖析演进</a></li><li><a href=/docs/2024-3-4-k8s-csi%E5%89%96%E6%9E%90/>2024-03-04 CSI剖析演进</a></li><li><a href=/docs/2024-3-4-cni%E5%89%96%E6%9E%90%E6%BC%94%E8%BF%9B/>2024-03-04 CNI剖析演进</a></li><li><a href=/docs/2024-2-26-%E9%9D%A2%E8%AF%95/>2024-02-26 面试</a></li><li><a href=/docs/2024-2-22-k8s%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8/>2024-02-22 k8s面试宝典</a></li><li><a href=/docs/2024-2-22-k8s%E6%9E%B6%E6%9E%84%E5%B8%88%E9%9D%A2%E8%AF%95%E5%A4%A7%E5%85%A8/>2024-02-22 k8s架构师面试大全</a></li><li><a href=/docs/%E4%BD%BF%E7%94%A8-openfunction-%E5%9C%A8%E4%BB%BB%E4%BD%95%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E4%B8%8A%E8%BF%90%E8%A1%8C%E6%97%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD-shi-yong-openfunction-zai-ren-he-ji-chu-she-shi-shang-yun-xing-wu-fu-wu-qi-gong-zuo-fu-zai/>2024-01-21 使用 OpenFunction 在任何基础设施上运行无服务器工作负载</a></li><li><a href=/docs/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E9%9B%86%E7%BE%A4-li-xian-an-zhuang-ji-qun/>2023-09-28 离线安装集群</a></li><li><a href=/docs/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%B4%E6%98%8E-cao-zuo-xi-tong-shuo-ming/>2023-09-28 操作系统说明</a></li><li><a href=/docs/%E5%BF%AB%E9%80%9F%E6%8C%87%E5%8D%97-kuai-su-zhi-nan/>2023-09-28 快速指南</a></li><li><a href=/docs/%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8-cilium-kai-shi-shi-yong-cilium/>2023-09-28 开始使用 cilium</a></li><li><a href=/docs/%E5%A4%9A%E6%9E%B6%E6%9E%84%E6%94%AF%E6%8C%81-duo-jia-gou-zhi-chi/>2023-09-28 多架构支持</a></li><li><a href=/docs/%E5%85%AC%E6%9C%89%E4%BA%91%E4%B8%8A%E9%83%A8%E7%BD%B2-kubeasz-gong-you-yun-shang-bu-shu-kubeasz/>2023-09-28 公有云上部署</a></li><li><a href=/docs/%E4%B8%AA%E6%80%A7%E5%8C%96%E9%9B%86%E7%BE%A4%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE-ge-xing-hua-ji-qun-can-shu-pei-zhi/>2023-09-28 个性化集群参数配置</a></li><li><a href=/docs/network-check-network-check/>2023-09-28 network-check</a></li><li><a href=/docs/kube-router-%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-kube-router-wang-luo-zu-jian/>2023-09-28 kube-router 网络组件</a></li><li><a href=/docs/ezctl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BB%8B%E7%BB%8D-ezctl-ming-ling-xing-jie-shao/>2023-09-28 ezctl 命令行介绍</a></li><li><a href=/docs/ex-lb-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E9%83%A8%E7%BD%B2-ex-lb-fu-zai-jun-heng-bu-shu/>2023-09-28 EX-LB 负载均衡部署</a></li><li><a href=/docs/calico-%E9%85%8D%E7%BD%AE-bgp-route-reflectors-calico-pei-zhi-bgproutereflectors/>2023-09-28 calico 配置 BGP Route Reflectors</a></li><li><a href=/docs/07-%E5%AE%89%E8%A3%85%E9%9B%86%E7%BE%A4%E4%B8%BB%E8%A6%81%E6%8F%92%E4%BB%B6-07--an-zhuang-ji-qun-zhu-yao-cha-jian/>2023-09-28 15:26:42.651 07-安装集群主要插件</a></li><li><a href=/docs/08-k8s-%E9%9B%86%E7%BE%A4%E5%AD%98%E5%82%A8--k8s-ji-qun-cun-chu/>2023-09-28 08-K8S 集群存储</a></li><li><a href=/docs/06-%E5%AE%89%E8%A3%85%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-06--an-zhuang-wang-luo-zu-jian/>2023-09-28 06-安装网络组件</a></li><li><a href=/docs/06-%E5%AE%89%E8%A3%85kube-ovn%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-06--an-zhuang-kube-ovn-wang-luo-zu-jian/>2023-09-28 06-安装kube-ovn网络组件</a></li><li><a href=/docs/06-%E5%AE%89%E8%A3%85flannel%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-06--an-zhuang-flannel-wang-luo-zu-jian/>2023-09-28 06-安装flannel网络组件</a></li><li><a href=/docs/06-%E5%AE%89%E8%A3%85cilium%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-06--an-zhuang-cilium-wang-luo-zu-jian/>2023-09-28 06-安装cilium网络组件</a></li><li><a href=/docs/06-%E5%AE%89%E8%A3%85calico%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-06--an-zhuang-calico-wang-luo-zu-jian/>2023-09-28 06-安装calico网络组件</a></li><li><a href=/docs/02-%E5%AE%89%E8%A3%85etcd%E9%9B%86%E7%BE%A4-02--an-zhuang-etcd-ji-qun/>2023-09-28 02-安装etcd集群</a></li><li><a href=/docs/00-%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92%E5%92%8C%E5%9F%BA%E7%A1%80%E5%8F%82%E6%95%B0%E8%AE%BE%E5%AE%9A-00--ji-qun-gui-hua-he-ji-chu-can-shu-she-ding/>2023-09-28 00-集群规划和基础参数设定</a></li><li><a href=/docs/05-%E5%AE%89%E8%A3%85kube_node%E8%8A%82%E7%82%B9-05--an-zhuang-kubenode-jie-dian/>2023-09-28 05-安装kube_node节点</a></li><li><a href=/docs/04-%E5%AE%89%E8%A3%85kube_master%E8%8A%82%E7%82%B9-04--an-zhuang-kubemaster-jie-dian/>2023-09-28 04-安装kube_master节点</a></li><li><a href=/docs/03-%E5%AE%89%E8%A3%85%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6-03--an-zhuang-rong-qi-yun-xing-shi/>2023-09-28 03-安装容器运行时</a></li><li><a href=/docs/01-%E5%88%9B%E5%BB%BA%E8%AF%81%E4%B9%A6%E5%92%8C%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87-01--chuang-jian-zheng-shu-he-huan-jing-zhun-bei/>2023-09-28 01-创建证书和环境准备</a></li><li><a href=/docs/%E6%9C%89%E8%BF%993%E4%B8%AA%E8%BF%B9%E8%B1%A1%E4%BD%A0%E5%B0%B1%E8%AF%A5%E7%A6%BB%E8%81%8C%E4%BA%86-you-zhe-3-ge-ji-xiang--ni-jiu-gai-li-zhi-le/>2023-09-21 思考</a></li><li><a href=/docs/%E4%BD%BF%E7%94%A8-keepalived-%E5%92%8C-haproxy-%E5%88%9B%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8-kubernetes-%E9%9B%86%E7%BE%A4-shi-yong-keepalived-he-haproxy-chuang-jian-gao-ke-yong-kubernetes-ji-qun/>2023-04-12 使用 Keepalived 和 HAproxy 创建高可用 Kubernetes 集群</a></li><li><a href=/docs/2025-4-20-%E6%80%A7%E5%90%8C%E6%84%8Fapp/>2025 4 20 性同意app</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>2024-04-09 K8S控制器之 scheduler.go 调度器 源码解读</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents></nav></aside></header><article class="markdown book-article"><pre tabindex=0><code>/*
Copyright 2014 The Kubernetes Authors.

Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package scheduler

import (
	&#34;context&#34;
	&#34;errors&#34;
	&#34;fmt&#34;
	&#34;time&#34;

	v1 &#34;k8s.io/api/core/v1&#34;
	&#34;k8s.io/apimachinery/pkg/api/meta&#34;
	metav1 &#34;k8s.io/apimachinery/pkg/apis/meta/v1&#34;
	&#34;k8s.io/apimachinery/pkg/util/wait&#34;
	utilfeature &#34;k8s.io/apiserver/pkg/util/feature&#34;
	&#34;k8s.io/client-go/dynamic/dynamicinformer&#34;
	&#34;k8s.io/client-go/informers&#34;
	coreinformers &#34;k8s.io/client-go/informers/core/v1&#34;
	clientset &#34;k8s.io/client-go/kubernetes&#34;
	restclient &#34;k8s.io/client-go/rest&#34;
	&#34;k8s.io/client-go/tools/cache&#34;
	configv1 &#34;k8s.io/kube-scheduler/config/v1&#34;
	&#34;k8s.io/kubernetes/pkg/features&#34;
	schedulerapi &#34;k8s.io/kubernetes/pkg/scheduler/apis/config&#34;
	&#34;k8s.io/kubernetes/pkg/scheduler/apis/config/scheme&#34;
	&#34;k8s.io/kubernetes/pkg/scheduler/framework&#34;
	&#34;k8s.io/kubernetes/pkg/scheduler/framework/parallelize&#34;
	frameworkplugins &#34;k8s.io/kubernetes/pkg/scheduler/framework/plugins&#34;
	&#34;k8s.io/kubernetes/pkg/scheduler/framework/plugins/noderesources&#34;
	frameworkruntime &#34;k8s.io/kubernetes/pkg/scheduler/framework/runtime&#34;
	internalcache &#34;k8s.io/kubernetes/pkg/scheduler/internal/cache&#34;
	cachedebugger &#34;k8s.io/kubernetes/pkg/scheduler/internal/cache/debugger&#34;
	internalqueue &#34;k8s.io/kubernetes/pkg/scheduler/internal/queue&#34;
	&#34;k8s.io/kubernetes/pkg/scheduler/metrics&#34;
	&#34;k8s.io/kubernetes/pkg/scheduler/profile&#34;
)

const (
	// Duration the scheduler will wait before expiring an assumed pod.
	// See issue #106361 for more details about this parameter and its value.
	durationToExpireAssumedPod time.Duration = 0
)

// ErrNoNodesAvailable is used to describe the error that no nodes available to schedule pods.
var ErrNoNodesAvailable = fmt.Errorf(&#34;no nodes available to schedule pods&#34;)

// Scheduler watches for new unscheduled pods. It attempts to find
// nodes that they fit on and writes bindings back to the api server.
type Scheduler struct {
	// It is expected that changes made via Cache will be observed
	// by NodeLister and Algorithm.
	Cache internalcache.Cache

	Extenders []framework.Extender

	// NextPod should be a function that blocks until the next pod
	// is available. We don&#39;t use a channel for this, because scheduling
	// a pod may take some amount of time and we don&#39;t want pods to get
	// stale while they sit in a channel.
	NextPod func(logger klog.Logger) (*framework.QueuedPodInfo, error)

	// FailureHandler is called upon a scheduling failure.
	FailureHandler FailureHandlerFn

	// SchedulePod tries to schedule the given pod to one of the nodes in the node list.
	// Return a struct of ScheduleResult with the name of suggested host on success,
	// otherwise will return a FitError with reasons.
	SchedulePod func(ctx context.Context, fwk framework.Framework, state *framework.CycleState, pod *v1.Pod) (ScheduleResult, error)

	// Close this to shut down the scheduler.
	StopEverything &lt;-chan struct{}

	// SchedulingQueue holds pods to be scheduled
	SchedulingQueue internalqueue.SchedulingQueue

	// Profiles are the scheduling profiles.
	Profiles profile.Map

	client clientset.Interface

	nodeInfoSnapshot *internalcache.Snapshot

	percentageOfNodesToScore int32

	nextStartNodeIndex int

	// logger *must* be initialized when creating a Scheduler,
	// otherwise logging functions will access a nil sink and
	// panic.
	logger klog.Logger

	// registeredHandlers contains the registrations of all handlers. It&#39;s used to check if all handlers have finished syncing before the scheduling cycles start.
	registeredHandlers []cache.ResourceEventHandlerRegistration
}

//该Go代码定义了一个名为Scheduler的结构体，用于管理Pod的调度过程。
//它包含多个字段，用于配置调度器的行为，
//例如Cache、Extenders、NextPod、FailureHandler、SchedulePod、StopEverything、SchedulingQueue、Profiles、
//client、nodeInfoSnapshot、percentageOfNodesToScore、nextStartNodeIndex、logger和registeredHandlers。
//这些字段的作用如下：
//- Cache：用于存储集群的状态信息， 以便Scheduler能够快速访问。
//- Extenders：是一组扩展程序，可以自定义Pod的调度逻辑。
//- NextPod：是一个函数，用于获取下一个待调度的Pod。 -
//FailureHandler：是一个函数，用于处理调度失败的情况。
//- SchedulePod：是一个函数，用于尝试将给定的Pod调度到节点列表中的一个节点上。
//成功时返回建议的主机名，失败时返回FitError错误。
//- StopEverything：是一个通道，用于关闭Scheduler。
//- SchedulingQueue：用于存储待调度的Pod。
//- Profiles：是一组调度配置文件，用于定义不同的调度策略。
//- client：是用于与Kubernetes API服务器交互的客户端。
//- nodeInfoSnapshot：是集群节点的快照，包含节点的状态信息。
//- percentageOfNodesToScore：用于指定参与评分的节点百分比。
//- nextStartNodeIndex：用于指定下一个开始调度的节点索引。
//- logger：用于记录日志信息。
//- registeredHandlers：包含所有处理器的注册信息，用于检查处理器是否已同步完成。
//总的来说，这个Scheduler结构体定义了一个调度器所需的各种配置和功能，
//包括节点和Pod的缓存、扩展程序、日志记录、失败处理、调度逻辑等。它提供了一种灵活的方式来定制和管理Pod的调度过程。

func (sched *Scheduler) applyDefaultHandlers() {
	sched.SchedulePod = sched.schedulePod
	sched.FailureHandler = sched.handleSchedulingFailure
}

//该函数为一个go语言函数，作用是为Scheduler结构体实例sched设置默认的处理函数。
//具体操作是将sched.schedulePod赋值给sched.SchedulePod，将sched.handleSchedulingFailure赋值给sched.FailureHandler。

type schedulerOptions struct {
	componentConfigVersion string
	kubeConfig             *restclient.Config
	// Overridden by profile level percentageOfNodesToScore if set in v1.
	percentageOfNodesToScore          int32
	podInitialBackoffSeconds          int64
	podMaxBackoffSeconds              int64
	podMaxInUnschedulablePodsDuration time.Duration
	// Contains out-of-tree plugins to be merged with the in-tree registry.
	frameworkOutOfTreeRegistry frameworkruntime.Registry
	profiles                   []schedulerapi.KubeSchedulerProfile
	extenders                  []schedulerapi.Extender
	frameworkCapturer          FrameworkCapturer
	parallelism                int32
	applyDefaultProfile        bool
}

//该代码定义了一个名为schedulerOptions的结构体，用于配置调度器的参数。
//其中包括了组件配置版本、kubeconfig配置、节点打分百分比、Pod初始退避时间、Pod最大退避时间、
//Pod在不可调度状态下的最大持续时间、外部插件注册表、调度器配置文件、扩展器、框架捕获器和并行度等参数。

// Option configures a Scheduler
type Option func(*schedulerOptions)

// ScheduleResult represents the result of scheduling a pod.
type ScheduleResult struct {
	// Name of the selected node.
	SuggestedHost string
	// The number of nodes the scheduler evaluated the pod against in the filtering
	// phase and beyond.
	// Note that it contains the number of nodes that filtered out by PreFilterResult.
	EvaluatedNodes int
	// The number of nodes out of the evaluated ones that fit the pod.
	FeasibleNodes int
	// The nominating info for scheduling cycle.
	nominatingInfo *framework.NominatingInfo
}

//这段代码定义了Go语言中的两个类型和一个函数：
//1. Option 是一个函数类型，其参数为一个 *schedulerOptions 指针，用于配置一个 Scheduler。
//2. ScheduleResult 是一个结构体类型，代表调度 Pod 的结果。它包含以下字段：
//- SuggestedHost：被选中的节点名称。
//- EvaluatedNodes：在过滤阶段及之后对 Pod 进行评估的节点数量。
//- FeasibleNodes：在评估节点中适合 Pod 的节点数量。
//- nominatingInfo：提名信息，用于记录调度周期的提名情况。
//这段代码没有定义函数的具体实现，因此无法对其复杂度进行评估。

// WithComponentConfigVersion sets the component config version to the
// KubeSchedulerConfiguration version used. The string should be the full
// scheme group/version of the external type we converted from (for example
// &#34;kubescheduler.config.k8s.io/v1&#34;)
func WithComponentConfigVersion(apiVersion string) Option {
	return func(o *schedulerOptions) {
		o.componentConfigVersion = apiVersion
	}
}

// WithKubeConfig sets the kube config for Scheduler.
func WithKubeConfig(cfg *restclient.Config) Option {
	return func(o *schedulerOptions) {
		o.kubeConfig = cfg
	}
}

// WithProfiles sets profiles for Scheduler. By default, there is one profile
// with the name &#34;default-scheduler&#34;.
func WithProfiles(p ...schedulerapi.KubeSchedulerProfile) Option {
	return func(o *schedulerOptions) {
		o.profiles = p
		o.applyDefaultProfile = false
	}
}

// WithParallelism sets the parallelism for all scheduler algorithms. Default is 16.
func WithParallelism(threads int32) Option {
	return func(o *schedulerOptions) {
		o.parallelism = threads
	}
}

// WithPercentageOfNodesToScore sets percentageOfNodesToScore for Scheduler.
// The default value of 0 will use an adaptive percentage: 50 - (num of nodes)/125.
func WithPercentageOfNodesToScore(percentageOfNodesToScore *int32) Option {
	return func(o *schedulerOptions) {
		if percentageOfNodesToScore != nil {
			o.percentageOfNodesToScore = *percentageOfNodesToScore
		}
	}
}

//这些函数是Go语言中的函数，用于设置调度器（scheduler）的配置选项。
//- WithComponentConfigVersion 函数用于设置组件配置的版本。
//它接受一个字符串参数 apiVersion，该参数应该是外部类型转换而来的完整方案组/版本（例如 &#34;kubescheduler.config.k8s.io/v1&#34;）。
//- WithKubeConfig 函数用于设置调度器的kube配置。
//- WithProfiles 函数用于设置调度器的配置文件。默认情况下，有一个名为 &#34;default-scheduler&#34; 的配置文件。
//- WithParallelism 函数用于设置所有调度算法的并行度。默认值为16。
//- WithPercentageOfNodesToScore 函数用于设置Scheduler的 percentageOfNodesToScore。
//默认值为0，使用自适应百分比：50 - (节点数)/125。

// WithFrameworkOutOfTreeRegistry sets the registry for out-of-tree plugins. Those plugins
// will be appended to the default registry.
func WithFrameworkOutOfTreeRegistry(registry frameworkruntime.Registry) Option {
	return func(o *schedulerOptions) {
		o.frameworkOutOfTreeRegistry = registry
	}
}

// WithPodInitialBackoffSeconds sets podInitialBackoffSeconds for Scheduler, the default value is 1
func WithPodInitialBackoffSeconds(podInitialBackoffSeconds int64) Option {
	return func(o *schedulerOptions) {
		o.podInitialBackoffSeconds = podInitialBackoffSeconds
	}
}

// WithPodMaxBackoffSeconds sets podMaxBackoffSeconds for Scheduler, the default value is 10
func WithPodMaxBackoffSeconds(podMaxBackoffSeconds int64) Option {
	return func(o *schedulerOptions) {
		o.podMaxBackoffSeconds = podMaxBackoffSeconds
	}
}

// WithPodMaxInUnschedulablePodsDuration sets podMaxInUnschedulablePodsDuration for PriorityQueue.
func WithPodMaxInUnschedulablePodsDuration(duration time.Duration) Option {
	return func(o *schedulerOptions) {
		o.podMaxInUnschedulablePodsDuration = duration
	}
}

//这些函数是Go语言中的函数，用于设置调度器的配置选项。
//- WithFrameworkOutOfTreeRegistry 函数用于设置外部插件的注册表，将这些插件追加到默认的注册表中。
//- WithPodInitialBackoffSeconds 函数用于设置 Scheduler 的 podInitialBackoffSeconds，其默认值为 1。
//- WithPodMaxBackoffSeconds 函数用于设置 Scheduler 的 podMaxBackoffSeconds，其默认值为 10。
//- WithPodMaxInUnschedulablePodsDuration 函数用于设置 PriorityQueue 的 podMaxInUnschedulablePodsDuration。

// WithExtenders sets extenders for the Scheduler
func WithExtenders(e ...schedulerapi.Extender) Option {
	return func(o *schedulerOptions) {
		o.extenders = e
	}
}

//该函数为Go语言中的函数，名为WithExtenders，接收一个变长参数e，类型为schedulerapi.Extender的切片。
//函数返回一个Option类型的函数，该函数接收一个schedulerOptions类型的指针o，将e赋值给o.extenders。

// FrameworkCapturer is used for registering a notify function in building framework.
type FrameworkCapturer func(schedulerapi.KubeSchedulerProfile)

// WithBuildFrameworkCapturer sets a notify function for getting buildFramework details.
func WithBuildFrameworkCapturer(fc FrameworkCapturer) Option {
	return func(o *schedulerOptions) {
		o.frameworkCapturer = fc
	}
}

//该函数是一个名为WithBuildFrameworkCapturer的函数，
//它接收一个FrameworkCapturer类型的参数fc，并返回一个Option类型的函数。
//返回的函数将传入的fc赋值给o.frameworkCapturer。

var defaultSchedulerOptions = schedulerOptions{
	percentageOfNodesToScore:          schedulerapi.DefaultPercentageOfNodesToScore,
	podInitialBackoffSeconds:          int64(internalqueue.DefaultPodInitialBackoffDuration.Seconds()),
	podMaxBackoffSeconds:              int64(internalqueue.DefaultPodMaxBackoffDuration.Seconds()),
	podMaxInUnschedulablePodsDuration: internalqueue.DefaultPodMaxInUnschedulablePodsDuration,
	parallelism:                       int32(parallelize.DefaultParallelism),
	// Ideally we would statically set the default profile here, but we can&#39;t because
	// creating the default profile may require testing feature gates, which may get
	// set dynamically in tests. Therefore, we delay creating it until New is actually
	// invoked.
	applyDefaultProfile: true,
}

//这段Go代码定义了一个名为defaultSchedulerOptions的变量，它是一个schedulerOptions类型的结构体。
//这个结构体用于设置调度器的默认选项，包括以下字段：
//- percentageOfNodesToScore：表示要进行打分的节点的百分比，默认值为schedulerapi.DefaultPercentageOfNodesToScore。
//- podInitialBackoffSeconds：表示Pod初始退避时间的秒数，默认值为internalqueue.DefaultPodInitialBackoffDuration的秒数。
//- podMaxBackoffSeconds：表示Pod最大退避时间的秒数，默认值为internalqueue.DefaultPodMaxBackoffDuration的秒数。
//- podMaxInUnschedulablePodsDuration：表示Pod在不可调度状态下允许的最大持续时间，
//默认值为internalqueue.DefaultPodMaxInUnschedulablePodsDuration。
//- parallelism：表示并行处理任务的数量，默认值为parallelize.DefaultParallelism。
//- applyDefaultProfile：表示是否应用默认的调度配置文件，默认值为true。
//这些选项用于配置调度器的行为，例如决定多少节点需要进行打分、设置Pod的退避策略等。

// New returns a Scheduler
func New(ctx context.Context,
	client clientset.Interface,
	informerFactory informers.SharedInformerFactory,
	dynInformerFactory dynamicinformer.DynamicSharedInformerFactory,
	recorderFactory profile.RecorderFactory,
	opts ...Option) (*Scheduler, error) {

	logger := klog.FromContext(ctx)
	stopEverything := ctx.Done()

	options := defaultSchedulerOptions
	for _, opt := range opts {
		opt(&amp;options)
	}
	//该函数名为New，返回一个Scheduler类型指针和一个错误类型。
	//函数参数包括上下文ctx、客户端接口client、共享informer工厂informerFactory、动态共享informer工厂dynInformerFactory、
	//记录器工厂recorderFactory以及可选参数opts。
	//函数首先从上下文中获取日志记录器logger和停止信号stopEverything。
	//然后定义默认的调度器选项options，并遍历opts对options进行配置。
	//最后返回一个Scheduler实例和错误类型。

	if options.applyDefaultProfile {
		var versionedCfg configv1.KubeSchedulerConfiguration
		scheme.Scheme.Default(&amp;versionedCfg)
		cfg := schedulerapi.KubeSchedulerConfiguration{}
		if err := scheme.Scheme.Convert(&amp;versionedCfg, &amp;cfg, nil); err != nil {
			return nil, err
		}
		options.profiles = cfg.Profiles
	}
	//这段Go代码主要功能是应用默认配置到调度器配置中。
	//首先，它创建了一个configv1.KubeSchedulerConfiguration类型的变量versionedCfg，
	//并使用scheme.Scheme.Default函数为其应用默认值。
	//接着，它创建了一个schedulerapi.KubeSchedulerConfiguration类型的变量cfg，
	//并将versionedCfg中的值通过scheme.Scheme.Convert函数转换并赋值给cfg。
	//最后，将cfg.Profiles赋值给options.profiles。

	registry := frameworkplugins.NewInTreeRegistry()
	if err := registry.Merge(options.frameworkOutOfTreeRegistry); err != nil {
		return nil, err
	}

	metrics.Register()

	extenders, err := buildExtenders(logger, options.extenders, options.profiles)
	if err != nil {
		return nil, fmt.Errorf(&#34;couldn&#39;t build extenders: %w&#34;, err)
	}

	podLister := informerFactory.Core().V1().Pods().Lister()
	nodeLister := informerFactory.Core().V1().Nodes().Lister()

	snapshot := internalcache.NewEmptySnapshot()
	metricsRecorder := metrics.NewMetricsAsyncRecorder(1000, time.Second, stopEverything)

	profiles, err := profile.NewMap(ctx, options.profiles, registry, recorderFactory,
		frameworkruntime.WithComponentConfigVersion(options.componentConfigVersion),
		frameworkruntime.WithClientSet(client),
		frameworkruntime.WithKubeConfig(options.kubeConfig),
		frameworkruntime.WithInformerFactory(informerFactory),
		frameworkruntime.WithSnapshotSharedLister(snapshot),
		frameworkruntime.WithCaptureProfile(frameworkruntime.CaptureProfile(options.frameworkCapturer)),
		frameworkruntime.WithParallelism(int(options.parallelism)),
		frameworkruntime.WithExtenders(extenders),
		frameworkruntime.WithMetricsRecorder(metricsRecorder),
	)
	if err != nil {
		return nil, fmt.Errorf(&#34;initializing profiles: %v&#34;, err)
	}
	//这段Go代码的功能是初始化一个调度器配置。
	//1. 首先创建一个in-tree注册表registry。
	//2. 将options.frameworkOutOfTreeRegistry合并到registry中，如果合并失败则返回错误。
	//3. 注册指标收集。
	//4. 构建扩展程序extenders，如果构建失败则返回错误。
	//5. 获取Pod和Node的列表器。
	//6. 创建一个空的快照snapshot。
	//7. 创建一个异步指标记录器metricsRecorder。
	//8. 使用给定的参数初始化调度器配置profiles，如果初始化失败则返回错误。
	//其中，buildExtenders函数用于构建扩展程序，informFactory是一个informers工厂，用于创建Pod和Node的列表器。internalcache.NewEmptySnapshot()创建一个空的快照，metrics.NewMetricsAsyncRecorder创建一个异步指标记录器。profile.NewMap用于初始化调度器配置。

	if len(profiles) == 0 {
		return nil, errors.New(&#34;at least one profile is required&#34;)
	}

	preEnqueuePluginMap := make(map[string][]framework.PreEnqueuePlugin)
	queueingHintsPerProfile := make(internalqueue.QueueingHintMapPerProfile)
	for profileName, profile := range profiles {
		preEnqueuePluginMap[profileName] = profile.PreEnqueuePlugins()
		queueingHintsPerProfile[profileName] = buildQueueingHintMap(profile.EnqueueExtensions())
	}

	podQueue := internalqueue.NewSchedulingQueue(
		profiles[options.profiles[0].SchedulerName].QueueSortFunc(),
		informerFactory,
		internalqueue.WithPodInitialBackoffDuration(time.Duration(options.podInitialBackoffSeconds)*time.Second),
		internalqueue.WithPodMaxBackoffDuration(time.Duration(options.podMaxBackoffSeconds)*time.Second),
		internalqueue.WithPodLister(podLister),
		internalqueue.WithPodMaxInUnschedulablePodsDuration(options.podMaxInUnschedulablePodsDuration),
		internalqueue.WithPreEnqueuePluginMap(preEnqueuePluginMap),
		internalqueue.WithQueueingHintMapPerProfile(queueingHintsPerProfile),
		internalqueue.WithPluginMetricsSamplePercent(pluginMetricsSamplePercent),
		internalqueue.WithMetricsRecorder(*metricsRecorder),
	)

	for _, fwk := range profiles {
		fwk.SetPodNominator(podQueue)
	}

	schedulerCache := internalcache.New(ctx, durationToExpireAssumedPod)

	// Setup cache debugger.
	debugger := cachedebugger.New(nodeLister, podLister, schedulerCache, podQueue)
	debugger.ListenForSignal(ctx)

	sched := &amp;Scheduler{
		Cache:                    schedulerCache,
		client:                   client,
		nodeInfoSnapshot:         snapshot,
		percentageOfNodesToScore: options.percentageOfNodesToScore,
		Extenders:                extenders,
		StopEverything:           stopEverything,
		SchedulingQueue:          podQueue,
		Profiles:                 profiles,
		logger:                   logger,
	}
	sched.NextPod = podQueue.Pop
	sched.applyDefaultHandlers()

	if err = addAllEventHandlers(sched, informerFactory, dynInformerFactory, unionedGVKs(queueingHintsPerProfile)); err != nil {
		return nil, fmt.Errorf(&#34;adding event handlers: %w&#34;, err)
	}

	return sched, nil
}

//该函数主要实现了以下功能：
//1. 检查传入的profiles是否为空，如果为空则返回错误。
//2. 根据profiles创建preEnqueuePluginMap和queueingHintsPerProfile。
//3. 使用profiles中指定的SchedulerName创建一个SchedulingQueue对象，该对象用于管理待调度的Pod。
//4. 为每个profile设置PodNominator。
//5. 创建一个schedulerCache对象，用于缓存节点和Pod的信息。
//6. 创建一个debugger对象，用于调试缓存。
//7. 创建一个Scheduler对象，并设置其属性。
//8. 设置Scheduler的NextPod方法。
//9. 应用默认的处理程序。
//10. 添加所有事件处理程序。
//综上所述，该函数的主要功能是创建一个Scheduler对象，并对其进行初始化。

// defaultQueueingHintFn is the default queueing hint function.
// It always returns Queue as the queueing hint.
var defaultQueueingHintFn = func(_ klog.Logger, _ *v1.Pod, _, _ interface{}) (framework.QueueingHint, error) {
	return framework.Queue, nil
}

func buildQueueingHintMap(es []framework.EnqueueExtensions) internalqueue.QueueingHintMap {
	queueingHintMap := make(internalqueue.QueueingHintMap)
	for _, e := range es {
		events := e.EventsToRegister()
		//该函数的功能是构建一个队列提示映射（QueueingHintMap），它将事件注册到队列中。
		//1. 函数接收一个[]framework.EnqueueExtensions参数，它是一个调度器扩展点的集合，这些扩展点可以注册事件。
		//2. 创建一个空的internalqueue.QueueingHintMap用于存储队列提示映射。
		//3. 遍历扩展点集合es中的每个扩展点e。
		//4. 调用扩展点e的EventsToRegister()方法，获取该扩展点需要注册的事件。
		//5. 将事件添加到队列提示映射queueingHintMap中。
		//最终，函数返回构建完成的队列提示映射queueingHintMap。

		// This will happen when plugin registers with empty events, it&#39;s usually the case a pod
		// will become reschedulable only for self-update, e.g. schedulingGates plugin, the pod
		// will enter into the activeQ via priorityQueue.Update().
		if len(events) == 0 {
			continue
		}

		// Note: Rarely, a plugin implements EnqueueExtensions but returns nil.
		// We treat it as: the plugin is not interested in any event, and hence pod failed by that plugin
		// cannot be moved by any regular cluster event.
		// So, we can just ignore such EventsToRegister here.

		registerNodeAdded := false
		registerNodeTaintUpdated := false
		for _, event := range events {
			fn := event.QueueingHintFn
			if fn == nil || !utilfeature.DefaultFeatureGate.Enabled(features.SchedulerQueueingHints) {
				fn = defaultQueueingHintFn
			}

			if event.Event.Resource == framework.Node {
				if event.Event.ActionType&amp;framework.Add != 0 {
					registerNodeAdded = true
				}
				if event.Event.ActionType&amp;framework.UpdateNodeTaint != 0 {
					registerNodeTaintUpdated = true
				}
			}
			//这段Go代码中的函数是一个循环，用于遍历一组事件（events），
			//并根据这些事件的类型来更新两个布尔变量registerNodeAdded和registerNodeTaintUpdated。
			//具体来说，函数首先检查事件是否启用了调度队列提示功能
			//（通过utilfeature.DefaultFeatureGate.Enabled(features.SchedulerQueueingHints)来判断），
			//如果没有启用，则使用默认的队列提示函数defaultQueueingHintFn
			//。然后，如果事件资源类型为framework.Node，并且事件动作类型包含framework.Add或framework.UpdateNodeTaint，
			//则分别将registerNodeAdded和registerNodeTaintUpdated设置为true。
			//这段代码的主要目的是为了根据事件的类型来决定是否需要注册节点添加或节点污点更新的操作。

			queueingHintMap[event.Event] = append(queueingHintMap[event.Event], &amp;internalqueue.QueueingHintFunction{
				PluginName:     e.Name(),
				QueueingHintFn: fn,
			})
		}
		if registerNodeAdded &amp;&amp; !registerNodeTaintUpdated {
			// Temporally fix for the issue https://github.com/kubernetes/kubernetes/issues/109437
			// NodeAdded QueueingHint isn&#39;t always called because of preCheck.
			// It&#39;s definitely not something expected for plugin developers,
			// and registering UpdateNodeTaint event is the only mitigation for now.
			//
			// So, here registers UpdateNodeTaint event for plugins that has NodeAdded event, but don&#39;t have UpdateNodeTaint event.
			// It has a bad impact for the requeuing efficiency though, a lot better than some Pods being stuch in the
			// unschedulable pod pool.
			// This behavior will be removed when we remove the preCheck feature.
			// See: https://github.com/kubernetes/kubernetes/issues/110175
			queueingHintMap[framework.ClusterEvent{Resource: framework.Node, ActionType: framework.UpdateNodeTaint}] =
				append(queueingHintMap[framework.ClusterEvent{Resource: framework.Node, ActionType: framework.UpdateNodeTaint}],
					&amp;internalqueue.QueueingHintFunction{
						PluginName:     e.Name(),
						QueueingHintFn: defaultQueueingHintFn,
					},
				)
		}
	}
	return queueingHintMap
}

//这段Go代码是一个函数，它根据传入的事件列表和注册选项生成一个队列提示映射。
//该映射将事件与相应的队列提示函数进行关联。
//如果注册了NodeAdded事件但未注册UpdateNodeTaint事件，则会临时修复一个Kubernetes问题，
//通过为这些插件注册UpdateNodeTaint事件来避免某些Pod被卡在不可调度的Pod池中。
//该函数返回生成的队列提示映射。

// Run begins watching and scheduling. It starts scheduling and blocked until the context is done.
func (sched *Scheduler) Run(ctx context.Context) {
	logger := klog.FromContext(ctx)
	sched.SchedulingQueue.Run(logger)

	// We need to start scheduleOne loop in a dedicated goroutine,
	// because scheduleOne function hangs on getting the next item
	// from the SchedulingQueue.
	// If there are no new pods to schedule, it will be hanging there
	// and if done in this goroutine it will be blocking closing
	// SchedulingQueue, in effect causing a deadlock on shutdown.
	go wait.UntilWithContext(ctx, sched.ScheduleOne, 0)

	&lt;-ctx.Done()
	sched.SchedulingQueue.Close()

	// If the plugins satisfy the io.Closer interface, they are closed.
	err := sched.Profiles.Close()
	if err != nil {
		logger.Error(err, &#34;Failed to close plugins&#34;)
	}
}

//该函数是Scheduler类型的Run方法，用于开始监控和调度。
//它启动调度并阻塞，直到上下文完成。具体步骤如下：
//1. 从上下文中获取日志记录器logger。
//2. 调用SchedulingQueue的Run方法，开始监控调度队列。
//3. 在一个独立的goroutine中启动scheduleOne循环，因为scheduleOne函数会在从SchedulingQueue获取下一个项目时挂起。
//如果没有任何新Pod需要调度，它将一直挂起。
//如果在当前goroutine中执行，它将阻塞关闭SchedulingQueue，从而在关闭时导致死锁。
//4. 等待上下文完成。
//5. 调用SchedulingQueue的Close方法，关闭调度队列。
//6. 尝试关闭满足io.Closer接口的插件。如果关闭失败，记录错误日志。

// NewInformerFactory creates a SharedInformerFactory and initializes a scheduler specific
// in-place podInformer.
func NewInformerFactory(cs clientset.Interface, resyncPeriod time.Duration) informers.SharedInformerFactory {
	informerFactory := informers.NewSharedInformerFactory(cs, resyncPeriod)
	informerFactory.InformerFor(&amp;v1.Pod{}, newPodInformer)
	return informerFactory
}

//该函数创建一个SharedInformerFactory，并为特定的调度程序初始化一个就地podInformer。
//函数接收一个clientset.Interface类型和一个时间周期作为参数，返回一个SharedInformerFactory。
//内部通过调用informers.NewSharedInformerFactory创建一个新的SharedInformerFactory实例，
//并使用InformerFor方法为v1.Pod类型创建一个新的podInformer。
//最后返回创建的SharedInformerFactory实例。

func buildExtenders(logger klog.Logger, extenders []schedulerapi.Extender, profiles []schedulerapi.KubeSchedulerProfile) ([]framework.Extender, error) {
	var fExtenders []framework.Extender
	if len(extenders) == 0 {
		return nil, nil
	}

	var ignoredExtendedResources []string
	var ignorableExtenders []framework.Extender
	for i := range extenders {
		logger.V(2).Info(&#34;Creating extender&#34;, &#34;extender&#34;, extenders[i])
		extender, err := NewHTTPExtender(&amp;extenders[i])
		if err != nil {
			return nil, err
		}
		if !extender.IsIgnorable() {
			fExtenders = append(fExtenders, extender)
		} else {
			ignorableExtenders = append(ignorableExtenders, extender)
		}
		for _, r := range extenders[i].ManagedResources {
			if r.IgnoredByScheduler {
				ignoredExtendedResources = append(ignoredExtendedResources, r.Name)
			}
		}
	}
	// place ignorable extenders to the tail of extenders
	fExtenders = append(fExtenders, ignorableExtenders...)
	//该函数主要负责根据传入的extenders参数构建一个framework.Extender类型的切片fExtenders。具体流程如下：
	//1. 首先判断extenders切片的长度是否为0，如果是则直接返回nil和nil。
	//2. 初始化两个切片ignoredExtendedResources和ignorableExtenders，分别用于存储被忽略的扩展资源名称和可忽略的扩展器。
	//3. 遍历extenders切片，对每个扩展器进行如下操作：
	//- 使用klog.Logger记录日志信息。
	//- 调用NewHTTPExtender函数创建一个新的HTTPExtender对象。
	//- 如果该扩展器不可忽略，则将其添加到fExtenders切片中。
	//- 如果该扩展器可忽略，则将其添加到ignorableExtenders切片中。
	//- 遍历该扩展器的ManagedResources字段，将被忽略的资源名称添加到ignoredExtendedResources切片中。
	//4. 将ignorableExtenders切片追加到fExtenders切片的末尾。
	//最终，函数返回构建好的fExtenders切片和可能出现的错误。

	// If there are any extended resources found from the Extenders, append them to the pluginConfig for each profile.
	// This should only have an effect on ComponentConfig, where it is possible to configure Extenders and
	// plugin args (and in which case the extender ignored resources take precedence).
	if len(ignoredExtendedResources) == 0 {
		return fExtenders, nil
	}

	for i := range profiles {
		prof := &amp;profiles[i]
		var found = false
		for k := range prof.PluginConfig {
			if prof.PluginConfig[k].Name == noderesources.Name {
				// Update the existing args
				pc := &amp;prof.PluginConfig[k]
				args, ok := pc.Args.(*schedulerapi.NodeResourcesFitArgs)
				if !ok {
					return nil, fmt.Errorf(&#34;want args to be of type NodeResourcesFitArgs, got %T&#34;, pc.Args)
				}
				args.IgnoredResources = ignoredExtendedResources
				found = true
				break
			}
		}
		if !found {
			return nil, fmt.Errorf(&#34;can&#39;t find NodeResourcesFitArgs in plugin config&#34;)
		}
	}
	return fExtenders, nil
}

//该函数首先检查ignoredExtendedResources是否为空，如果为空则直接返回fExtenders和nil。
//如果不为空，则遍历profiles中的每一个元素，然后遍历该元素的PluginConfig。
//当找到PluginConfig中的Name等于noderesources.Name时，将ignoredExtendedResources赋值给Args的IgnoredResources字段，
//并将found设为true。 如果遍历完所有PluginConfig后仍未找到符合条件的元素，则返回nil和错误信息。
//最后返回fExtenders和nil。

type FailureHandlerFn func(ctx context.Context, fwk framework.Framework, podInfo *framework.QueuedPodInfo, status *framework.Status, nominatingInfo *framework.NominatingInfo, start time.Time)

func unionedGVKs(queueingHintsPerProfile internalqueue.QueueingHintMapPerProfile) map[framework.GVK]framework.ActionType {
	gvkMap := make(map[framework.GVK]framework.ActionType)
	for _, queueingHints := range queueingHintsPerProfile {
		for evt := range queueingHints {
			if _, ok := gvkMap[evt.Resource]; ok {
				gvkMap[evt.Resource] |= evt.ActionType
			} else {
				gvkMap[evt.Resource] = evt.ActionType
			}
		}
	}
	return gvkMap
}

//该函数用于将一个internalqueue.QueueingHintMapPerProfile类型的参数转换为一个map[framework.GVK]framework.ActionType类型的结果。
//具体实现过程为：遍历输入参数中的每个queueingHints，再遍历queueingHints中的每个事件evt，将evt.Resource作为键，
//evt.ActionType作为值存入gvkMap中。如果gvkMap中已经存在该键，则将该键对应的值与evt.ActionType进行按位或运算后再存入gvkMap中。
//最后返回gvkMap作为结果。

// newPodInformer creates a shared index informer that returns only non-terminal pods.
// The PodInformer allows indexers to be added, but note that only non-conflict indexers are allowed.
func newPodInformer(cs clientset.Interface, resyncPeriod time.Duration) cache.SharedIndexInformer {
	selector := fmt.Sprintf(&#34;status.phase!=%v,status.phase!=%v&#34;, v1.PodSucceeded, v1.PodFailed)
	tweakListOptions := func(options *metav1.ListOptions) {
		options.FieldSelector = selector
	}
	informer := coreinformers.NewFilteredPodInformer(cs, metav1.NamespaceAll, resyncPeriod, cache.Indexers{}, tweakListOptions)

	// Dropping `.metadata.managedFields` to improve memory usage.
	// The Extract workflow (i.e. `ExtractPod`) should be unused.
	trim := func(obj interface{}) (interface{}, error) {
		if accessor, err := meta.Accessor(obj); err == nil {
			accessor.SetManagedFields(nil)
		}
		return obj, nil
	}
	informer.SetTransform(trim)
	return informer
}

//该函数创建一个共享索引 informer，用于返回非终止状态的 pod。
//它通过设置筛选条件，使得 informer 只能获取到状态不是 &#34;Succeeded&#34; 或 &#34;Failed&#34; 的 pod。
//此外，函数还通过设置 transform 函数来删除 pod 的 .metadata.managedFields 字段，以减少内存使用。
//该函数返回一个经过筛选和转换的 pod informer 实例。
</code></pre></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents></nav></div></aside></main></body></html>