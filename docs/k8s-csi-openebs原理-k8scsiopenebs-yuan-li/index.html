<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content='
  Kubernetes CSI (二): OpenEBS 原理
  #


  简介
  #


  在 Kubernetes CSI (一): Kubernetes 存储原理 一文中详细讲解了 Kubernetes CSI 的原理，本篇文章通过原理和源码走读形式讲解 OpenEBS 原理。
  #


  OpenEBS 是一款使用Go语言编写的基于容器的块存储开源软件。OpenEBS 使得在容器中运行关键性任务和需要数据持久化的负载变得更可靠。实现了 Kubernetes CSI，所以可以很方便对接 Kubernetes 存储功能。
  #


  对于大部分第三方存储厂商，它们都只实现了分布式存储，OpenEBS 可以为 Kubernetes 有状态负载( StatefulSet ) 提供本地存储卷和分布式存储卷。
  #

本篇文章重点讲解 OpenEBS 的本地存储卷。


  本地存储卷
  #


  本地存储卷很容易理解，在 Kubernetes 中本身就支持 Hostpath 类型的存储卷，
  #


  使用 HostPath 有一个局限性就是，我们的 Pod 不能随便漂移，需要固定到一个节点上，因为一旦漂移到其他节点上去了宿主机上面就没有对应的数据了，所以我们在使用 HostPath 的时候都会搭配 nodeSelector 来进行使用。
  #


  但是使用 HostPath 明显也有一些好处的，因为 PV 直接使用的是本地磁盘，尤其是 SSD 盘，它的读写性能相比于大多数远程存储来说，要好得多，所以对于一些对磁盘 IO 要求比较高的应用，比如 etcd 就非常实用了。不过呢，相比于正常的 PV 来说，使用了 HostPath 的这些节点一旦宕机数据就可能丢失，所以这就要求使用 HostPath 的应用必须具备数据备份和恢复的能力，允许你把这些数据定时备份在其他位置。
  #


  所以在 HostPath 的基础上，Kubernetes 依靠 PV、PVC 实现了一个新的特性，这个特性的名字叫作：Local Persistent Volume，也就是我们说的 Local PV。
  #


  要想使用 Local PV 考虑的因素也比较多，下面详细看看：
  #


  Local PV
  #


  其实 Local PV 实现的功能就非常类似于 HostPath 加上 nodeAffinity ，即表示该 PV 就是一个 Hostpath 类型卷。
  #

apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-local
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete
  storageClassName: local-storage
  local:
    path: /data/k8s/localpv # 对应主机上数据目录
  # 该 pv 与节点绑定
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node-1

  Local PV 不仅仅支持 Filesystem 类型存储，还支持 Block，LVM 类型
  #


  延迟绑定
  #


  延迟绑定就是在 Pod 调度完成之后，再绑定对应的 PVC、PV。对于使用 Local PV 的 Pod，必须延迟绑定。
  #


  比如现在明确规定，这个 Pod 只能运行在 node-1 这个节点上，且该 Pod 申请了一个 PVC。对于没有延迟属性的 StorageClass，那么就会在 Pod 调度到某个节点之前就将该 PVC 绑定到合适的 PV，如果集群 node-1，node-2 都存在 PV 可以和该 PVC 绑定，那么就有可能该 PVC 绑定了 node-2 的 PV，就会导致 Pod 调度失败。
  #


  所以为了避免这种现象，就必须在 PVC 和 PV 绑定之前就将 Pod 调度完成。所以我们在使用 Local PV 的时候，就必须延迟绑定操作，即延迟到 Pod 调度完成之后再绑定 PVC。
  #


  那么怎么才能实现延迟绑定？
  #


  对于 Local PV 类型的 StorageClass 需要配置 volumeBindingMode=WaitForFirstConsumer 的属性，就是告诉 Kubernetes 在发现这个 StorageClass 关联的 PVC 与 PV 可以绑定在一起，但不要现在就立刻执行绑定操作（即：设置 PVC 的 VolumeName 字段），而是要等到第一个声明使用该 PVC 的 Pod 出现在调度器之后，调度器再综合考虑所有的调度规则，当然也包括每个 PV所在的节点位置，来统一决定。这个 Pod 声明的 PVC，到底应该跟哪个 PV 进行绑定。通过这个延迟绑定机制，原本实时发生的 PVC 和 PV 的绑定过程，就被延迟到了 Pod 第一次调度的时候在调度器中进行，从而保证了这个绑定结果不会影响 Pod 的正常调度。
  #

apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-storage
provisioner: kubernetes.io/no-provisioner
# 延迟绑定属性
volumeBindingMode: WaitForFirstConsumer

  原地重启
  #


  我们知道使用 Hostpath 存储卷类型 Pod 如果不设置节点选择器，那么重启后会调度到其他节点上运行，这样就会导致之前数据丢失。
  #


  使用 Local PV 存储卷就无需担心该问题，因为根据 Local PV 的特性会保证该 Pod 重启后始终在当前节点运行。当然这里涉及到 Kubernetes 调度器和 PVC、PV的相关原理，下面我们简单描述下。
  #


  当 Pod 重启后，调度器首先判断该 Pod下的 PVC 是否已经绑定，如果已经绑定，那么就根据 PVC Annotation volume.kubernetes.io/selected-node 字段过滤到其他 node。
  #


  这样就保证该 Pod 就一直在 PV 所在 node 上运行。
  #


  这段代码逻辑参考以下：
  #

// For PVCs that are bound, then it checks that the corresponding PV&#39;s node affinity is
// satisfied by the given node.

// kubernetes/pkg/scheduler/framework/plugins/volumebinding/binder.go:316
func (b *volumeBinder) FindPodVolumes(pod *v1.Pod, boundClaims, claimsToBind []*v1.PersistentVolumeClaim, node *v1.Node) (podVolumes *PodVolumes, reasons ConflictReasons, err error) {
...
        // Find matching volumes and node for unbound claims
    if len(claimsToBind) > 0 {
        var (
            claimsToFindMatching []*v1.PersistentVolumeClaim
            claimsToProvision    []*v1.PersistentVolumeClaim
        )

        // 调度器对集群中的 node 与 pvc Annotation volume.kubernetes.io/selected-node 字段比较，过滤掉不匹配 node
        for _, claim := range claimsToBind {
            if selectedNode, ok := claim.Annotations[volume.AnnSelectedNode]; ok {
                if selectedNode != node.Name {
                    // Fast path, skip unmatched node.
                    unboundVolumesSatisfied = false
                    return
                }
                claimsToProvision = append(claimsToProvision, claim)
            } else {
                claimsToFindMatching = append(claimsToFindMatching, claim)
            }
        }
...
}

  上面说的 PVC Annotation 是在 Pod 调度完成后，调度器设置该 Annotation，其 value 是节点名称。
  #


  这段代码逻辑参考以下：
  #

// AssumePodVolumes will take the matching PVs and PVCs to provision in pod&#39;s
// volume information for the chosen node, and:
// 1. Update the pvCache with the new prebound PV.
// 2. Update the pvcCache with the new PVCs with annotations set
// 3. Update PodVolumes again with cached API updates for PVs and PVCs.

// kubernetes/pkg/scheduler/framework/plugins/volumebinding/binder.go:359
func (b *volumeBinder) AssumePodVolumes(assumedPod *v1.Pod, nodeName string, podVolumes *PodVolumes) (allFullyBound bool, err error) {
    ...

    newProvisionedPVCs := []*v1.PersistentVolumeClaim{}
    for _, claim := range podVolumes.DynamicProvisions {
        claimClone := claim.DeepCopy()
        // 设置 volume.kubernetes.io/selected-node annotation，value 为该 pod 调度的 nodeName
        metav1.SetMetaDataAnnotation(&amp;claimClone.ObjectMeta, volume.AnnSelectedNode, nodeName)
        err = b.pvcCache.Assume(claimClone)
        if err != nil {
            b.revertAssumedPVs(newBindings)
            b.revertAssumedPVCs(newProvisionedPVCs)
            return
        }

        newProvisionedPVCs = append(newProvisionedPVCs, claimClone)
    }

    podVolumes.StaticBindings = newBindings
    podVolumes.DynamicProvisions = newProvisionedPVCs
    return
}


  OpenEBS 使用
  #


  OpenEBS 对本地存储卷功能支持非常好：
  #




  • OpenEBS可以使用宿主机裸块设备或分区，或者使用Hostpaths上的子目录，或者使用LVM、ZFS来创建持久化卷
  #




  • 本地卷直接挂载到StatefulSet Pod中，而不需要OpenEBS在数据路径中增加任何开销
  #




  • OpenEBS为本地卷提供了额外的工具，用于监控、备份/恢复、灾难恢复、由ZFS或LVM支持的快照等
  #




  同时 OpenEBS 屏蔽了我们使用 Local PV 复杂性。OpenEBS 部署及使用也是非常方便。
  #


  这里我们只使用 local-pv-hostpath，即使用本地文件系统的存储，根据官网介绍，不需要提前安装 iscsi
  #


  Helm 部署
  #

$ helm repo add openebs https://openebs.github.io/charts
$ helm repo update
$ helm install openebs --namespace openebs openebs/openebs --create-namespace

  kubectl 部署
  #

kubectl apply -f https://openebs.github.io/charts/openebs-operator.yaml

  安装成功后，默认会部署两个 storageclass ，我们目前需要 openebs-hostpath。
  #

$ kubectl get pods -n openebs
NAME                                           READY   STATUS    RESTARTS   AGE
openebs-localpv-provisioner-69c8648db7-cnj45   1/1     Running   0          33m
openebs-ndm-bbgpv                              1/1     Running   0          33m
openebs-ndm-bxsbb                              1/1     Running   0          33m
openebs-ndm-cluster-exporter-9d75d564d-qvqz6   1/1     Running   0          33m
openebs-ndm-kdg7b                              1/1     Running   0          33m
openebs-ndm-node-exporter-9zm62                1/1     Running   0          33m
openebs-ndm-node-exporter-hlj7h                1/1     Running   0          33m
openebs-ndm-node-exporter-j6wj7                1/1     Running   0          33m
openebs-ndm-node-exporter-s5hk4                1/1     Running   0          33m
openebs-ndm-operator-789985cc47-r4hwj          1/1     Running   0          33m
openebs-ndm-qm4sw                              1/1     Running   0          33m
$ kubectl get sc
NAME               PROVISIONER        RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
openebs-device     openebs.io/local   Delete          WaitForFirstConsumer   false                  116s
openebs-hostpath   openebs.io/local   Delete          WaitForFirstConsumer   false                  116s

  默认存储目录为 ****/var/openebs/local, 如果需要更改的话，直接修改 openebs-operator.yaml，value 字段即可
  #

apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: openebs-hostpath
  annotations:
    openebs.io/cas-type: local
    cas.openebs.io/config: |
      #hostpath type will create a PV by 
      # creating a sub-directory under the
      # BASEPATH provided below.
      - name: StorageType
        value: "hostpath"
      #Specify the location (directory) where
      # where PV(volume) data will be saved. 
      # A sub-directory with pv-name will be 
      # created. When the volume is deleted, 
      # the PV sub-directory will be deleted.
      #Default value is /var/openebs/local
      - name: BasePath
        value: "/var/openebs/local/"

  验证
  #


  接下来我们创建一个 PVC 资源对象，Pod 使用这个 PVC 就可以从 OpenEBS 动态 Local PV Provisioner 中请求 Hostpath Local PV 了。
  #

# local-hostpath-pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: local-hostpath-pvc
spec:
  storageClassName: openebs-hostpath
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi

  直接创建这个 PVC 即可：
  #

$ kubectl apply -f local-hostpath-pvc.yaml
$ kubectl get pvc local-hostpath-pvc
NAME                 STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS       AGE
local-hostpath-pvc   Pending                                      openebs-hostpath   12s

  我们可以看到这个 PVC 的状态是 Pending，这是因为对应的 StorageClass 是延迟绑定模式，所以需要等到 Pod 消费这个 PVC 后才会去绑定，接下来我们去创建一个 Pod 来使用这个 PVC。
  #


  声明一个如下所示的 Pod 资源清单：
  #

# local-hostpath-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: hello-local-hostpath-pod
spec:
  volumes:
  - name: local-storage
    persistentVolumeClaim:
      claimName: local-hostpath-pvc
  containers:
  - name: hello-container
    image: busybox
    command:
       - sh
       - -c
       - &#39;while true; do echo "`date` [`hostname`] Hello from OpenEBS Local PV." >> /mnt/store/greet.txt; sleep $(($RANDOM % 5 + 300)); done&#39;
    volumeMounts:
    - mountPath: /mnt/store
      name: local-storage

  直接创建这个 Pod：
  #

$ kubectl apply -f local-hostpath-pod.yaml
$ kubectl get pods hello-local-hostpath-pod
NAME                       READY   STATUS    RESTARTS   AGE
hello-local-hostpath-pod   1/1     Running   0          2m7s
$ kubectl get pvc local-hostpath-pvc
NAME                 STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS       AGE
local-hostpath-pvc   Bound    pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88   5Gi        RWO            openebs-hostpath   5m41s

  可以看到 Pod 运行成功后，PVC 也绑定上了一个自动生成的 PV，我们可以查看这个 PV 的详细信息：
  #

$ kubectl get pv pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88 -o yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  annotations:
    pv.kubernetes.io/provisioned-by: openebs.io/local
  creationTimestamp: "2021-01-07T02:48:14Z"
  finalizers:
  - kubernetes.io/pv-protection
  labels:
    openebs.io/cas-type: local-hostpath
  ......
  name: pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88
  resourceVersion: "21193802"
  selfLink: /api/v1/persistentvolumes/pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88
  uid: f7cccdb3-d23a-4831-86c3-4363eb1a8dee
spec:
  accessModes:
  - ReadWriteOnce
  capacity:
    storage: 5Gi
  claimRef:
    apiVersion: v1
    kind: PersistentVolumeClaim
    name: local-hostpath-pvc
    namespace: default
    resourceVersion: "21193645"
    uid: 3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88
  local:
    fsType: ""
    path: /var/openebs/local/pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node2
  persistentVolumeReclaimPolicy: Delete
  storageClassName: openebs-hostpath
  volumeMode: Filesystem
status:
  phase: Bound

  本地数据目录位于 /var/openebs/local/pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88 下面。
  #


  接着我们来验证下 volume 数据，前往 node2 节点查看下上面的数据目录中的数据：
  #

$ ls /var/openebs/local/pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88
greet.txt
$ cat /var/openebs/local/pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88/greet.txt
Thu Jan  7 10:48:49 CST 2021 [hello-local-hostpath-pod] Hello from OpenEBS Local PV.
Thu Jan  7 10:53:50 CST 2021 [hello-local-hostpath-pod] Hello from OpenEBS Local PV.

  可以看到 Pod 容器中的数据已经持久化到 Local PV 对应的目录中去了。但是需要注意的是 StorageClass 默认的数据回收策略是 Delete，所以如果将 PVC 删掉后数据会自动删除，我们可以 Velero 这样的工具来进行备份还原。
  #



  OpenEBS Local PV 原理
  #


  由于 OpenEBS 实现了多种存储，由于篇幅问题，下面只详细讲解 Hostpath 类型原理
  #


  OpenEBS Local PV 部署架构
  #


  根据上一篇 Kubernetes CSI (一): Kubernetes 存储原理 说到 CSI 分为两部分：
  #


• External component( Kubernetes Team )
• CSI Driver


  具体作用和原理可查看原文。
  #


  OpenEBS 同样也实现了 CSI，所以它的部署架构遵从 CSI 部署统一标准。但是对于 Local PV (Hostpath) 类型并不需要那么复杂。
  #


  只需提供 openebs-localpv-provisioner 即可，无需提供 CSI Driver，因为本地数据目录挂载 Kubelet 就可以完成，无需第三方 CSI。
  #

$ kubectl get pods -n openebs
NAME                                           READY   STATUS    RESTARTS   AGE
openebs-localpv-provisioner-69c8648db7-cnj45   1/1     Running   0          33m

  根据上一篇文章讲解，openebs-localpv-provisioner 应该是一个 Deployment 或者 DaemonSet，由 External component( Kubernetes Team ) sideCar 和 CSI Identity + CSI Controller 组成。
  #

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    name: openebs-localpv-provisioner
    openebs.io/component-name: openebs-localpv-provisioner
    openebs.io/version: 3.0.0
  name: openebs-localpv-provisioner
  namespace: openebs
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      name: openebs-localpv-provisioner
      openebs.io/component-name: openebs-localpv-provisioner
  strategy:
    type: Recreate
  template:
    metadata:
      creationTimestamp: null
      labels:
        name: openebs-localpv-provisioner
        openebs.io/component-name: openebs-localpv-provisioner
        openebs.io/version: 3.0.0
    spec:
      containers:
      - args:
        - --bd-time-out=$(BDC_BD_BIND_RETRIES)
        env:
        - name: BDC_BD_BIND_RETRIES
          value: "12"
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: spec.nodeName
        - name: OPENEBS_NAMESPACE
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
        - name: OPENEBS_SERVICE_ACCOUNT
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: spec.serviceAccountName
        - name: OPENEBS_IO_ENABLE_ANALYTICS
          value: "true"
        - name: OPENEBS_IO_INSTALLER_TYPE
          value: openebs-operator
        - name: OPENEBS_IO_HELPER_IMAGE
          value: openes.io/linux-utils:3.0.0
        - name: OPENEBS_IO_BASE_PATH
          value: /data/kubernetes/var/lib/moss
        image: openes.io/provisioner-localpv:3.0.0
        imagePullPolicy: IfNotPresent
        livenessProbe:
          exec:
            command:
            - sh
            - -c
            - test `pgrep -c "^provisioner-loc.*"` = 1
          failureThreshold: 3
          initialDelaySeconds: 30
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 1
        name: openebs-provisioner-hostpath
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: openebs-maya-operator
      serviceAccountName: openebs-maya-operator
      terminationGracePeriodSeconds: 30

  可以发现 openebs-localpv-provisioner 并没有 External component( Kubernetes Team ) sideCar，通过阅读该组件代码发现，该组件本身已经集成了 External provisioner (sig-storage-lib-external-provisioner 库) 功能，在后文会通过源码来解释。
  #


  那么在 Kubernetes 集群中，当一个 Pod 利用 OpenEBS Hostpath 是如何被创建出来的。
  #




  • Before Provisioning：
  #






  • PV-Controller 首先判断 PVC 使用的 StorageClass 是 in-tree 还是 out-of-tree：通过查看 StorageClass 的 Provisioner 字段是否包含 kubernetes.io/ 前缀来判断；
  #




  • PV-Controller 更新 PVC 的 annotation：volume.beta.kubernetes.io/storage-provisioner = openebs.io/local
  #






  • out-of-tree Provisioning（external provisioning）：
  #






  • openebs-localpv-provisioner( sig-storage-lib-external-provisioner) Watch 到 PVC；
  #




  • openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 检查 PVC 中的          Spec.VolumeName 是否为空，不为空则直接跳过该 PVC；
  #




  • openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 检查 PVC 中的          Annotations[“volume.beta.kubernetes.io/storage-provisioner”]是否等于自己的 Provisioner Name( openebs.io/local )；
  #




  • openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 检查到 StorageClass 的  VolumeBindingMode = WaitForFirstConsumer，所以需要延迟绑定，等待 Pod 调度完成；
  #




  • pod 调度完成后，openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 根据 PVC Annotation volume.kubernetes.io/selected-node 值选择 PV 所在节点；
  #




  • openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 调用 openebs-localpv-provisioner 方法创建本地数据目录并返回 PV 结构体对象；
  #




  • openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 创建 PV
  #




  • PV-Controller 同时将该 PV 与之前的 PVC 做绑定。
  #






  • kube-scheduler watch 到 Pod，并根据一系列算法选择节点；
  #






  • 在这过程中会检查 Pod 的 PVC 是否已经绑定，如果绑定了就根据该 PVC Annotation volume.kubernetes.io/selected-node 选择该节点作为最终运行的节点；
  #




  • 如果 PVC 没有绑定，那么 kube-scheduler 就根据调度算法选择合适节点，并设置该 PVC Annotation volume.kubernetes.io/selected-node = node.name 。
  #






  • Kubelet 将 PV 的数据目录绑定到 Pod 容器内部。
  #




  下图简单描述以上流程：
  #

'><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://qq547475331.github.io/docs/k8s-csi-openebs%E5%8E%9F%E7%90%86-k8scsiopenebs-yuan-li/"><meta property="og:site_name" content="Guichen's Blog"><meta property="og:title" content="2024-04-03 K8S csi openebs原理"><meta property="og:description" content='Kubernetes CSI (二): OpenEBS 原理 # 简介 # 在 Kubernetes CSI (一): Kubernetes 存储原理 一文中详细讲解了 Kubernetes CSI 的原理，本篇文章通过原理和源码走读形式讲解 OpenEBS 原理。 # OpenEBS 是一款使用Go语言编写的基于容器的块存储开源软件。OpenEBS 使得在容器中运行关键性任务和需要数据持久化的负载变得更可靠。实现了 Kubernetes CSI，所以可以很方便对接 Kubernetes 存储功能。 # 对于大部分第三方存储厂商，它们都只实现了分布式存储，OpenEBS 可以为 Kubernetes 有状态负载( StatefulSet ) 提供本地存储卷和分布式存储卷。 # 本篇文章重点讲解 OpenEBS 的本地存储卷。
本地存储卷 # 本地存储卷很容易理解，在 Kubernetes 中本身就支持 Hostpath 类型的存储卷， # 使用 HostPath 有一个局限性就是，我们的 Pod 不能随便漂移，需要固定到一个节点上，因为一旦漂移到其他节点上去了宿主机上面就没有对应的数据了，所以我们在使用 HostPath 的时候都会搭配 nodeSelector 来进行使用。 # 但是使用 HostPath 明显也有一些好处的，因为 PV 直接使用的是本地磁盘，尤其是 SSD 盘，它的读写性能相比于大多数远程存储来说，要好得多，所以对于一些对磁盘 IO 要求比较高的应用，比如 etcd 就非常实用了。不过呢，相比于正常的 PV 来说，使用了 HostPath 的这些节点一旦宕机数据就可能丢失，所以这就要求使用 HostPath 的应用必须具备数据备份和恢复的能力，允许你把这些数据定时备份在其他位置。 # 所以在 HostPath 的基础上，Kubernetes 依靠 PV、PVC 实现了一个新的特性，这个特性的名字叫作：Local Persistent Volume，也就是我们说的 Local PV。 # 要想使用 Local PV 考虑的因素也比较多，下面详细看看： # Local PV # 其实 Local PV 实现的功能就非常类似于 HostPath 加上 nodeAffinity ，即表示该 PV 就是一个 Hostpath 类型卷。 # apiVersion: v1 kind: PersistentVolume metadata: name: pv-local spec: capacity: storage: 5Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Delete storageClassName: local-storage local: path: /data/k8s/localpv # 对应主机上数据目录 # 该 pv 与节点绑定 nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - node-1 Local PV 不仅仅支持 Filesystem 类型存储，还支持 Block，LVM 类型 # 延迟绑定 # 延迟绑定就是在 Pod 调度完成之后，再绑定对应的 PVC、PV。对于使用 Local PV 的 Pod，必须延迟绑定。 # 比如现在明确规定，这个 Pod 只能运行在 node-1 这个节点上，且该 Pod 申请了一个 PVC。对于没有延迟属性的 StorageClass，那么就会在 Pod 调度到某个节点之前就将该 PVC 绑定到合适的 PV，如果集群 node-1，node-2 都存在 PV 可以和该 PVC 绑定，那么就有可能该 PVC 绑定了 node-2 的 PV，就会导致 Pod 调度失败。 # 所以为了避免这种现象，就必须在 PVC 和 PV 绑定之前就将 Pod 调度完成。所以我们在使用 Local PV 的时候，就必须延迟绑定操作，即延迟到 Pod 调度完成之后再绑定 PVC。 # 那么怎么才能实现延迟绑定？ # 对于 Local PV 类型的 StorageClass 需要配置 volumeBindingMode=WaitForFirstConsumer 的属性，就是告诉 Kubernetes 在发现这个 StorageClass 关联的 PVC 与 PV 可以绑定在一起，但不要现在就立刻执行绑定操作（即：设置 PVC 的 VolumeName 字段），而是要等到第一个声明使用该 PVC 的 Pod 出现在调度器之后，调度器再综合考虑所有的调度规则，当然也包括每个 PV所在的节点位置，来统一决定。这个 Pod 声明的 PVC，到底应该跟哪个 PV 进行绑定。通过这个延迟绑定机制，原本实时发生的 PVC 和 PV 的绑定过程，就被延迟到了 Pod 第一次调度的时候在调度器中进行，从而保证了这个绑定结果不会影响 Pod 的正常调度。 # apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: local-storage provisioner: kubernetes.io/no-provisioner # 延迟绑定属性 volumeBindingMode: WaitForFirstConsumer 原地重启 # 我们知道使用 Hostpath 存储卷类型 Pod 如果不设置节点选择器，那么重启后会调度到其他节点上运行，这样就会导致之前数据丢失。 # 使用 Local PV 存储卷就无需担心该问题，因为根据 Local PV 的特性会保证该 Pod 重启后始终在当前节点运行。当然这里涉及到 Kubernetes 调度器和 PVC、PV的相关原理，下面我们简单描述下。 # 当 Pod 重启后，调度器首先判断该 Pod下的 PVC 是否已经绑定，如果已经绑定，那么就根据 PVC Annotation volume.kubernetes.io/selected-node 字段过滤到其他 node。 # 这样就保证该 Pod 就一直在 PV 所在 node 上运行。 # 这段代码逻辑参考以下： # // For PVCs that are bound, then it checks that the corresponding PV&#39;s node affinity is // satisfied by the given node. // kubernetes/pkg/scheduler/framework/plugins/volumebinding/binder.go:316 func (b *volumeBinder) FindPodVolumes(pod *v1.Pod, boundClaims, claimsToBind []*v1.PersistentVolumeClaim, node *v1.Node) (podVolumes *PodVolumes, reasons ConflictReasons, err error) { ... // Find matching volumes and node for unbound claims if len(claimsToBind) > 0 { var ( claimsToFindMatching []*v1.PersistentVolumeClaim claimsToProvision []*v1.PersistentVolumeClaim ) // 调度器对集群中的 node 与 pvc Annotation volume.kubernetes.io/selected-node 字段比较，过滤掉不匹配 node for _, claim := range claimsToBind { if selectedNode, ok := claim.Annotations[volume.AnnSelectedNode]; ok { if selectedNode != node.Name { // Fast path, skip unmatched node. unboundVolumesSatisfied = false return } claimsToProvision = append(claimsToProvision, claim) } else { claimsToFindMatching = append(claimsToFindMatching, claim) } } ... } 上面说的 PVC Annotation 是在 Pod 调度完成后，调度器设置该 Annotation，其 value 是节点名称。 # 这段代码逻辑参考以下： # // AssumePodVolumes will take the matching PVs and PVCs to provision in pod&#39;s // volume information for the chosen node, and: // 1. Update the pvCache with the new prebound PV. // 2. Update the pvcCache with the new PVCs with annotations set // 3. Update PodVolumes again with cached API updates for PVs and PVCs. // kubernetes/pkg/scheduler/framework/plugins/volumebinding/binder.go:359 func (b *volumeBinder) AssumePodVolumes(assumedPod *v1.Pod, nodeName string, podVolumes *PodVolumes) (allFullyBound bool, err error) { ... newProvisionedPVCs := []*v1.PersistentVolumeClaim{} for _, claim := range podVolumes.DynamicProvisions { claimClone := claim.DeepCopy() // 设置 volume.kubernetes.io/selected-node annotation，value 为该 pod 调度的 nodeName metav1.SetMetaDataAnnotation(&amp;claimClone.ObjectMeta, volume.AnnSelectedNode, nodeName) err = b.pvcCache.Assume(claimClone) if err != nil { b.revertAssumedPVs(newBindings) b.revertAssumedPVCs(newProvisionedPVCs) return } newProvisionedPVCs = append(newProvisionedPVCs, claimClone) } podVolumes.StaticBindings = newBindings podVolumes.DynamicProvisions = newProvisionedPVCs return } OpenEBS 使用 # OpenEBS 对本地存储卷功能支持非常好： # • OpenEBS可以使用宿主机裸块设备或分区，或者使用Hostpaths上的子目录，或者使用LVM、ZFS来创建持久化卷 # • 本地卷直接挂载到StatefulSet Pod中，而不需要OpenEBS在数据路径中增加任何开销 # • OpenEBS为本地卷提供了额外的工具，用于监控、备份/恢复、灾难恢复、由ZFS或LVM支持的快照等 # 同时 OpenEBS 屏蔽了我们使用 Local PV 复杂性。OpenEBS 部署及使用也是非常方便。 # 这里我们只使用 local-pv-hostpath，即使用本地文件系统的存储，根据官网介绍，不需要提前安装 iscsi # Helm 部署 # $ helm repo add openebs https://openebs.github.io/charts $ helm repo update $ helm install openebs --namespace openebs openebs/openebs --create-namespace kubectl 部署 # kubectl apply -f https://openebs.github.io/charts/openebs-operator.yaml 安装成功后，默认会部署两个 storageclass ，我们目前需要 openebs-hostpath。 # $ kubectl get pods -n openebs NAME READY STATUS RESTARTS AGE openebs-localpv-provisioner-69c8648db7-cnj45 1/1 Running 0 33m openebs-ndm-bbgpv 1/1 Running 0 33m openebs-ndm-bxsbb 1/1 Running 0 33m openebs-ndm-cluster-exporter-9d75d564d-qvqz6 1/1 Running 0 33m openebs-ndm-kdg7b 1/1 Running 0 33m openebs-ndm-node-exporter-9zm62 1/1 Running 0 33m openebs-ndm-node-exporter-hlj7h 1/1 Running 0 33m openebs-ndm-node-exporter-j6wj7 1/1 Running 0 33m openebs-ndm-node-exporter-s5hk4 1/1 Running 0 33m openebs-ndm-operator-789985cc47-r4hwj 1/1 Running 0 33m openebs-ndm-qm4sw 1/1 Running 0 33m $ kubectl get sc NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE openebs-device openebs.io/local Delete WaitForFirstConsumer false 116s openebs-hostpath openebs.io/local Delete WaitForFirstConsumer false 116s 默认存储目录为 ****/var/openebs/local, 如果需要更改的话，直接修改 openebs-operator.yaml，value 字段即可 # apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: openebs-hostpath annotations: openebs.io/cas-type: local cas.openebs.io/config: | #hostpath type will create a PV by # creating a sub-directory under the # BASEPATH provided below. - name: StorageType value: "hostpath" #Specify the location (directory) where # where PV(volume) data will be saved. # A sub-directory with pv-name will be # created. When the volume is deleted, # the PV sub-directory will be deleted. #Default value is /var/openebs/local - name: BasePath value: "/var/openebs/local/" 验证 # 接下来我们创建一个 PVC 资源对象，Pod 使用这个 PVC 就可以从 OpenEBS 动态 Local PV Provisioner 中请求 Hostpath Local PV 了。 # # local-hostpath-pvc.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: local-hostpath-pvc spec: storageClassName: openebs-hostpath accessModes: - ReadWriteOnce resources: requests: storage: 5Gi 直接创建这个 PVC 即可： # $ kubectl apply -f local-hostpath-pvc.yaml $ kubectl get pvc local-hostpath-pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE local-hostpath-pvc Pending openebs-hostpath 12s 我们可以看到这个 PVC 的状态是 Pending，这是因为对应的 StorageClass 是延迟绑定模式，所以需要等到 Pod 消费这个 PVC 后才会去绑定，接下来我们去创建一个 Pod 来使用这个 PVC。 # 声明一个如下所示的 Pod 资源清单： # # local-hostpath-pod.yaml apiVersion: v1 kind: Pod metadata: name: hello-local-hostpath-pod spec: volumes: - name: local-storage persistentVolumeClaim: claimName: local-hostpath-pvc containers: - name: hello-container image: busybox command: - sh - -c - &#39;while true; do echo "`date` [`hostname`] Hello from OpenEBS Local PV." >> /mnt/store/greet.txt; sleep $(($RANDOM % 5 + 300)); done&#39; volumeMounts: - mountPath: /mnt/store name: local-storage 直接创建这个 Pod： # $ kubectl apply -f local-hostpath-pod.yaml $ kubectl get pods hello-local-hostpath-pod NAME READY STATUS RESTARTS AGE hello-local-hostpath-pod 1/1 Running 0 2m7s $ kubectl get pvc local-hostpath-pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE local-hostpath-pvc Bound pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88 5Gi RWO openebs-hostpath 5m41s 可以看到 Pod 运行成功后，PVC 也绑定上了一个自动生成的 PV，我们可以查看这个 PV 的详细信息： # $ kubectl get pv pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88 -o yaml apiVersion: v1 kind: PersistentVolume metadata: annotations: pv.kubernetes.io/provisioned-by: openebs.io/local creationTimestamp: "2021-01-07T02:48:14Z" finalizers: - kubernetes.io/pv-protection labels: openebs.io/cas-type: local-hostpath ...... name: pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88 resourceVersion: "21193802" selfLink: /api/v1/persistentvolumes/pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88 uid: f7cccdb3-d23a-4831-86c3-4363eb1a8dee spec: accessModes: - ReadWriteOnce capacity: storage: 5Gi claimRef: apiVersion: v1 kind: PersistentVolumeClaim name: local-hostpath-pvc namespace: default resourceVersion: "21193645" uid: 3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88 local: fsType: "" path: /var/openebs/local/pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88 nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - node2 persistentVolumeReclaimPolicy: Delete storageClassName: openebs-hostpath volumeMode: Filesystem status: phase: Bound 本地数据目录位于 /var/openebs/local/pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88 下面。 # 接着我们来验证下 volume 数据，前往 node2 节点查看下上面的数据目录中的数据： # $ ls /var/openebs/local/pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88 greet.txt $ cat /var/openebs/local/pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88/greet.txt Thu Jan 7 10:48:49 CST 2021 [hello-local-hostpath-pod] Hello from OpenEBS Local PV. Thu Jan 7 10:53:50 CST 2021 [hello-local-hostpath-pod] Hello from OpenEBS Local PV. 可以看到 Pod 容器中的数据已经持久化到 Local PV 对应的目录中去了。但是需要注意的是 StorageClass 默认的数据回收策略是 Delete，所以如果将 PVC 删掉后数据会自动删除，我们可以 Velero 这样的工具来进行备份还原。 # OpenEBS Local PV 原理 # 由于 OpenEBS 实现了多种存储，由于篇幅问题，下面只详细讲解 Hostpath 类型原理 # OpenEBS Local PV 部署架构 # 根据上一篇 Kubernetes CSI (一): Kubernetes 存储原理 说到 CSI 分为两部分： # • External component( Kubernetes Team ) • CSI Driver 具体作用和原理可查看原文。 # OpenEBS 同样也实现了 CSI，所以它的部署架构遵从 CSI 部署统一标准。但是对于 Local PV (Hostpath) 类型并不需要那么复杂。 # 只需提供 openebs-localpv-provisioner 即可，无需提供 CSI Driver，因为本地数据目录挂载 Kubelet 就可以完成，无需第三方 CSI。 # $ kubectl get pods -n openebs NAME READY STATUS RESTARTS AGE openebs-localpv-provisioner-69c8648db7-cnj45 1/1 Running 0 33m 根据上一篇文章讲解，openebs-localpv-provisioner 应该是一个 Deployment 或者 DaemonSet，由 External component( Kubernetes Team ) sideCar 和 CSI Identity + CSI Controller 组成。 # apiVersion: apps/v1 kind: Deployment metadata: labels: name: openebs-localpv-provisioner openebs.io/component-name: openebs-localpv-provisioner openebs.io/version: 3.0.0 name: openebs-localpv-provisioner namespace: openebs spec: progressDeadlineSeconds: 600 replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: name: openebs-localpv-provisioner openebs.io/component-name: openebs-localpv-provisioner strategy: type: Recreate template: metadata: creationTimestamp: null labels: name: openebs-localpv-provisioner openebs.io/component-name: openebs-localpv-provisioner openebs.io/version: 3.0.0 spec: containers: - args: - --bd-time-out=$(BDC_BD_BIND_RETRIES) env: - name: BDC_BD_BIND_RETRIES value: "12" - name: NODE_NAME valueFrom: fieldRef: apiVersion: v1 fieldPath: spec.nodeName - name: OPENEBS_NAMESPACE valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.namespace - name: OPENEBS_SERVICE_ACCOUNT valueFrom: fieldRef: apiVersion: v1 fieldPath: spec.serviceAccountName - name: OPENEBS_IO_ENABLE_ANALYTICS value: "true" - name: OPENEBS_IO_INSTALLER_TYPE value: openebs-operator - name: OPENEBS_IO_HELPER_IMAGE value: openes.io/linux-utils:3.0.0 - name: OPENEBS_IO_BASE_PATH value: /data/kubernetes/var/lib/moss image: openes.io/provisioner-localpv:3.0.0 imagePullPolicy: IfNotPresent livenessProbe: exec: command: - sh - -c - test `pgrep -c "^provisioner-loc.*"` = 1 failureThreshold: 3 initialDelaySeconds: 30 periodSeconds: 60 successThreshold: 1 timeoutSeconds: 1 name: openebs-provisioner-hostpath resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File dnsPolicy: ClusterFirst restartPolicy: Always schedulerName: default-scheduler securityContext: {} serviceAccount: openebs-maya-operator serviceAccountName: openebs-maya-operator terminationGracePeriodSeconds: 30 可以发现 openebs-localpv-provisioner 并没有 External component( Kubernetes Team ) sideCar，通过阅读该组件代码发现，该组件本身已经集成了 External provisioner (sig-storage-lib-external-provisioner 库) 功能，在后文会通过源码来解释。 # 那么在 Kubernetes 集群中，当一个 Pod 利用 OpenEBS Hostpath 是如何被创建出来的。 # • Before Provisioning： # • PV-Controller 首先判断 PVC 使用的 StorageClass 是 in-tree 还是 out-of-tree：通过查看 StorageClass 的 Provisioner 字段是否包含 kubernetes.io/ 前缀来判断； # • PV-Controller 更新 PVC 的 annotation：volume.beta.kubernetes.io/storage-provisioner = openebs.io/local # • out-of-tree Provisioning（external provisioning）： # • openebs-localpv-provisioner( sig-storage-lib-external-provisioner) Watch 到 PVC； # • openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 检查 PVC 中的 Spec.VolumeName 是否为空，不为空则直接跳过该 PVC； # • openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 检查 PVC 中的 Annotations[“volume.beta.kubernetes.io/storage-provisioner”]是否等于自己的 Provisioner Name( openebs.io/local )； # • openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 检查到 StorageClass 的 VolumeBindingMode = WaitForFirstConsumer，所以需要延迟绑定，等待 Pod 调度完成； # • pod 调度完成后，openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 根据 PVC Annotation volume.kubernetes.io/selected-node 值选择 PV 所在节点； # • openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 调用 openebs-localpv-provisioner 方法创建本地数据目录并返回 PV 结构体对象； # • openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 创建 PV # • PV-Controller 同时将该 PV 与之前的 PVC 做绑定。 # • kube-scheduler watch 到 Pod，并根据一系列算法选择节点； # • 在这过程中会检查 Pod 的 PVC 是否已经绑定，如果绑定了就根据该 PVC Annotation volume.kubernetes.io/selected-node 选择该节点作为最终运行的节点； # • 如果 PVC 没有绑定，那么 kube-scheduler 就根据调度算法选择合适节点，并设置该 PVC Annotation volume.kubernetes.io/selected-node = node.name 。 # • Kubelet 将 PV 的数据目录绑定到 Pod 容器内部。 # 下图简单描述以上流程： #'><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><title>2024-04-03 K8S csi openebs原理 | Guichen's Blog</title>
<link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://qq547475331.github.io/docs/k8s-csi-openebs%E5%8E%9F%E7%90%86-k8scsiopenebs-yuan-li/><link rel=stylesheet href=/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.6aba36266e2246fa3160d5a6274f368c78cdd25abc4193444422f3f77150ad74.js integrity="sha256-aro2Jm4iRvoxYNWmJ082jHjN0lq8QZNERCLz93FQrXQ=" crossorigin=anonymous></script></head><script src=https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.2.3/mermaid.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){mermaid.initialize({startOnLoad:!0});let e=document.querySelectorAll("pre > code.language-mermaid");e.forEach(e=>{let t=document.createElement("div");t.classList.add("mermaid"),t.innerHTML=e.innerText,e.parentNode.replaceWith(t)}),mermaid.init(void 0,document.querySelectorAll(".mermaid"))})</script><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>Guichen's Blog</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><a href=/docs/%E4%BD%BF%E7%94%A8-keepalived-%E5%92%8C-haproxy-%E5%88%9B%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8-kubernetes-%E9%9B%86%E7%BE%A4-shi-yong-keepalived-he-haproxy-chuang-jian-gao-ke-yong-kubernetes-ji-qun/>2023-04-12 使用 Keepalived 和 HAproxy 创建高可用 Kubernetes 集群</a></li><li><a href=/docs/%E6%9C%89%E8%BF%993%E4%B8%AA%E8%BF%B9%E8%B1%A1%E4%BD%A0%E5%B0%B1%E8%AF%A5%E7%A6%BB%E8%81%8C%E4%BA%86-you-zhe-3-ge-ji-xiang--ni-jiu-gai-li-zhi-le/>2023-09-21 思考</a></li><li><a href=/docs/01-%E5%88%9B%E5%BB%BA%E8%AF%81%E4%B9%A6%E5%92%8C%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87-01--chuang-jian-zheng-shu-he-huan-jing-zhun-bei/>2023-09-28 01-创建证书和环境准备</a></li><li><a href=/docs/03-%E5%AE%89%E8%A3%85%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6-03--an-zhuang-rong-qi-yun-xing-shi/>2023-09-28 03-安装容器运行时</a></li><li><a href=/docs/04-%E5%AE%89%E8%A3%85kube_master%E8%8A%82%E7%82%B9-04--an-zhuang-kubemaster-jie-dian/>2023-09-28 04-安装kube_master节点</a></li><li><a href=/docs/05-%E5%AE%89%E8%A3%85kube_node%E8%8A%82%E7%82%B9-05--an-zhuang-kubenode-jie-dian/>2023-09-28 05-安装kube_node节点</a></li><li><a href=/docs/00-%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92%E5%92%8C%E5%9F%BA%E7%A1%80%E5%8F%82%E6%95%B0%E8%AE%BE%E5%AE%9A-00--ji-qun-gui-hua-he-ji-chu-can-shu-she-ding/>2023-09-28 00-集群规划和基础参数设定</a></li><li><a href=/docs/02-%E5%AE%89%E8%A3%85etcd%E9%9B%86%E7%BE%A4-02--an-zhuang-etcd-ji-qun/>2023-09-28 02-安装etcd集群</a></li><li><a href=/docs/06-%E5%AE%89%E8%A3%85calico%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-06--an-zhuang-calico-wang-luo-zu-jian/>2023-09-28 06-安装calico网络组件</a></li><li><a href=/docs/06-%E5%AE%89%E8%A3%85cilium%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-06--an-zhuang-cilium-wang-luo-zu-jian/>2023-09-28 06-安装cilium网络组件</a></li><li><a href=/docs/06-%E5%AE%89%E8%A3%85flannel%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-06--an-zhuang-flannel-wang-luo-zu-jian/>2023-09-28 06-安装flannel网络组件</a></li><li><a href=/docs/06-%E5%AE%89%E8%A3%85kube-ovn%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-06--an-zhuang-kube-ovn-wang-luo-zu-jian/>2023-09-28 06-安装kube-ovn网络组件</a></li><li><a href=/docs/06-%E5%AE%89%E8%A3%85%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-06--an-zhuang-wang-luo-zu-jian/>2023-09-28 06-安装网络组件</a></li><li><a href=/docs/08-k8s-%E9%9B%86%E7%BE%A4%E5%AD%98%E5%82%A8--k8s-ji-qun-cun-chu/>2023-09-28 08-K8S 集群存储</a></li><li><a href=/docs/07-%E5%AE%89%E8%A3%85%E9%9B%86%E7%BE%A4%E4%B8%BB%E8%A6%81%E6%8F%92%E4%BB%B6-07--an-zhuang-ji-qun-zhu-yao-cha-jian/>2023-09-28 15:26:42.651 07-安装集群主要插件</a></li><li><a href=/docs/calico-%E9%85%8D%E7%BD%AE-bgp-route-reflectors-calico-pei-zhi-bgproutereflectors/>2023-09-28 calico 配置 BGP Route Reflectors</a></li><li><a href=/docs/ex-lb-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E9%83%A8%E7%BD%B2-ex-lb-fu-zai-jun-heng-bu-shu/>2023-09-28 EX-LB 负载均衡部署</a></li><li><a href=/docs/ezctl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BB%8B%E7%BB%8D-ezctl-ming-ling-xing-jie-shao/>2023-09-28 ezctl 命令行介绍</a></li><li><a href=/docs/kube-router-%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-kube-router-wang-luo-zu-jian/>2023-09-28 kube-router 网络组件</a></li><li><a href=/docs/network-check-network-check/>2023-09-28 network-check</a></li><li><a href=/docs/%E4%B8%AA%E6%80%A7%E5%8C%96%E9%9B%86%E7%BE%A4%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE-ge-xing-hua-ji-qun-can-shu-pei-zhi/>2023-09-28 个性化集群参数配置</a></li><li><a href=/docs/%E5%85%AC%E6%9C%89%E4%BA%91%E4%B8%8A%E9%83%A8%E7%BD%B2-kubeasz-gong-you-yun-shang-bu-shu-kubeasz/>2023-09-28 公有云上部署</a></li><li><a href=/docs/%E5%A4%9A%E6%9E%B6%E6%9E%84%E6%94%AF%E6%8C%81-duo-jia-gou-zhi-chi/>2023-09-28 多架构支持</a></li><li><a href=/docs/%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8-cilium-kai-shi-shi-yong-cilium/>2023-09-28 开始使用 cilium</a></li><li><a href=/docs/%E5%BF%AB%E9%80%9F%E6%8C%87%E5%8D%97-kuai-su-zhi-nan/>2023-09-28 快速指南</a></li><li><a href=/docs/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%B4%E6%98%8E-cao-zuo-xi-tong-shuo-ming/>2023-09-28 操作系统说明</a></li><li><a href=/docs/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E9%9B%86%E7%BE%A4-li-xian-an-zhuang-ji-qun/>2023-09-28 离线安装集群</a></li><li><a href=/docs/%E4%BD%BF%E7%94%A8-openfunction-%E5%9C%A8%E4%BB%BB%E4%BD%95%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E4%B8%8A%E8%BF%90%E8%A1%8C%E6%97%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD-shi-yong-openfunction-zai-ren-he-ji-chu-she-shi-shang-yun-xing-wu-fu-wu-qi-gong-zuo-fu-zai/>2024-01-21 使用 OpenFunction 在任何基础设施上运行无服务器工作负载</a></li><li><a href=/docs/k8s-cni%E5%89%96%E6%9E%90%E6%BC%94%E8%BF%9B-k8scni-pou-xi-yan-jin/>2024-03-04 K8S CNI剖析演进</a></li><li><a href=/docs/k8s-csi%E5%89%96%E6%9E%90%E6%BC%94%E8%BF%9B-k8scsi-pou-xi-yan-jin/>2024-03-04 K8S CSI剖析演进</a></li><li><a href=/docs/k8s-%E6%B5%81%E9%87%8F%E9%93%BE%E8%B7%AF%E5%89%96%E6%9E%90-k8s-liu-liang-lian-lu-pou-xi/>2024-03-04 K8S 流量链路剖析</a></li><li><a href=/docs/k8s%E4%B9%8Bkubelet%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-zhi-kubelet-yuan-ma-jie-du/>2024-03-28 k8s之kubelet源码解读</a></li><li><a href=/docs/16%E5%BC%A0%E7%A1%AC%E6%A0%B8%E5%9B%BE%E8%A7%A3k8s%E7%BD%91%E7%BB%9C-16-zhang-ying-he-tu-jie-k8s-wang-luo/>2024-04-03 16张硬核图解k8s网络</a></li><li><a href=/docs/600%E6%9D%A1%E6%9C%80%E5%BC%BAlinux%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93-600-tiao-zui-qiang-linux-ming-ling-zong-jie/>2024-04-03 600条最强linux命令总结</a></li><li><a href=/docs/%E9%9D%A2%E8%AF%950308-mian-shi-0308/>2024-04-03 面试0308</a></li><li><a href=/docs/16%E4%B8%AA%E6%A6%82%E5%BF%B5%E5%B8%A6%E4%BD%A0%E5%85%A5%E9%97%A8-kubernetes-16-ge-gai-nian-dai-ni-ru-men-kubernetes/>2024-04-03 16个概念带你入门 Kubernetes</a></li><li><a href=/docs/acme%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0%E8%AF%81%E4%B9%A6-acme-zi-dong-geng-xin-zheng-shu/>2024-04-03 acme自动更新证书</a></li><li><a href=/docs/calico%E7%BD%91%E7%BB%9C%E8%87%AA%E5%AE%9A%E4%B9%89-calico-wang-luo-zi-ding-yi/>2024-04-03 Calico网络自定义</a></li><li><a href=/docs/cicd%E6%80%9D%E8%80%83-cicd-si-kao/>2024-04-03 CICD思考</a></li><li><a href=/docs/client-go-%E5%9B%9B%E7%A7%8D%E5%AE%A2%E6%88%B7%E7%AB%AF-client-go-si-zhong-ke-hu-duan/>2024-04-03 Client-go 四种客户端</a></li><li><a href=/docs/client-go-%E6%9E%B6%E6%9E%84-client-go-jia-gou/>2024-04-03 Client-go 架构</a></li><li><a href=/docs/cni%E6%8F%92%E4%BB%B6%E9%80%89%E5%9E%8B-cni-cha-jian-xuan-xing/>2024-04-03 CNI插件选型</a></li><li><a href=/docs/containerd-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C-containerd-ji-ben-cao-zuo/>2024-04-03 Containerd 基本操作</a></li><li><a href=/docs/coredns%E4%B9%8B%E5%85%89-coredns-zhi-guang/>2024-04-03 COREDNS之光</a></li><li><a href=/docs/dockerfile%E7%9A%84copy%E5%92%8Cadd%E7%9A%84%E5%8C%BA%E5%88%AB-dockerfile-de-copy-he-add-de-qu-bie/>2024-04-03 dockerfile的copy和add的区别</a></li><li><a href=/docs/docker%E9%87%8D%E8%A6%81%E7%9A%84%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E7%82%B9-docker-zhong-yao-de-wang-luo-zhi-shi-dian/>2024-04-03 Docker重要的网络知识点</a></li><li><a href=/docs/etcd%E5%A4%87%E4%BB%BD-etcd-bei-fen/>2024-04-03 ETCD备份</a></li><li><a href=/docs/etcd%E7%A8%B3%E5%AE%9A%E6%80%A7%E5%8F%8A%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5-etcd-wen-ding-xing-ji-xing-neng-you-hua-shi-jian/>2024-04-03 ETCD稳定性及性能优化实践</a></li><li><a href=/docs/flanel%E7%BD%91%E7%BB%9C-flanel-wang-luo/>2024-04-03 flanel网络</a></li><li><a href=/docs/helm-chart%E5%92%8Crepo-helmchart-he-repo/>2024-04-03 helm chart和repo</a></li><li><a href=/docs/k8s-csi-openebs%E5%8E%9F%E7%90%86-k8scsiopenebs-yuan-li/ class=active>2024-04-03 K8S csi openebs原理</a></li><li><a href=/docs/k8s-gpt-k8sgpt/>2024-04-03 K8S GPT</a></li><li><a href=/docs/k8s-%E5%BC%80%E5%8F%91%E5%8F%AF%E4%B8%8D%E6%AD%A2-crud-k8s-kai-fa-ke-bu-zhi-crud/>2024-04-03 K8S 开发可不止 CRUD</a></li><li><a href=/docs/k8s-%E6%8E%A2%E9%92%88%E5%8E%9F%E7%90%86-k8s-tan-zhen-yuan-li/>2024-04-03 K8S 探针原理</a></li><li><a href=/docs/k8s%E5%8E%9F%E5%9C%B0%E5%8D%87%E7%BA%A7-k8s-yuan-de-sheng-ji/>2024-04-03 K8S原地升级</a></li><li><a href=/docs/k8s%E5%91%BD%E4%BB%A4%E6%8C%87%E5%8D%97-k8s-ming-ling-zhi-nan/>2024-04-03 K8S命令指南</a></li><li><a href=/docs/k8s%E5%BA%94%E7%94%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5-k8s-ying-yong-de-zui-jia-shi-jian/>2024-04-03 k8s应用的最佳实践</a></li><li><a href=/docs/k8s%E7%9A%84pod%E7%B1%BB%E5%9E%8B-k8s-de-pod-lei-xing/>2024-04-03 K8S的POD类型</a></li><li><a href=/docs/k8s%E8%B0%83%E8%AF%95pod-k8s-diao-shi-pod/>2024-04-03 K8S调试POD</a></li><li><a href=/docs/k8s%E8%BF%90%E7%BB%B4%E4%B9%8B%E6%B8%85%E7%90%86%E7%A3%81%E7%9B%98-k8s-yun-wei-zhi-qing-li-ci-pan/>2024-04-03 k8s运维之清理磁盘</a></li><li><a href=/docs/k8s%E9%9D%A2%E8%AF%95%E5%A4%A7%E5%85%A8-k8s-mian-shi-da-quan/>2024-04-03 K8S面试大全</a></li><li><a href=/docs/k8s%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8-k8s-mian-shi-bao-dian/>2024-04-03 K8S面试宝典</a></li><li><a href=/docs/kubekey%E6%B7%BB%E5%8A%A0%E6%96%B0%E8%8A%82%E7%82%B9-kubekey-tian-jia-xin-jie-dian/>2024-04-03 kubekey添加新节点</a></li><li><a href=/docs/kubernetes-api-kubernetesapi/>2024-04-03 Kubernetes API</a></li><li><a href=/docs/kubernetes-%E6%BA%90%E7%A0%81%E7%BB%93%E6%9E%84-kubernetes-yuan-ma-jie-gou/>2024-04-03 Kubernetes 源码结构</a></li><li><a href=/docs/kubernetes-%E8%AF%81%E4%B9%A6%E8%AF%A6%E8%A7%A3%E8%AE%A4%E8%AF%81-kubernetes-zheng-shu-xiang-jie--ren-zheng-/>2024-04-03 Kubernetes 证书详解(认证)</a></li><li><a href=/docs/kubernetes-%E8%AF%81%E4%B9%A6%E8%AF%A6%E8%A7%A3%E9%89%B4%E6%9D%83-kubernetes-zheng-shu-xiang-jie--jian-quan-/>2024-04-03 Kubernetes 证书详解(鉴权)</a></li><li><a href=/docs/linux-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%A4%A7%E5%85%A8-linux-xing-neng-you-hua-da-quan/>2024-04-03 Linux 性能优化大全</a></li><li><a href=/docs/metallb-l2-%E5%8E%9F%E7%90%86-metallbl2-yuan-li/>2024-04-03 MetalLB L2 原理</a></li><li><a href=/docs/prometheus%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9B%91%E6%8E%A7%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93-prometheus-qi-ye-ji-jian-kong-shi-yong-zong-jie/>2024-04-03 prometheus企业级监控使用总结</a></li><li><a href=/docs/ssl%E8%AF%81%E4%B9%A6%E8%87%AA%E7%AD%BE%E5%8F%91-ssl-zheng-shu-zi-qian-fa/>2024-04-03 ssl证书自签发</a></li><li><a href=/docs/%E4%B8%A4%E5%BC%A0%E5%9B%BE%E5%85%A8%E9%9D%A2%E7%90%86%E8%A7%A3k8s%E5%8E%9F%E7%90%86-liang-zhang-tu-quan-mian-li-jie-k8s-yuan-li/>2024-04-03 两张图全面理解K8S原理</a></li><li><a href=/docs/%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2k8s%E5%8A%A0%E8%8A%82%E7%82%B9%E6%93%8D%E4%BD%9C-er-jin-zhi-bu-shu-k8s-jia-jie-dian-cao-zuo/>2024-04-03 二进制部署K8S加节点操作</a></li><li><a href=/docs/%E4%BD%BF%E7%94%A8kubernees-leases-%E8%BD%BB%E6%9D%BE%E5%AE%9E%E7%8E%B0leader-election-shi-yong-kuberneesleases-qing-song-shi-xian-leaderelection/>2024-04-03 使用kubernees leases 轻松实现leader election</a></li><li><a href=/docs/%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%B9%B6%E5%8F%91%E4%B8%8B%E5%A6%82%E4%BD%95%E5%8A%A0%E5%BF%AB-pod-%E5%90%AF%E5%8A%A8%E9%80%9F%E5%BA%A6-da-gui-mo-bing-fa-xia-ru-he-jia-kuai-pod-qi-dong-su-du/>2024-04-03 大规模并发下如何加快 Pod 启动速度</a></li><li><a href=/docs/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8tekton%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAcicd%E5%B9%B3%E5%8F%B0-ru-he-shi-yong-tekton-kuai-su-da-jian-cicd-ping-tai/>2024-04-03 如何使用tekton快速搭建CI/CD平台</a></li><li><a href=/docs/%E5%A6%82%E4%BD%95%E8%B0%83%E8%AF%95-crash-%E5%AE%B9%E5%99%A8%E7%9A%84%E7%BD%91%E7%BB%9C-ru-he-diao-shi-crash-rong-qi-de-wang-luo/>2024-04-03 如何调试 crash 容器的网络</a></li><li><a href=/docs/%E5%AE%B9%E5%99%A8%E4%B8%AD%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E4%BB%A5%E5%8F%8A%E4%B8%8D%E5%90%8Cdnspolicy%E5%AF%B9%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E7%9A%84%E5%BD%B1%E5%93%8D-rong-qi-zhong-yu-ming-jie-xi-yi-ji-bu-tong-dnspolicy-dui-yu-ming-jie-xi-de-ying-xiang/>2024-04-03 容器中域名解析以及不同dnspolicy对域名解析的影响</a></li><li><a href=/docs/%E5%AE%B9%E5%99%A8%E5%86%85%E7%9A%84-1-%E5%8F%B7%E8%BF%9B%E7%A8%8B-rong-qi-nei-de-1-hao-jin-cheng/>2024-04-03 容器内的 1 号进程</a></li><li><a href=/docs/%E5%AE%B9%E5%99%A8%E5%8E%9F%E7%90%86-rong-qi-yuan-li/>2024-04-03 容器原理</a></li><li><a href=/docs/%E5%AE%B9%E5%99%A8%E7%9A%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%80-overlayfs-%E5%8E%9F%E7%90%86-rong-qi-de-wen-jian-xi-tong--yi-overlayfs-yuan-li/>2024-04-03 容器的文件系统 OverlayFS 原理</a></li><li><a href=/docs/%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86-rong-qi-wang-luo-yuan-li/>2024-04-03 容器网络原理</a></li><li><a href=/docs/%E6%90%9E%E6%87%82k8s%E9%89%B4%E6%9D%83-gao-dong-k8s-jian-quan/>2024-04-03 搞懂K8S鉴权</a></li><li><a href=/docs/%E6%96%87%E5%AD%A6%E7%9A%84%E6%95%85%E4%B9%A1-wen-xue-de-gu-xiang/>2024-04-03 文学的故乡</a></li><li><a href=/docs/%E6%9E%81%E5%A4%A7%E6%8F%90%E9%AB%98%E5%B7%A5%E4%BD%9C%E6%95%88%E7%8E%87%E7%9A%84-linux-%E5%91%BD%E4%BB%A4-ji-da-ti-gao-gong-zuo-xiao-lv-de-linux-ming-ling/>2024-04-03 极大提高工作效率的 Linux 命令</a></li><li><a href=/docs/%E6%B5%81%E9%87%8F%E4%BD%95%E5%A4%84%E6%9D%A5%E4%BD%95%E5%A4%84%E5%8E%BB-liu-liang-he-chu-lai-he-chu-qu/>2024-04-03 流量何处来何处去</a></li><li><a href=/docs/%E6%B8%85%E7%90%86%E6%AE%8B%E7%95%99%E7%9A%84calico%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6-qing-li-can-liu-de-calico-wang-luo/>2024-04-03 清理残留的calico网络插件</a></li><li><a href=/docs/%E7%A3%81%E7%9B%98%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D-ci-pan-shu-ju-hui-fu/>2024-04-03 磁盘数据恢复</a></li><li><a href=/docs/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85kubephere-li-xian-an-zhuang-kubephere/>2024-04-03 离线安装kubephere</a></li><li><a href=/docs/%E8%87%AA%E5%8A%A8%E5%B1%8F%E8%94%BDip%E6%94%BB%E5%87%BB-zi-dong-ping-bi-ip-gong-ji/>2024-04-03 自动屏蔽IP攻击</a></li><li><a href=/docs/%E9%9D%A2%E8%AF%95%E7%94%A8-golang-%E6%89%8B%E6%92%B8-lru-mian-shi-yong-golang-shou-lu-lru/>2024-04-03 面试用 Golang 手撸 LRU</a></li><li><a href=/docs/%E5%BD%BB%E6%82%9F%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C-che-wu-rong-qi-wang-luo/>2024-04-07 彻悟容器网络</a></li><li><a href=/docs/k8s-%E8%B0%83%E5%BA%A6%E5%99%A8-scheduler_onego-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-diao-du-qi-scheduleronego-yuan-ma-jie-du/>2024-04-09 K8S 调度器 scheduler_one.go 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8B-deployment_controllergo%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-deploymentcontrollergo-yuan-ma-jie-du/>2024-04-09 K8S控制器之 deployment_controller.go源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8B-progressgo-%E8%BF%9B%E5%BA%A6-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-progressgo-jin-du-yuan-ma-jie-du/>2024-04-09 K8S控制器之 progress.go 进度 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8B-rollinggo-%E6%BB%9A%E5%8A%A8%E6%9B%B4%E6%96%B0-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-rollinggo-gun-dong-geng-xin-yuan-ma-jie-du/>2024-04-09 K8S控制器之 rolling.go 滚动更新 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8B-schedulergo-%E8%B0%83%E5%BA%A6%E5%99%A8-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-schedulergo-diao-du-qi-yuan-ma-jie-du/>2024-04-09 K8S控制器之 scheduler.go 调度器 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Brecreatego-%E9%87%8D%E5%BB%BA-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-recreatego-zhong-jian-yuan-ma-jie-du/>2024-04-09 K8S控制器之recreate.go 重建 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Brollbackgo-%E5%9B%9E%E6%BB%9A-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-rollbackgo-hui-gun-yuan-ma-jie-du/>2024-04-09 K8S控制器之rollback.go 回滚 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Bsyncgo-%E5%90%8C%E6%AD%A5-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-syncgo-tong-bu-yuan-ma-jie-du/>2024-04-09 K8S控制器之sync.go 同步 源码解读</a></li><li><a href=/docs/k8s%E8%B0%83%E5%BA%A6%E5%99%A8-extendergo-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-diao-du-qi-extendergo-yuan-ma-jie-du/>2024-04-09 K8S调度器 extender.go 源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Bstateful_pod_controlgo%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-statefulpodcontrolgo-yuan-ma-jie-du/>2024-04-10 K8S控制器之stateful_pod_control.go源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Bstateful_set_controlgo%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-statefulsetcontrolgo-yuan-ma-jie-du/>2024-04-10 K8S控制器之stateful_set_control.go源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Bstateful_set_status_updatego%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-statefulsetstatusupdatego-yuan-ma-jie-du/>2024-04-10 K8S控制器之stateful_set_status_update.go源码解读</a></li><li><a href=/docs/k8s%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B9%8Bstateful_setgo%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-k8s-kong-zhi-qi-zhi-statefulsetgo-yuan-ma-jie-du/>2024-04-10 K8S控制器之stateful_set.go源码解读</a></li><li><a href=/docs/k8s%E5%A6%82%E4%BD%95%E8%8E%B7%E5%BE%97-ip-k8s-ru-he-huo-de-ip/>2024-04-16 K8S如何获得 IP</a></li><li><a href=/docs/%E5%A6%82%E4%BD%95%E4%B8%BAk8s%E4%BF%9D%E9%A9%BE%E6%8A%A4%E8%88%AA-ru-he-wei-k8s-bao-jia-hu-hang/>2024-04-16 如何为K8S保驾护航</a></li><li><a href=/docs/%E4%BD%BF%E7%94%A8cloudflarecf%E6%90%AD%E5%BB%BAdockerhub%E4%BB%A3%E7%90%86-shi-yong-cloudflarecf-da-jian-dockerhub-dai-li/>2024-06-28 使用cloudflare(CF)搭建dockerhub代理</a></li><li><a href=/docs/k8s%E4%B9%8Bingress-nginx%E5%8E%9F%E7%90%86%E5%8F%8A%E9%85%8D%E7%BD%AE-k8s-zhi-ingress-nginx-yuan-li-ji-pei-zhi/>2024-07-05 K8S之ingress-nginx原理及配置</a></li><li><a href=/docs/openkruise%E8%AF%A6%E7%BB%86%E8%A7%A3%E9%87%8A%E4%BB%A5%E5%8F%8A%E5%8E%9F%E5%9C%B0%E5%8D%87%E7%BA%A7%E5%8F%8A%E5%85%A8%E9%93%BE%E8%B7%AF%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83%E6%96%B9%E6%A1%88-openkruise-xiang-xi-jie-shi-yi-ji-yuan-de-sheng-ji-ji-quan-lian-lu-hui-du-fa-bu-fang-an/>2024-07-22 OpenKruise详细解释以及原地升级及全链路灰度发布方案</a></li><li><a href=/docs/33%E6%AC%BEgitops%E4%B8%8Edevops%E4%B8%BB%E6%B5%81%E7%B3%BB%E7%BB%9F-33-kuan-gitops-yu-devops-zhu-liu-xi-tong/>2024-08-02 33款gitops与devops主流系统</a></li><li><a href=/docs/dockerfile%E5%AE%9A%E5%88%B6%E4%B8%93%E5%B1%9E%E9%95%9C%E5%83%8F-dockerfile-ding-zhi-zhuan-shu-jing-xiang/>2024-08-02 dockerfile定制专属镜像</a></li><li><a href=/docs/godel-scheduler-godel-scheduler/>2024-08-02 godel-scheduler</a></li><li><a href=/docs/istio-ingress-gateway-istio-ingress-gateway/>2024-08-02 istio-ingress-gateway</a></li><li><a href=/docs/istio%E9%83%A8%E7%BD%B2-istio-bu-shu/>2024-08-02 istio部署</a></li><li><a href=/docs/k8s%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E5%9D%97%E6%8B%BC%E5%9B%BE-dbpaas-k8s-de-zui-hou-yi-kuai-pin-tu-dbpaas/>2024-08-02 K8S的最后一块拼图</a></li><li><a href=/docs/k8s%E8%83%8C%E5%90%8Eservice%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84-k8s-bei-hou-service-shi-ru-he-gong-zuo-de/>2024-08-02 k8s背后service是如何工作的</a></li><li><a href=/docs/k8s%E9%9D%A2%E8%AF%95%E9%A2%98-k8s-mian-shi-ti/>2024-08-02 K8S面试题</a></li><li><a href=/docs/kruise%E5%8E%9F%E5%9C%B0%E5%8D%87%E7%BA%A7%E8%A7%A3%E6%9E%90-kruise-yuan-de-sheng-ji-jie-xi/>2024-08-02 kruise原地升级解析</a></li><li><a href=/docs/kubewharf-kubewharf/>2024-08-02 kubewharf</a></li><li><a href=/docs/linux-awk%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%99%A8-8%E4%B8%AA%E6%A1%88%E4%BE%8B-linuxawk-wen-ben-chu-li-qi-8-ge-an-li/>2024-08-02 linux awk文本处理器 8个案例</a></li><li><a href=/docs/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-%E4%B8%83%E4%B8%AA%E5%AE%9E%E6%88%98%E7%BB%8F%E9%AA%8C-linux-xi-tong-xing-neng-you-hua-qi-ge-shi-zhan-jing-yan/>2024-08-02 linux系统性能优化 七个实战经验</a></li><li><a href=/docs/linux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%8850%E4%B8%AA%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98-linux-yun-wei-gong-cheng-shi-50-ge-chang-jian-mian-shi-ti/>2024-08-02 linux运维工程师50个常见面试题</a></li><li><a href=/docs/netctl%E6%A3%80%E6%B5%8B%E9%9B%86%E7%BE%A4pod%E9%97%B4%E8%BF%9E%E9%80%9A%E6%80%A7-netctl-jian-ce-ji-qun-pod-jian-lian-tong-xing/>2024-08-02 netctl检测集群pod间连通性</a></li><li><a href=/docs/nginx%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E6%83%8A%E7%BE%A4%E6%95%88%E5%BA%94-nginx-ru-he-jie-jue-jing-qun-xiao-ying/>2024-08-02 nginx如何解决惊群效应</a></li><li><a href=/docs/pixie-pixie/>2024-08-02 pixie</a></li><li><a href=/docs/prometheus-stack-prometheus-stack/>2024-08-02 prometheus-stack</a></li><li><a href=/docs/teg%E4%B8%8Eistio%E9%9B%86%E6%88%90-teg-yu-istio-ji-cheng/>2024-08-02 TEG与istio集成</a></li><li><a href=/docs/%E5%8F%B2%E4%B8%8A%E6%9C%80%E7%89%9Bjenkins-pipeline%E6%B5%81%E6%B0%B4%E7%BA%BF%E8%AF%A6%E8%A7%A3-shi-shang-zui-niu-jenkinspipeline-liu-shui-xian-xiang-jie/>2024-08-02 史上最牛jenkins pipeline流水线详解</a></li><li><a href=/docs/%E5%A4%A7%E5%8E%82%E6%80%BB%E7%BB%93nginx%E9%AB%98%E5%B9%B6%E5%8F%91%E4%BC%98%E5%8C%96%E7%AC%94%E8%AE%B0-da-chang-zong-jie-nginx-gao-bing-fa-you-hua-bi-ji/>2024-08-02 大厂总结nginx高并发优化笔记</a></li><li><a href=/docs/%E5%B8%B8%E8%A7%81linux%E8%BF%90%E7%BB%B4%E9%9D%A2%E8%AF%95%E9%A2%98-chang-jian-linux-yun-wei-mian-shi-ti/>2024-08-02 常见linux运维面试题</a></li><li><a href=/docs/%E6%88%91%E5%8F%AA%E6%83%B3%E5%81%9A%E6%8A%80%E6%9C%AF-%E8%B5%B0%E6%8A%80%E6%9C%AF%E8%B7%AF%E7%BA%BF-wo-zhi-xiang-zuo-ji-shu-zou-ji-shu-lu-xian/>2024-08-02 我只想做技术 走技术路线</a></li><li><a href=/docs/%E6%90%AD%E4%B8%AA%E6%97%A5%E5%BF%97%E6%89%8B%E6%9C%BA%E7%B3%BB%E7%BB%9F%E4%B8%8D%E9%A6%99%E5%90%97-da-ge-ri-zhi-shou-ji-xi-tong-bu-xiang-ma/>2024-08-02 搭个日志手机系统不香吗</a></li><li><a href=/docs/%E6%98%AF%E6%8A%80%E6%9C%AF%E5%A4%A7%E7%A5%9E%E8%BF%98%E6%98%AF%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E9%83%A8%E7%9A%84%E7%A5%B8%E5%AE%B3-shi-ji-shu-da-shen-hai-shi-ji-chu-jia-gou-bu-de-huo-hai/>2024-08-02 是技术大神还是基础架构部的祸害</a></li><li><a href=/docs/%E6%9E%84%E5%BB%BA%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E5%88%A9%E5%99%A8buildkit-gou-jian-rong-qi-jing-xiang-li-qi-buildkit/>2024-08-02 构建容器镜像利器buildkit</a></li><li><a href=/docs/%E6%B8%85%E7%90%86docker%E9%95%9C%E5%83%8F-qing-li-docker-jing-xiang/>2024-08-02 清理docker镜像</a></li><li><a href=/docs/%E9%A1%B6%E7%BA%A7devops%E5%B7%A5%E5%85%B7%E5%A4%A7%E7%9B%98%E7%82%B9-ding-ji-devops-gong-ju-da-pan-dian/>2024-08-02 顶级devops工具大盘点</a></li><li><a href=/docs/2024-10-20-%E5%88%9B%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/>2024-10-20 使用 Keepalived 和 HAproxy 创建高可用 Kubernetes 集群</a></li><li><a href=/docs/2024-12-05-kubeasz%E9%83%A8%E7%BD%B2k8s/>2024-12-05 kubeasz部署k8s</a></li><li><a href=/docs/2024-12-07-microk8s/>2024-12-07 microk8s</a></li><li><a href=/docs/2024-12-08-devstack/>2024-12-08 devstack</a></li><li><a href=/docs/2024-12-08-mutilpass%E6%93%8D%E4%BD%9C/>2024-12-08 mutilpass操作</a></li><li><a href=/docs/2024-12-08-nano%E6%93%8D%E4%BD%9C/>2024-12-08 nano操作</a></li><li><a href=/docs/2024-12-08-openstack%E5%92%8Ckubernetes%E5%8C%BA%E5%88%AB/>2024-12-08 openstack和kubernetes区别</a></li><li><a href=/docs/2024-12-08-openstack%E9%9C%80%E8%A6%81%E5%87%A0%E5%8F%B0%E8%99%9A%E6%8B%9F%E6%9C%BA/>2024-12-08 openstack需要几台虚拟机</a></li><li><a href=/docs/2024-12-08-%E5%9D%97%E5%AD%98%E5%82%A8%E5%92%8C%E5%AF%B9%E8%B1%A1%E5%82%A8%E5%AD%98%E5%8C%BA%E5%88%AB/>2024-12-08 块存储和对象储存区别</a></li><li><a href=/docs/2024-12-09-docker-daemon.json/>2024-12-09 docker daemon.json</a></li><li><a href=/docs/2024-12-09-helmchart-%E9%83%A8%E7%BD%B2flask%E5%BA%94%E7%94%A8/>2024-12-09 helmchart 部署flask应用</a></li><li><a href=/docs/2024-12-08-mutilpass%E9%83%A8%E7%BD%B2openstack/>2024-12-09 mutilpass部署openstack devstack形式</a></li><li><a href=/docs/2024-12-09-openstack-ssh%E8%BF%9E%E6%8E%A5/>2024-12-09 openstack ssh连接</a></li><li><a href=/docs/2024-12-10-docker-registrry/>2024-12-10 docker registrry</a></li><li><a href=/docs/2024-2-22-k8s%E6%9E%B6%E6%9E%84%E5%B8%88%E9%9D%A2%E8%AF%95%E5%A4%A7%E5%85%A8/>2024-2-22 k8s架构师面试大全</a></li><li><a href=/docs/2024-2-22-k8s%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8/>2024-2-22 k8s面试宝典</a></li><li><a href=/docs/2024-2-26-%E9%9D%A2%E8%AF%95/>2024-2-26 面试</a></li><li><a href=/docs/2024-3-19-%E4%B8%A4%E5%BC%A0%E5%9B%BE%E5%85%A8%E9%9D%A2%E7%90%86%E8%A7%A3k8s%E5%8E%9F%E7%90%86/>2024-3-19 两张图全面理解k8s原理</a></li><li><a href=/docs/2024-3-4-cni%E5%89%96%E6%9E%90%E6%BC%94%E8%BF%9B/>2024-3-4 CNI剖析演进</a></li><li><a href=/docs/2024-3-8-%E9%9D%A2%E8%AF%950308/>2024-3-8 面试</a></li><li><a href=/docs/2024-4-17-%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/>2024-4-17 面试总结</a></li><li><a href=/docs/2024-5-14-%E5%8D%95master%E5%8D%95etcd%E6%94%B9%E9%80%A0/>2024-5-1 单master单etcd改造为3master3etcd</a></li><li><a href=/docs/2024-8-1-kubernetes%E9%9D%A2%E8%AF%95%E9%A2%98/>2024-8-1 k8s面试题</a></li><li><a href=/docs/2024-8-1-%E5%B8%B8%E8%A7%81linux%E8%BF%90%E7%BB%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%BF%85%E7%9C%8B/>2024-8-1 linux运维面试题</a></li><li><a href=/docs/2024-8-1-linux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%8850%E4%B8%AA%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/>2024-8-1 linux面试题</a></li><li><a href=/docs/2025-1-1-sealos%E8%8E%B7%E6%8A%95/>2025-1-1 sealos获投</a></li><li><a href=/docs/2025-1-1-%E5%88%9B%E4%B8%9A%E7%82%B9%E5%AD%90/>2025-1-1 创业点子</a></li><li><a href=/docs/2025-1-1-%E5%88%9B%E4%B8%9A%E8%80%85%E4%BA%A4%E6%B5%81/>2025-1-1 创业者交流</a></li><li><a href=/docs/2025-1-1-%E5%88%9D%E5%88%9B%E5%85%AC%E5%8F%B8/>2025-1-1 初创公司</a></li><li><a href=/docs/2025-1-1-%E5%A4%A7%E5%A0%B0%E6%B2%B3-%E6%88%91%E7%9A%84%E4%BF%9D%E5%A7%86/>2025-1-1 大堰河-我的保姆</a></li><li><a href=/docs/2025-1-1-%E6%97%A9%E6%9C%9F%E6%A8%A1%E5%BC%8F/>2025-1-1 早期模式</a></li><li><a href=/docs/2025-1-1-%E8%A6%81%E4%B8%8D%E8%A6%81%E5%88%9B%E4%B8%9A/>2025-1-1 要不要创业</a></li><li><a href=/docs/2024-3-4-k8s-csi%E5%89%96%E6%9E%90/>2025-1-16 CSI剖析演进</a></li><li><a href=/docs/2025-1-16-k8s%E5%B8%B8%E8%A7%81%E6%95%85%E9%9A%9C%E6%8C%87%E5%8D%97/>2025-1-16 k8s常见故障指南</a></li><li><a href=/docs/2024-3-4-k8s%E6%B5%81%E9%87%8F%E9%93%BE%E8%B7%AF%E5%89%96%E6%9E%90/>2025-1-16 k8s流量链路剖析</a></li><li><a href=/docs/2025-2-11-%E9%9D%A2%E8%AF%950211/>2025-2-11 面试2025-02-11</a></li><li><a href=/docs/2025-2-12-%E9%9D%A2%E8%AF%950212/>2025-2-12 面试0212</a></li><li><a href=/docs/2025-2-26-k8s%E7%9B%B8%E5%85%B3/>2025-2-16 k8s题目</a></li><li><a href=/docs/2025-2-18-%E9%9D%A2%E8%AF%95/>2025-2-18 面试2025-0218</a></li><li><a href=/docs/2025-2-19-%E9%9D%A2%E8%AF%950219/>2025-2-19 面试0219</a></li><li><a href=/docs/2025-2-20-%E9%9D%A2%E8%AF%950220/>2025-2-20 面试0220</a></li><li><a href=/docs/2025-2-24-%E9%9D%A2%E8%AF%950224/>2025-2-24 0224面试</a></li><li><a href=/docs/2025-2-24-%E4%B8%AD%E7%BA%A7%E8%BF%90%E7%BB%B4%E9%9D%A2%E8%AF%95%E9%A2%98_%E9%A2%98%E7%9B%AE/>2025-2-24 中级运维面试题</a></li><li><a href=/docs/2025-2-24-%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4%E9%9D%A2%E8%AF%95%E9%A2%98_ai_linux%E9%83%A8%E5%88%86/>2025-2-24 高级运维面试题-linux部分</a></li><li><a href=/docs/2025-2-26-%E9%9D%A2%E8%AF%950225/>2025-2-25 面试0225</a></li><li><a href=/docs/2025-2-28-prometheus/>2025-2-28 prometheus 面试题</a></li><li><a href=/docs/2025-2-7-k8s%E7%BB%84%E4%BB%B6/>2025-2-7 k8s组件</a></li><li><a href=/docs/2025-2-7-%E8%AE%A1%E5%88%92/>2025-2-7 美国码农薪酬</a></li><li><a href=/docs/2025-2-7-%E8%AE%A1%E5%88%922/>2025-2-7 美国码农计划</a></li><li><a href=/docs/2025-3-12-%E8%BF%BD%E8%A7%85%E9%9D%A2%E8%AF%95/>2025-3-12 追觅面试</a></li><li><a href=/docs/2025-3-12-%E5%A1%94%E8%B5%9E%E9%9D%A2%E8%AF%95/>2025-3-12 塔赞面试</a></li><li><a href=/docs/2025-3-13-calico%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F%E4%B8%8B%E6%B5%81%E9%87%8F%E4%BC%A0%E8%BE%93%E8%B7%AF%E5%BE%84%E5%88%86%E6%9E%90/>2025-3-13 calico三种模式下流量传输</a></li><li><a href=/docs/2025-3-13-istio%E6%B5%81%E9%87%8F%E5%88%86%E6%9E%90/>2025-3-13 istio流量分析</a></li><li><a href=/docs/2025-3-8-k8s%E5%88%9B%E5%BB%BApod-deployment%E6%B5%81%E7%A8%8B%E5%9B%BE%E8%AF%A6%E8%A7%A3/>2025-3-8 k8s创建pod 流程图详解</a></li><li><a href=/docs/2025-3-8-k8s%E5%88%A0%E9%99%A4pod-deployment%E7%9A%84%E6%B5%81%E7%A8%8B%E5%9B%BE%E8%AF%A6%E8%A7%A3/>2025-3-8 k8s删除pod deployment的流程图详解</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>2024-04-03 K8S csi openebs原理</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#简介>简介</a><ul><li></li></ul></li><li><a href=#本地存储卷>本地存储卷</a><ul><li></li><li><a href=#local-pv>Local PV</a></li><li><a href=#延迟绑定>延迟绑定</a></li><li><a href=#原地重启>原地重启</a></li></ul></li><li><a href=#openebs-使用>OpenEBS 使用</a><ul><li></li><li><a href=#helm-部署>Helm 部署</a></li><li><a href=#kubectl-部署>kubectl 部署</a></li><li><a href=#验证>验证</a></li></ul></li><li><a href=#openebs-local-pv-原理>OpenEBS Local PV 原理</a><ul><li></li><li><a href=#openebs-local-pv-部署架构>OpenEBS Local PV 部署架构</a></li><li><a href=#openebs-localpv-provisioner-源码解析>openebs-localpv-provisioner 源码解析</a></li></ul></li><li><a href=#总结>总结</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=kubernetes-csi-二-openebs-原理>Kubernetes CSI (二): OpenEBS 原理
<a class=anchor href=#kubernetes-csi-%e4%ba%8c-openebs-%e5%8e%9f%e7%90%86>#</a></h1><h2 id=简介>简介
<a class=anchor href=#%e7%ae%80%e4%bb%8b>#</a></h2><h5 id=在-kubernetes-csi-一-kubernetes-存储原理-一文中详细讲解了-kubernetes-csi-的原理本篇文章通过原理和源码走读形式讲解-openebs-原理>在 Kubernetes CSI (一): Kubernetes 存储原理 一文中详细讲解了 Kubernetes CSI 的原理，本篇文章通过原理和源码走读形式讲解 <strong>OpenEBS</strong> 原理。
<a class=anchor href=#%e5%9c%a8-kubernetes-csi-%e4%b8%80-kubernetes-%e5%ad%98%e5%82%a8%e5%8e%9f%e7%90%86-%e4%b8%80%e6%96%87%e4%b8%ad%e8%af%a6%e7%bb%86%e8%ae%b2%e8%a7%a3%e4%ba%86-kubernetes-csi-%e7%9a%84%e5%8e%9f%e7%90%86%e6%9c%ac%e7%af%87%e6%96%87%e7%ab%a0%e9%80%9a%e8%bf%87%e5%8e%9f%e7%90%86%e5%92%8c%e6%ba%90%e7%a0%81%e8%b5%b0%e8%af%bb%e5%bd%a2%e5%bc%8f%e8%ae%b2%e8%a7%a3-openebs-%e5%8e%9f%e7%90%86>#</a></h5><h5 id=openebs-是一款使用go语言编写的基于容器的块存储开源软件openebs-使得在容器中运行关键性任务和需要数据持久化的负载变得更可靠实现了-kubernetes-csi所以可以很方便对接-kubernetes-存储功能>OpenEBS 是一款使用Go语言编写的基于容器的块存储开源软件。OpenEBS 使得在容器中运行关键性任务和需要数据持久化的负载变得更可靠。实现了 <strong>Kubernetes CSI</strong>，所以可以很方便对接 Kubernetes 存储功能。
<a class=anchor href=#openebs-%e6%98%af%e4%b8%80%e6%ac%be%e4%bd%bf%e7%94%a8go%e8%af%ad%e8%a8%80%e7%bc%96%e5%86%99%e7%9a%84%e5%9f%ba%e4%ba%8e%e5%ae%b9%e5%99%a8%e7%9a%84%e5%9d%97%e5%ad%98%e5%82%a8%e5%bc%80%e6%ba%90%e8%bd%af%e4%bb%b6openebs-%e4%bd%bf%e5%be%97%e5%9c%a8%e5%ae%b9%e5%99%a8%e4%b8%ad%e8%bf%90%e8%a1%8c%e5%85%b3%e9%94%ae%e6%80%a7%e4%bb%bb%e5%8a%a1%e5%92%8c%e9%9c%80%e8%a6%81%e6%95%b0%e6%8d%ae%e6%8c%81%e4%b9%85%e5%8c%96%e7%9a%84%e8%b4%9f%e8%bd%bd%e5%8f%98%e5%be%97%e6%9b%b4%e5%8f%af%e9%9d%a0%e5%ae%9e%e7%8e%b0%e4%ba%86-kubernetes-csi%e6%89%80%e4%bb%a5%e5%8f%af%e4%bb%a5%e5%be%88%e6%96%b9%e4%be%bf%e5%af%b9%e6%8e%a5-kubernetes-%e5%ad%98%e5%82%a8%e5%8a%9f%e8%83%bd>#</a></h5><h5 id=对于大部分第三方存储厂商它们都只实现了分布式存储openebs-可以为-kubernetes-有状态负载-statefulset--提供本地存储卷和分布式存储卷>对于大部分第三方存储厂商，它们都只实现了分布式存储，OpenEBS 可以为 Kubernetes 有状态负载( StatefulSet ) 提供本地存储卷和分布式存储卷。
<a class=anchor href=#%e5%af%b9%e4%ba%8e%e5%a4%a7%e9%83%a8%e5%88%86%e7%ac%ac%e4%b8%89%e6%96%b9%e5%ad%98%e5%82%a8%e5%8e%82%e5%95%86%e5%ae%83%e4%bb%ac%e9%83%bd%e5%8f%aa%e5%ae%9e%e7%8e%b0%e4%ba%86%e5%88%86%e5%b8%83%e5%bc%8f%e5%ad%98%e5%82%a8openebs-%e5%8f%af%e4%bb%a5%e4%b8%ba-kubernetes-%e6%9c%89%e7%8a%b6%e6%80%81%e8%b4%9f%e8%bd%bd-statefulset--%e6%8f%90%e4%be%9b%e6%9c%ac%e5%9c%b0%e5%ad%98%e5%82%a8%e5%8d%b7%e5%92%8c%e5%88%86%e5%b8%83%e5%bc%8f%e5%ad%98%e5%82%a8%e5%8d%b7>#</a></h5><p>本篇文章重点讲解 OpenEBS 的<strong>本地存储卷</strong>。</p><hr><h2 id=本地存储卷>本地存储卷
<a class=anchor href=#%e6%9c%ac%e5%9c%b0%e5%ad%98%e5%82%a8%e5%8d%b7>#</a></h2><h5 id=本地存储卷很容易理解在-kubernetes-中本身就支持-hostpath-类型的存储卷>本地存储卷很容易理解，在 Kubernetes 中本身就支持 <strong>Hostpath</strong> 类型的存储卷，
<a class=anchor href=#%e6%9c%ac%e5%9c%b0%e5%ad%98%e5%82%a8%e5%8d%b7%e5%be%88%e5%ae%b9%e6%98%93%e7%90%86%e8%a7%a3%e5%9c%a8-kubernetes-%e4%b8%ad%e6%9c%ac%e8%ba%ab%e5%b0%b1%e6%94%af%e6%8c%81-hostpath-%e7%b1%bb%e5%9e%8b%e7%9a%84%e5%ad%98%e5%82%a8%e5%8d%b7>#</a></h5><h5 id=使用-hostpath-有一个局限性就是我们的-pod-不能随便漂移需要固定到一个节点上因为一旦漂移到其他节点上去了宿主机上面就没有对应的数据了所以我们在使用-hostpath-的时候都会搭配-nodeselector-来进行使用>使用 HostPath 有一个局限性就是，我们的 Pod 不能随便漂移，需要固定到一个节点上，因为一旦漂移到其他节点上去了宿主机上面就没有对应的数据了，所以我们在使用 HostPath 的时候都会搭配 nodeSelector 来进行使用。
<a class=anchor href=#%e4%bd%bf%e7%94%a8-hostpath-%e6%9c%89%e4%b8%80%e4%b8%aa%e5%b1%80%e9%99%90%e6%80%a7%e5%b0%b1%e6%98%af%e6%88%91%e4%bb%ac%e7%9a%84-pod-%e4%b8%8d%e8%83%bd%e9%9a%8f%e4%be%bf%e6%bc%82%e7%a7%bb%e9%9c%80%e8%a6%81%e5%9b%ba%e5%ae%9a%e5%88%b0%e4%b8%80%e4%b8%aa%e8%8a%82%e7%82%b9%e4%b8%8a%e5%9b%a0%e4%b8%ba%e4%b8%80%e6%97%a6%e6%bc%82%e7%a7%bb%e5%88%b0%e5%85%b6%e4%bb%96%e8%8a%82%e7%82%b9%e4%b8%8a%e5%8e%bb%e4%ba%86%e5%ae%bf%e4%b8%bb%e6%9c%ba%e4%b8%8a%e9%9d%a2%e5%b0%b1%e6%b2%a1%e6%9c%89%e5%af%b9%e5%ba%94%e7%9a%84%e6%95%b0%e6%8d%ae%e4%ba%86%e6%89%80%e4%bb%a5%e6%88%91%e4%bb%ac%e5%9c%a8%e4%bd%bf%e7%94%a8-hostpath-%e7%9a%84%e6%97%b6%e5%80%99%e9%83%bd%e4%bc%9a%e6%90%ad%e9%85%8d-nodeselector-%e6%9d%a5%e8%bf%9b%e8%a1%8c%e4%bd%bf%e7%94%a8>#</a></h5><h5 id=但是使用-hostpath-明显也有一些好处的因为-pv-直接使用的是本地磁盘尤其是-ssd-盘它的读写性能相比于大多数远程存储来说要好得多所以对于一些对磁盘-io-要求比较高的应用比如-etcd-就非常实用了不过呢相比于正常的-pv-来说使用了-hostpath-的这些节点一旦宕机数据就可能丢失所以这就要求使用-hostpath-的应用必须具备数据备份和恢复的能力允许你把这些数据定时备份在其他位置>但是使用 HostPath 明显也有一些好处的，因为 PV 直接使用的是本地磁盘，尤其是 SSD 盘，它的读写性能相比于大多数远程存储来说，要好得多，所以对于一些对磁盘 IO 要求比较高的应用，比如 etcd 就非常实用了。不过呢，相比于正常的 PV 来说，使用了 HostPath 的这些节点一旦宕机数据就可能丢失，所以这就要求使用 HostPath 的应用必须具备数据备份和恢复的能力，允许你把这些数据定时备份在其他位置。
<a class=anchor href=#%e4%bd%86%e6%98%af%e4%bd%bf%e7%94%a8-hostpath-%e6%98%8e%e6%98%be%e4%b9%9f%e6%9c%89%e4%b8%80%e4%ba%9b%e5%a5%bd%e5%a4%84%e7%9a%84%e5%9b%a0%e4%b8%ba-pv-%e7%9b%b4%e6%8e%a5%e4%bd%bf%e7%94%a8%e7%9a%84%e6%98%af%e6%9c%ac%e5%9c%b0%e7%a3%81%e7%9b%98%e5%b0%a4%e5%85%b6%e6%98%af-ssd-%e7%9b%98%e5%ae%83%e7%9a%84%e8%af%bb%e5%86%99%e6%80%a7%e8%83%bd%e7%9b%b8%e6%af%94%e4%ba%8e%e5%a4%a7%e5%a4%9a%e6%95%b0%e8%bf%9c%e7%a8%8b%e5%ad%98%e5%82%a8%e6%9d%a5%e8%af%b4%e8%a6%81%e5%a5%bd%e5%be%97%e5%a4%9a%e6%89%80%e4%bb%a5%e5%af%b9%e4%ba%8e%e4%b8%80%e4%ba%9b%e5%af%b9%e7%a3%81%e7%9b%98-io-%e8%a6%81%e6%b1%82%e6%af%94%e8%be%83%e9%ab%98%e7%9a%84%e5%ba%94%e7%94%a8%e6%af%94%e5%a6%82-etcd-%e5%b0%b1%e9%9d%9e%e5%b8%b8%e5%ae%9e%e7%94%a8%e4%ba%86%e4%b8%8d%e8%bf%87%e5%91%a2%e7%9b%b8%e6%af%94%e4%ba%8e%e6%ad%a3%e5%b8%b8%e7%9a%84-pv-%e6%9d%a5%e8%af%b4%e4%bd%bf%e7%94%a8%e4%ba%86-hostpath-%e7%9a%84%e8%bf%99%e4%ba%9b%e8%8a%82%e7%82%b9%e4%b8%80%e6%97%a6%e5%ae%95%e6%9c%ba%e6%95%b0%e6%8d%ae%e5%b0%b1%e5%8f%af%e8%83%bd%e4%b8%a2%e5%a4%b1%e6%89%80%e4%bb%a5%e8%bf%99%e5%b0%b1%e8%a6%81%e6%b1%82%e4%bd%bf%e7%94%a8-hostpath-%e7%9a%84%e5%ba%94%e7%94%a8%e5%bf%85%e9%a1%bb%e5%85%b7%e5%a4%87%e6%95%b0%e6%8d%ae%e5%a4%87%e4%bb%bd%e5%92%8c%e6%81%a2%e5%a4%8d%e7%9a%84%e8%83%bd%e5%8a%9b%e5%85%81%e8%ae%b8%e4%bd%a0%e6%8a%8a%e8%bf%99%e4%ba%9b%e6%95%b0%e6%8d%ae%e5%ae%9a%e6%97%b6%e5%a4%87%e4%bb%bd%e5%9c%a8%e5%85%b6%e4%bb%96%e4%bd%8d%e7%bd%ae>#</a></h5><h5 id=所以在-hostpath-的基础上kubernetes-依靠-pvpvc-实现了一个新的特性这个特性的名字叫作local-persistent-volume也就是我们说的-local-pv>所以在 HostPath 的基础上，Kubernetes 依靠 PV、PVC 实现了一个新的特性，这个特性的名字叫作：<code>Local Persistent Volume</code>，也就是我们说的 <code>Local PV</code>。
<a class=anchor href=#%e6%89%80%e4%bb%a5%e5%9c%a8-hostpath-%e7%9a%84%e5%9f%ba%e7%a1%80%e4%b8%8akubernetes-%e4%be%9d%e9%9d%a0-pvpvc-%e5%ae%9e%e7%8e%b0%e4%ba%86%e4%b8%80%e4%b8%aa%e6%96%b0%e7%9a%84%e7%89%b9%e6%80%a7%e8%bf%99%e4%b8%aa%e7%89%b9%e6%80%a7%e7%9a%84%e5%90%8d%e5%ad%97%e5%8f%ab%e4%bd%9clocal-persistent-volume%e4%b9%9f%e5%b0%b1%e6%98%af%e6%88%91%e4%bb%ac%e8%af%b4%e7%9a%84-local-pv>#</a></h5><h5 id=要想使用-local-pv-考虑的因素也比较多下面详细看看>要想使用 <code>Local PV</code> 考虑的因素也比较多，下面详细看看：
<a class=anchor href=#%e8%a6%81%e6%83%b3%e4%bd%bf%e7%94%a8-local-pv-%e8%80%83%e8%99%91%e7%9a%84%e5%9b%a0%e7%b4%a0%e4%b9%9f%e6%af%94%e8%be%83%e5%a4%9a%e4%b8%8b%e9%9d%a2%e8%af%a6%e7%bb%86%e7%9c%8b%e7%9c%8b>#</a></h5><h3 id=local-pv>Local PV
<a class=anchor href=#local-pv>#</a></h3><h5 id=其实-local-pv-实现的功能就非常类似于-hostpath-加上-nodeaffinity-即表示该-pv-就是一个-hostpath-类型卷>其实 <code>Local PV</code> 实现的功能就非常类似于 <code>HostPath</code> 加上 <code>nodeAffinity</code> ，即表示该 PV 就是一个 <code>Hostpath</code> 类型卷。
<a class=anchor href=#%e5%85%b6%e5%ae%9e-local-pv-%e5%ae%9e%e7%8e%b0%e7%9a%84%e5%8a%9f%e8%83%bd%e5%b0%b1%e9%9d%9e%e5%b8%b8%e7%b1%bb%e4%bc%bc%e4%ba%8e-hostpath-%e5%8a%a0%e4%b8%8a-nodeaffinity-%e5%8d%b3%e8%a1%a8%e7%a4%ba%e8%af%a5-pv-%e5%b0%b1%e6%98%af%e4%b8%80%e4%b8%aa-hostpath-%e7%b1%bb%e5%9e%8b%e5%8d%b7>#</a></h5><pre tabindex=0><code>apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-local
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete
  storageClassName: local-storage
  local:
    path: /data/k8s/localpv # 对应主机上数据目录
  # 该 pv 与节点绑定
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node-1
</code></pre><h5 id=local-pv-不仅仅支持-filesystem-类型存储还支持-blocklvm-类型><code>Local PV</code> 不仅仅支持 Filesystem 类型存储，还支持 Block，LVM 类型
<a class=anchor href=#local-pv-%e4%b8%8d%e4%bb%85%e4%bb%85%e6%94%af%e6%8c%81-filesystem-%e7%b1%bb%e5%9e%8b%e5%ad%98%e5%82%a8%e8%bf%98%e6%94%af%e6%8c%81-blocklvm-%e7%b1%bb%e5%9e%8b>#</a></h5><h3 id=延迟绑定>延迟绑定
<a class=anchor href=#%e5%bb%b6%e8%bf%9f%e7%bb%91%e5%ae%9a>#</a></h3><h5 id=延迟绑定就是在-pod-调度完成之后再绑定对应的-pvcpv对于使用-local-pv-的-pod必须延迟绑定><strong>延迟绑定</strong>就是在 Pod 调度完成之后，再绑定对应的 PVC、PV。对于使用 <code>Local PV</code> 的 Pod，必须延迟绑定。
<a class=anchor href=#%e5%bb%b6%e8%bf%9f%e7%bb%91%e5%ae%9a%e5%b0%b1%e6%98%af%e5%9c%a8-pod-%e8%b0%83%e5%ba%a6%e5%ae%8c%e6%88%90%e4%b9%8b%e5%90%8e%e5%86%8d%e7%bb%91%e5%ae%9a%e5%af%b9%e5%ba%94%e7%9a%84-pvcpv%e5%af%b9%e4%ba%8e%e4%bd%bf%e7%94%a8-local-pv-%e7%9a%84-pod%e5%bf%85%e9%a1%bb%e5%bb%b6%e8%bf%9f%e7%bb%91%e5%ae%9a>#</a></h5><h5 id=比如现在明确规定这个-pod-只能运行在-node-1-这个节点上且该-pod-申请了一个-pvc对于没有延迟属性的-storageclass那么就会在-pod-调度到某个节点之前就将该-pvc-绑定到合适的-pv如果集群-node-1node-2-都存在-pv-可以和该-pvc-绑定那么就有可能该-pvc-绑定了-node-2-的-pv就会导致-pod-调度失败>比如现在明确规定，这个 Pod 只能运行在 <code>node-1</code> 这个节点上，且该 Pod 申请了一个 PVC。对于没有延迟属性的 StorageClass，那么就会在 Pod 调度到某个节点之前就将该 PVC 绑定到合适的 PV，如果集群 <code>node-1，node-2</code> 都存在 PV 可以和该 PVC 绑定，那么就有可能该 PVC 绑定了 <code>node-2</code> 的 PV，就会导致 Pod 调度失败。
<a class=anchor href=#%e6%af%94%e5%a6%82%e7%8e%b0%e5%9c%a8%e6%98%8e%e7%a1%ae%e8%a7%84%e5%ae%9a%e8%bf%99%e4%b8%aa-pod-%e5%8f%aa%e8%83%bd%e8%bf%90%e8%a1%8c%e5%9c%a8-node-1-%e8%bf%99%e4%b8%aa%e8%8a%82%e7%82%b9%e4%b8%8a%e4%b8%94%e8%af%a5-pod-%e7%94%b3%e8%af%b7%e4%ba%86%e4%b8%80%e4%b8%aa-pvc%e5%af%b9%e4%ba%8e%e6%b2%a1%e6%9c%89%e5%bb%b6%e8%bf%9f%e5%b1%9e%e6%80%a7%e7%9a%84-storageclass%e9%82%a3%e4%b9%88%e5%b0%b1%e4%bc%9a%e5%9c%a8-pod-%e8%b0%83%e5%ba%a6%e5%88%b0%e6%9f%90%e4%b8%aa%e8%8a%82%e7%82%b9%e4%b9%8b%e5%89%8d%e5%b0%b1%e5%b0%86%e8%af%a5-pvc-%e7%bb%91%e5%ae%9a%e5%88%b0%e5%90%88%e9%80%82%e7%9a%84-pv%e5%a6%82%e6%9e%9c%e9%9b%86%e7%be%a4-node-1node-2-%e9%83%bd%e5%ad%98%e5%9c%a8-pv-%e5%8f%af%e4%bb%a5%e5%92%8c%e8%af%a5-pvc-%e7%bb%91%e5%ae%9a%e9%82%a3%e4%b9%88%e5%b0%b1%e6%9c%89%e5%8f%af%e8%83%bd%e8%af%a5-pvc-%e7%bb%91%e5%ae%9a%e4%ba%86-node-2-%e7%9a%84-pv%e5%b0%b1%e4%bc%9a%e5%af%bc%e8%87%b4-pod-%e8%b0%83%e5%ba%a6%e5%a4%b1%e8%b4%a5>#</a></h5><h5 id=所以为了避免这种现象就必须在-pvc-和-pv-绑定之前就将-pod-调度完成所以我们在使用-local-pv-的时候就必须延迟绑定操作即延迟到-pod-调度完成之后再绑定-pvc>所以为了避免这种现象，就必须在 PVC 和 PV 绑定之前就将 Pod 调度完成。所以我们在使用 <code>Local PV</code> 的时候，就必须<strong>延迟绑定</strong>操作，即延迟到 Pod 调度完成之后再绑定 PVC。
<a class=anchor href=#%e6%89%80%e4%bb%a5%e4%b8%ba%e4%ba%86%e9%81%bf%e5%85%8d%e8%bf%99%e7%a7%8d%e7%8e%b0%e8%b1%a1%e5%b0%b1%e5%bf%85%e9%a1%bb%e5%9c%a8-pvc-%e5%92%8c-pv-%e7%bb%91%e5%ae%9a%e4%b9%8b%e5%89%8d%e5%b0%b1%e5%b0%86-pod-%e8%b0%83%e5%ba%a6%e5%ae%8c%e6%88%90%e6%89%80%e4%bb%a5%e6%88%91%e4%bb%ac%e5%9c%a8%e4%bd%bf%e7%94%a8-local-pv-%e7%9a%84%e6%97%b6%e5%80%99%e5%b0%b1%e5%bf%85%e9%a1%bb%e5%bb%b6%e8%bf%9f%e7%bb%91%e5%ae%9a%e6%93%8d%e4%bd%9c%e5%8d%b3%e5%bb%b6%e8%bf%9f%e5%88%b0-pod-%e8%b0%83%e5%ba%a6%e5%ae%8c%e6%88%90%e4%b9%8b%e5%90%8e%e5%86%8d%e7%bb%91%e5%ae%9a-pvc>#</a></h5><h5 id=那么怎么才能实现延迟绑定>那么怎么才能实现<strong>延迟绑定</strong>？
<a class=anchor href=#%e9%82%a3%e4%b9%88%e6%80%8e%e4%b9%88%e6%89%8d%e8%83%bd%e5%ae%9e%e7%8e%b0%e5%bb%b6%e8%bf%9f%e7%bb%91%e5%ae%9a>#</a></h5><h5 id=对于-local-pv-类型的-storageclass-需要配置-volumebindingmodewaitforfirstconsumer-的属性就是告诉-kubernetes-在发现这个-storageclass-关联的-pvc-与-pv-可以绑定在一起但不要现在就立刻执行绑定操作即设置-pvc-的-volumename-字段而是要等到第一个声明使用该-pvc-的-pod-出现在调度器之后调度器再综合考虑所有的调度规则当然也包括每个-pv所在的节点位置来统一决定这个-pod-声明的-pvc到底应该跟哪个-pv-进行绑定通过这个延迟绑定机制原本实时发生的-pvc-和-pv-的绑定过程就被延迟到了-pod-第一次调度的时候在调度器中进行从而保证了这个绑定结果不会影响-pod-的正常调度>对于 <code>Local PV</code> 类型的 StorageClass 需要配置 <code>volumeBindingMode=WaitForFirstConsumer</code> 的属性，就是告诉 Kubernetes 在发现这个 StorageClass 关联的 PVC 与 PV 可以绑定在一起，但不要现在就立刻执行绑定操作（即：设置 PVC 的 VolumeName 字段），而是要等到第一个声明使用该 PVC 的 Pod 出现在调度器之后，调度器再综合考虑所有的调度规则，当然也包括每个 PV所在的节点位置，来统一决定。这个 Pod 声明的 PVC，到底应该跟哪个 PV 进行绑定。通过这个延迟绑定机制，原本实时发生的 PVC 和 PV 的绑定过程，就被延迟到了 Pod 第一次调度的时候在调度器中进行，从而保证了这个绑定结果不会影响 Pod 的正常调度。
<a class=anchor href=#%e5%af%b9%e4%ba%8e-local-pv-%e7%b1%bb%e5%9e%8b%e7%9a%84-storageclass-%e9%9c%80%e8%a6%81%e9%85%8d%e7%bd%ae-volumebindingmodewaitforfirstconsumer-%e7%9a%84%e5%b1%9e%e6%80%a7%e5%b0%b1%e6%98%af%e5%91%8a%e8%af%89-kubernetes-%e5%9c%a8%e5%8f%91%e7%8e%b0%e8%bf%99%e4%b8%aa-storageclass-%e5%85%b3%e8%81%94%e7%9a%84-pvc-%e4%b8%8e-pv-%e5%8f%af%e4%bb%a5%e7%bb%91%e5%ae%9a%e5%9c%a8%e4%b8%80%e8%b5%b7%e4%bd%86%e4%b8%8d%e8%a6%81%e7%8e%b0%e5%9c%a8%e5%b0%b1%e7%ab%8b%e5%88%bb%e6%89%a7%e8%a1%8c%e7%bb%91%e5%ae%9a%e6%93%8d%e4%bd%9c%e5%8d%b3%e8%ae%be%e7%bd%ae-pvc-%e7%9a%84-volumename-%e5%ad%97%e6%ae%b5%e8%80%8c%e6%98%af%e8%a6%81%e7%ad%89%e5%88%b0%e7%ac%ac%e4%b8%80%e4%b8%aa%e5%a3%b0%e6%98%8e%e4%bd%bf%e7%94%a8%e8%af%a5-pvc-%e7%9a%84-pod-%e5%87%ba%e7%8e%b0%e5%9c%a8%e8%b0%83%e5%ba%a6%e5%99%a8%e4%b9%8b%e5%90%8e%e8%b0%83%e5%ba%a6%e5%99%a8%e5%86%8d%e7%bb%bc%e5%90%88%e8%80%83%e8%99%91%e6%89%80%e6%9c%89%e7%9a%84%e8%b0%83%e5%ba%a6%e8%a7%84%e5%88%99%e5%bd%93%e7%84%b6%e4%b9%9f%e5%8c%85%e6%8b%ac%e6%af%8f%e4%b8%aa-pv%e6%89%80%e5%9c%a8%e7%9a%84%e8%8a%82%e7%82%b9%e4%bd%8d%e7%bd%ae%e6%9d%a5%e7%bb%9f%e4%b8%80%e5%86%b3%e5%ae%9a%e8%bf%99%e4%b8%aa-pod-%e5%a3%b0%e6%98%8e%e7%9a%84-pvc%e5%88%b0%e5%ba%95%e5%ba%94%e8%af%a5%e8%b7%9f%e5%93%aa%e4%b8%aa-pv-%e8%bf%9b%e8%a1%8c%e7%bb%91%e5%ae%9a%e9%80%9a%e8%bf%87%e8%bf%99%e4%b8%aa%e5%bb%b6%e8%bf%9f%e7%bb%91%e5%ae%9a%e6%9c%ba%e5%88%b6%e5%8e%9f%e6%9c%ac%e5%ae%9e%e6%97%b6%e5%8f%91%e7%94%9f%e7%9a%84-pvc-%e5%92%8c-pv-%e7%9a%84%e7%bb%91%e5%ae%9a%e8%bf%87%e7%a8%8b%e5%b0%b1%e8%a2%ab%e5%bb%b6%e8%bf%9f%e5%88%b0%e4%ba%86-pod-%e7%ac%ac%e4%b8%80%e6%ac%a1%e8%b0%83%e5%ba%a6%e7%9a%84%e6%97%b6%e5%80%99%e5%9c%a8%e8%b0%83%e5%ba%a6%e5%99%a8%e4%b8%ad%e8%bf%9b%e8%a1%8c%e4%bb%8e%e8%80%8c%e4%bf%9d%e8%af%81%e4%ba%86%e8%bf%99%e4%b8%aa%e7%bb%91%e5%ae%9a%e7%bb%93%e6%9e%9c%e4%b8%8d%e4%bc%9a%e5%bd%b1%e5%93%8d-pod-%e7%9a%84%e6%ad%a3%e5%b8%b8%e8%b0%83%e5%ba%a6>#</a></h5><pre tabindex=0><code>apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-storage
provisioner: kubernetes.io/no-provisioner
# 延迟绑定属性
volumeBindingMode: WaitForFirstConsumer
</code></pre><h3 id=原地重启>原地重启
<a class=anchor href=#%e5%8e%9f%e5%9c%b0%e9%87%8d%e5%90%af>#</a></h3><h5 id=我们知道使用-hostpath-存储卷类型-pod-如果不设置节点选择器那么重启后会调度到其他节点上运行这样就会导致之前数据丢失>我们知道使用 Hostpath 存储卷类型 Pod 如果不设置节点选择器，那么重启后会调度到其他节点上运行，这样就会导致之前数据丢失。
<a class=anchor href=#%e6%88%91%e4%bb%ac%e7%9f%a5%e9%81%93%e4%bd%bf%e7%94%a8-hostpath-%e5%ad%98%e5%82%a8%e5%8d%b7%e7%b1%bb%e5%9e%8b-pod-%e5%a6%82%e6%9e%9c%e4%b8%8d%e8%ae%be%e7%bd%ae%e8%8a%82%e7%82%b9%e9%80%89%e6%8b%a9%e5%99%a8%e9%82%a3%e4%b9%88%e9%87%8d%e5%90%af%e5%90%8e%e4%bc%9a%e8%b0%83%e5%ba%a6%e5%88%b0%e5%85%b6%e4%bb%96%e8%8a%82%e7%82%b9%e4%b8%8a%e8%bf%90%e8%a1%8c%e8%bf%99%e6%a0%b7%e5%b0%b1%e4%bc%9a%e5%af%bc%e8%87%b4%e4%b9%8b%e5%89%8d%e6%95%b0%e6%8d%ae%e4%b8%a2%e5%a4%b1>#</a></h5><h5 id=使用-local-pv-存储卷就无需担心该问题因为根据-local-pv-的特性会保证该-pod-重启后始终在当前节点运行当然这里涉及到-kubernetes-调度器和-pvcpv的相关原理下面我们简单描述下>使用 Local PV 存储卷就无需担心该问题，因为根据 Local PV 的特性会保证该 Pod 重启后始终在<strong>当前节点</strong>运行。当然这里涉及到 Kubernetes 调度器和 PVC、PV的相关原理，下面我们简单描述下。
<a class=anchor href=#%e4%bd%bf%e7%94%a8-local-pv-%e5%ad%98%e5%82%a8%e5%8d%b7%e5%b0%b1%e6%97%a0%e9%9c%80%e6%8b%85%e5%bf%83%e8%af%a5%e9%97%ae%e9%a2%98%e5%9b%a0%e4%b8%ba%e6%a0%b9%e6%8d%ae-local-pv-%e7%9a%84%e7%89%b9%e6%80%a7%e4%bc%9a%e4%bf%9d%e8%af%81%e8%af%a5-pod-%e9%87%8d%e5%90%af%e5%90%8e%e5%a7%8b%e7%bb%88%e5%9c%a8%e5%bd%93%e5%89%8d%e8%8a%82%e7%82%b9%e8%bf%90%e8%a1%8c%e5%bd%93%e7%84%b6%e8%bf%99%e9%87%8c%e6%b6%89%e5%8f%8a%e5%88%b0-kubernetes-%e8%b0%83%e5%ba%a6%e5%99%a8%e5%92%8c-pvcpv%e7%9a%84%e7%9b%b8%e5%85%b3%e5%8e%9f%e7%90%86%e4%b8%8b%e9%9d%a2%e6%88%91%e4%bb%ac%e7%ae%80%e5%8d%95%e6%8f%8f%e8%bf%b0%e4%b8%8b>#</a></h5><h5 id=当-pod-重启后调度器首先判断该-pod下的-pvc-是否已经绑定如果已经绑定那么就根据-pvc-annotation-volumekubernetesioselected-node-字段过滤到其他-node>当 Pod 重启后，调度器首先判断该 Pod下的 PVC 是否已经绑定，如果已经绑定，那么就根据 PVC Annotation <code>volume.kubernetes.io/selected-node</code> 字段过滤到其他 node。
<a class=anchor href=#%e5%bd%93-pod-%e9%87%8d%e5%90%af%e5%90%8e%e8%b0%83%e5%ba%a6%e5%99%a8%e9%a6%96%e5%85%88%e5%88%a4%e6%96%ad%e8%af%a5-pod%e4%b8%8b%e7%9a%84-pvc-%e6%98%af%e5%90%a6%e5%b7%b2%e7%bb%8f%e7%bb%91%e5%ae%9a%e5%a6%82%e6%9e%9c%e5%b7%b2%e7%bb%8f%e7%bb%91%e5%ae%9a%e9%82%a3%e4%b9%88%e5%b0%b1%e6%a0%b9%e6%8d%ae-pvc-annotation-volumekubernetesioselected-node-%e5%ad%97%e6%ae%b5%e8%bf%87%e6%bb%a4%e5%88%b0%e5%85%b6%e4%bb%96-node>#</a></h5><h5 id=这样就保证该-pod-就一直在-pv-所在-node-上运行>这样就保证该 Pod 就一直在 PV 所在 node 上运行。
<a class=anchor href=#%e8%bf%99%e6%a0%b7%e5%b0%b1%e4%bf%9d%e8%af%81%e8%af%a5-pod-%e5%b0%b1%e4%b8%80%e7%9b%b4%e5%9c%a8-pv-%e6%89%80%e5%9c%a8-node-%e4%b8%8a%e8%bf%90%e8%a1%8c>#</a></h5><h5 id=这段代码逻辑参考以下>这段代码逻辑参考以下：
<a class=anchor href=#%e8%bf%99%e6%ae%b5%e4%bb%a3%e7%a0%81%e9%80%bb%e8%be%91%e5%8f%82%e8%80%83%e4%bb%a5%e4%b8%8b>#</a></h5><pre tabindex=0><code>// For PVCs that are bound, then it checks that the corresponding PV&#39;s node affinity is
// satisfied by the given node.

// kubernetes/pkg/scheduler/framework/plugins/volumebinding/binder.go:316
func (b *volumeBinder) FindPodVolumes(pod *v1.Pod, boundClaims, claimsToBind []*v1.PersistentVolumeClaim, node *v1.Node) (podVolumes *PodVolumes, reasons ConflictReasons, err error) {
...
        // Find matching volumes and node for unbound claims
    if len(claimsToBind) &gt; 0 {
        var (
            claimsToFindMatching []*v1.PersistentVolumeClaim
            claimsToProvision    []*v1.PersistentVolumeClaim
        )

        // 调度器对集群中的 node 与 pvc Annotation volume.kubernetes.io/selected-node 字段比较，过滤掉不匹配 node
        for _, claim := range claimsToBind {
            if selectedNode, ok := claim.Annotations[volume.AnnSelectedNode]; ok {
                if selectedNode != node.Name {
                    // Fast path, skip unmatched node.
                    unboundVolumesSatisfied = false
                    return
                }
                claimsToProvision = append(claimsToProvision, claim)
            } else {
                claimsToFindMatching = append(claimsToFindMatching, claim)
            }
        }
...
}
</code></pre><h5 id=上面说的-pvc-annotation-是在-pod-调度完成后调度器设置该-annotation其-value-是节点名称>上面说的 PVC Annotation 是在 Pod 调度完成后，调度器设置该 Annotation，其 value 是<strong>节点名称</strong>。
<a class=anchor href=#%e4%b8%8a%e9%9d%a2%e8%af%b4%e7%9a%84-pvc-annotation-%e6%98%af%e5%9c%a8-pod-%e8%b0%83%e5%ba%a6%e5%ae%8c%e6%88%90%e5%90%8e%e8%b0%83%e5%ba%a6%e5%99%a8%e8%ae%be%e7%bd%ae%e8%af%a5-annotation%e5%85%b6-value-%e6%98%af%e8%8a%82%e7%82%b9%e5%90%8d%e7%a7%b0>#</a></h5><h5 id=这段代码逻辑参考以下-1>这段代码逻辑参考以下：
<a class=anchor href=#%e8%bf%99%e6%ae%b5%e4%bb%a3%e7%a0%81%e9%80%bb%e8%be%91%e5%8f%82%e8%80%83%e4%bb%a5%e4%b8%8b-1>#</a></h5><pre tabindex=0><code>// AssumePodVolumes will take the matching PVs and PVCs to provision in pod&#39;s
// volume information for the chosen node, and:
// 1. Update the pvCache with the new prebound PV.
// 2. Update the pvcCache with the new PVCs with annotations set
// 3. Update PodVolumes again with cached API updates for PVs and PVCs.

// kubernetes/pkg/scheduler/framework/plugins/volumebinding/binder.go:359
func (b *volumeBinder) AssumePodVolumes(assumedPod *v1.Pod, nodeName string, podVolumes *PodVolumes) (allFullyBound bool, err error) {
    ...

    newProvisionedPVCs := []*v1.PersistentVolumeClaim{}
    for _, claim := range podVolumes.DynamicProvisions {
        claimClone := claim.DeepCopy()
        // 设置 volume.kubernetes.io/selected-node annotation，value 为该 pod 调度的 nodeName
        metav1.SetMetaDataAnnotation(&amp;claimClone.ObjectMeta, volume.AnnSelectedNode, nodeName)
        err = b.pvcCache.Assume(claimClone)
        if err != nil {
            b.revertAssumedPVs(newBindings)
            b.revertAssumedPVCs(newProvisionedPVCs)
            return
        }

        newProvisionedPVCs = append(newProvisionedPVCs, claimClone)
    }

    podVolumes.StaticBindings = newBindings
    podVolumes.DynamicProvisions = newProvisionedPVCs
    return
}
</code></pre><hr><h2 id=openebs-使用>OpenEBS 使用
<a class=anchor href=#openebs-%e4%bd%bf%e7%94%a8>#</a></h2><h5 id=openebs-对本地存储卷功能支持非常好>OpenEBS 对本地存储卷功能支持非常好：
<a class=anchor href=#openebs-%e5%af%b9%e6%9c%ac%e5%9c%b0%e5%ad%98%e5%82%a8%e5%8d%b7%e5%8a%9f%e8%83%bd%e6%94%af%e6%8c%81%e9%9d%9e%e5%b8%b8%e5%a5%bd>#</a></h5><ul><li><h5 id=-openebs可以使用宿主机裸块设备或分区或者使用hostpaths上的子目录或者使用lvmzfs来创建持久化卷>• <code>OpenEBS</code>可以使用宿主机<code>裸块设备或分区</code>，或者使用<code>Hostpaths</code>上的子目录，或者使用<code>LVM</code>、<code>ZFS</code>来创建持久化卷
<a class=anchor href=#-openebs%e5%8f%af%e4%bb%a5%e4%bd%bf%e7%94%a8%e5%ae%bf%e4%b8%bb%e6%9c%ba%e8%a3%b8%e5%9d%97%e8%ae%be%e5%a4%87%e6%88%96%e5%88%86%e5%8c%ba%e6%88%96%e8%80%85%e4%bd%bf%e7%94%a8hostpaths%e4%b8%8a%e7%9a%84%e5%ad%90%e7%9b%ae%e5%bd%95%e6%88%96%e8%80%85%e4%bd%bf%e7%94%a8lvmzfs%e6%9d%a5%e5%88%9b%e5%bb%ba%e6%8c%81%e4%b9%85%e5%8c%96%e5%8d%b7>#</a></h5></li><li><h5 id=-本地卷直接挂载到statefulset-pod中而不需要openebs在数据路径中增加任何开销>• 本地卷直接挂载到<code>StatefulSet Pod</code>中，而不需要<code>OpenEBS</code>在数据路径中增加任何开销
<a class=anchor href=#-%e6%9c%ac%e5%9c%b0%e5%8d%b7%e7%9b%b4%e6%8e%a5%e6%8c%82%e8%bd%bd%e5%88%b0statefulset-pod%e4%b8%ad%e8%80%8c%e4%b8%8d%e9%9c%80%e8%a6%81openebs%e5%9c%a8%e6%95%b0%e6%8d%ae%e8%b7%af%e5%be%84%e4%b8%ad%e5%a2%9e%e5%8a%a0%e4%bb%bb%e4%bd%95%e5%bc%80%e9%94%80>#</a></h5></li><li><h5 id=-openebs为本地卷提供了额外的工具用于监控备份恢复灾难恢复由zfs或lvm支持的快照等>• <code>OpenEBS</code>为本地卷提供了额外的工具，用于监控、备份/恢复、灾难恢复、由<code>ZFS</code>或<code>LVM</code>支持的快照等
<a class=anchor href=#-openebs%e4%b8%ba%e6%9c%ac%e5%9c%b0%e5%8d%b7%e6%8f%90%e4%be%9b%e4%ba%86%e9%a2%9d%e5%a4%96%e7%9a%84%e5%b7%a5%e5%85%b7%e7%94%a8%e4%ba%8e%e7%9b%91%e6%8e%a7%e5%a4%87%e4%bb%bd%e6%81%a2%e5%a4%8d%e7%81%be%e9%9a%be%e6%81%a2%e5%a4%8d%e7%94%b1zfs%e6%88%96lvm%e6%94%af%e6%8c%81%e7%9a%84%e5%bf%ab%e7%85%a7%e7%ad%89>#</a></h5></li></ul><h5 id=同时-openebs-屏蔽了我们使用-local-pv-复杂性openebs-部署及使用也是非常方便>同时 OpenEBS 屏蔽了我们使用 Local PV 复杂性。OpenEBS 部署及使用也是非常方便。
<a class=anchor href=#%e5%90%8c%e6%97%b6-openebs-%e5%b1%8f%e8%94%bd%e4%ba%86%e6%88%91%e4%bb%ac%e4%bd%bf%e7%94%a8-local-pv-%e5%a4%8d%e6%9d%82%e6%80%a7openebs-%e9%83%a8%e7%bd%b2%e5%8f%8a%e4%bd%bf%e7%94%a8%e4%b9%9f%e6%98%af%e9%9d%9e%e5%b8%b8%e6%96%b9%e4%be%bf>#</a></h5><h5 id=这里我们只使用-local-pv-hostpath即使用本地文件系统的存储根据官网介绍不需要提前安装-iscsi>这里我们只使用 <strong>local-pv-hostpath</strong>，即使用本地文件系统的存储，根据官网介绍，不需要提前安装 <strong>iscsi</strong>
<a class=anchor href=#%e8%bf%99%e9%87%8c%e6%88%91%e4%bb%ac%e5%8f%aa%e4%bd%bf%e7%94%a8-local-pv-hostpath%e5%8d%b3%e4%bd%bf%e7%94%a8%e6%9c%ac%e5%9c%b0%e6%96%87%e4%bb%b6%e7%b3%bb%e7%bb%9f%e7%9a%84%e5%ad%98%e5%82%a8%e6%a0%b9%e6%8d%ae%e5%ae%98%e7%bd%91%e4%bb%8b%e7%bb%8d%e4%b8%8d%e9%9c%80%e8%a6%81%e6%8f%90%e5%89%8d%e5%ae%89%e8%a3%85-iscsi>#</a></h5><h3 id=helm-部署>Helm 部署
<a class=anchor href=#helm-%e9%83%a8%e7%bd%b2>#</a></h3><pre tabindex=0><code>$ helm repo add openebs https://openebs.github.io/charts
$ helm repo update
$ helm install openebs --namespace openebs openebs/openebs --create-namespace
</code></pre><h3 id=kubectl-部署>kubectl 部署
<a class=anchor href=#kubectl-%e9%83%a8%e7%bd%b2>#</a></h3><pre tabindex=0><code>kubectl apply -f https://openebs.github.io/charts/openebs-operator.yaml
</code></pre><h5 id=安装成功后默认会部署两个-storageclass-我们目前需要-openebs-hostpath>安装成功后，默认会部署两个 <strong>storageclass</strong> ，我们目前需要 <strong>openebs-hostpath。</strong>
<a class=anchor href=#%e5%ae%89%e8%a3%85%e6%88%90%e5%8a%9f%e5%90%8e%e9%bb%98%e8%ae%a4%e4%bc%9a%e9%83%a8%e7%bd%b2%e4%b8%a4%e4%b8%aa-storageclass-%e6%88%91%e4%bb%ac%e7%9b%ae%e5%89%8d%e9%9c%80%e8%a6%81-openebs-hostpath>#</a></h5><pre tabindex=0><code>$ kubectl get pods -n openebs
NAME                                           READY   STATUS    RESTARTS   AGE
openebs-localpv-provisioner-69c8648db7-cnj45   1/1     Running   0          33m
openebs-ndm-bbgpv                              1/1     Running   0          33m
openebs-ndm-bxsbb                              1/1     Running   0          33m
openebs-ndm-cluster-exporter-9d75d564d-qvqz6   1/1     Running   0          33m
openebs-ndm-kdg7b                              1/1     Running   0          33m
openebs-ndm-node-exporter-9zm62                1/1     Running   0          33m
openebs-ndm-node-exporter-hlj7h                1/1     Running   0          33m
openebs-ndm-node-exporter-j6wj7                1/1     Running   0          33m
openebs-ndm-node-exporter-s5hk4                1/1     Running   0          33m
openebs-ndm-operator-789985cc47-r4hwj          1/1     Running   0          33m
openebs-ndm-qm4sw                              1/1     Running   0          33m
$ kubectl get sc
NAME               PROVISIONER        RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
openebs-device     openebs.io/local   Delete          WaitForFirstConsumer   false                  116s
openebs-hostpath   openebs.io/local   Delete          WaitForFirstConsumer   false                  116s
</code></pre><h5 id=默认存储目录为-varopenebslocal-如果需要更改的话直接修改-openebs-operatoryamlvalue-字段即可>默认存储目录为 ****<code>/var/openebs/local</code>, 如果需要更改的话，直接修改 <code>openebs-operator.yaml</code>，<code>value</code> 字段即可
<a class=anchor href=#%e9%bb%98%e8%ae%a4%e5%ad%98%e5%82%a8%e7%9b%ae%e5%bd%95%e4%b8%ba-varopenebslocal-%e5%a6%82%e6%9e%9c%e9%9c%80%e8%a6%81%e6%9b%b4%e6%94%b9%e7%9a%84%e8%af%9d%e7%9b%b4%e6%8e%a5%e4%bf%ae%e6%94%b9-openebs-operatoryamlvalue-%e5%ad%97%e6%ae%b5%e5%8d%b3%e5%8f%af>#</a></h5><pre tabindex=0><code>apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: openebs-hostpath
  annotations:
    openebs.io/cas-type: local
    cas.openebs.io/config: |
      #hostpath type will create a PV by 
      # creating a sub-directory under the
      # BASEPATH provided below.
      - name: StorageType
        value: &#34;hostpath&#34;
      #Specify the location (directory) where
      # where PV(volume) data will be saved. 
      # A sub-directory with pv-name will be 
      # created. When the volume is deleted, 
      # the PV sub-directory will be deleted.
      #Default value is /var/openebs/local
      - name: BasePath
        value: &#34;/var/openebs/local/&#34;
</code></pre><h3 id=验证>验证
<a class=anchor href=#%e9%aa%8c%e8%af%81>#</a></h3><h5 id=接下来我们创建一个-pvc-资源对象pod-使用这个-pvc-就可以从-openebs-动态-local-pv-provisioner-中请求-hostpath-local-pv-了>接下来我们创建一个 PVC 资源对象，Pod 使用这个 PVC 就可以从 OpenEBS 动态 Local PV Provisioner 中请求 Hostpath Local PV 了。
<a class=anchor href=#%e6%8e%a5%e4%b8%8b%e6%9d%a5%e6%88%91%e4%bb%ac%e5%88%9b%e5%bb%ba%e4%b8%80%e4%b8%aa-pvc-%e8%b5%84%e6%ba%90%e5%af%b9%e8%b1%a1pod-%e4%bd%bf%e7%94%a8%e8%bf%99%e4%b8%aa-pvc-%e5%b0%b1%e5%8f%af%e4%bb%a5%e4%bb%8e-openebs-%e5%8a%a8%e6%80%81-local-pv-provisioner-%e4%b8%ad%e8%af%b7%e6%b1%82-hostpath-local-pv-%e4%ba%86>#</a></h5><pre tabindex=0><code># local-hostpath-pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: local-hostpath-pvc
spec:
  storageClassName: openebs-hostpath
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
</code></pre><h5 id=直接创建这个-pvc-即可>直接创建这个 PVC 即可：
<a class=anchor href=#%e7%9b%b4%e6%8e%a5%e5%88%9b%e5%bb%ba%e8%bf%99%e4%b8%aa-pvc-%e5%8d%b3%e5%8f%af>#</a></h5><pre tabindex=0><code>$ kubectl apply -f local-hostpath-pvc.yaml
$ kubectl get pvc local-hostpath-pvc
NAME                 STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS       AGE
local-hostpath-pvc   Pending                                      openebs-hostpath   12s
</code></pre><h5 id=我们可以看到这个-pvc-的状态是-pending这是因为对应的-storageclass-是延迟绑定模式所以需要等到-pod-消费这个-pvc-后才会去绑定接下来我们去创建一个-pod-来使用这个-pvc>我们可以看到这个 PVC 的状态是 <code>Pending</code>，这是因为对应的 StorageClass 是延迟绑定模式，所以需要等到 Pod 消费这个 PVC 后才会去绑定，接下来我们去创建一个 Pod 来使用这个 PVC。
<a class=anchor href=#%e6%88%91%e4%bb%ac%e5%8f%af%e4%bb%a5%e7%9c%8b%e5%88%b0%e8%bf%99%e4%b8%aa-pvc-%e7%9a%84%e7%8a%b6%e6%80%81%e6%98%af-pending%e8%bf%99%e6%98%af%e5%9b%a0%e4%b8%ba%e5%af%b9%e5%ba%94%e7%9a%84-storageclass-%e6%98%af%e5%bb%b6%e8%bf%9f%e7%bb%91%e5%ae%9a%e6%a8%a1%e5%bc%8f%e6%89%80%e4%bb%a5%e9%9c%80%e8%a6%81%e7%ad%89%e5%88%b0-pod-%e6%b6%88%e8%b4%b9%e8%bf%99%e4%b8%aa-pvc-%e5%90%8e%e6%89%8d%e4%bc%9a%e5%8e%bb%e7%bb%91%e5%ae%9a%e6%8e%a5%e4%b8%8b%e6%9d%a5%e6%88%91%e4%bb%ac%e5%8e%bb%e5%88%9b%e5%bb%ba%e4%b8%80%e4%b8%aa-pod-%e6%9d%a5%e4%bd%bf%e7%94%a8%e8%bf%99%e4%b8%aa-pvc>#</a></h5><h5 id=声明一个如下所示的-pod-资源清单>声明一个如下所示的 Pod 资源清单：
<a class=anchor href=#%e5%a3%b0%e6%98%8e%e4%b8%80%e4%b8%aa%e5%a6%82%e4%b8%8b%e6%89%80%e7%a4%ba%e7%9a%84-pod-%e8%b5%84%e6%ba%90%e6%b8%85%e5%8d%95>#</a></h5><pre tabindex=0><code># local-hostpath-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: hello-local-hostpath-pod
spec:
  volumes:
  - name: local-storage
    persistentVolumeClaim:
      claimName: local-hostpath-pvc
  containers:
  - name: hello-container
    image: busybox
    command:
       - sh
       - -c
       - &#39;while true; do echo &#34;`date` [`hostname`] Hello from OpenEBS Local PV.&#34; &gt;&gt; /mnt/store/greet.txt; sleep $(($RANDOM % 5 + 300)); done&#39;
    volumeMounts:
    - mountPath: /mnt/store
      name: local-storage
</code></pre><h5 id=直接创建这个-pod>直接创建这个 Pod：
<a class=anchor href=#%e7%9b%b4%e6%8e%a5%e5%88%9b%e5%bb%ba%e8%bf%99%e4%b8%aa-pod>#</a></h5><pre tabindex=0><code>$ kubectl apply -f local-hostpath-pod.yaml
$ kubectl get pods hello-local-hostpath-pod
NAME                       READY   STATUS    RESTARTS   AGE
hello-local-hostpath-pod   1/1     Running   0          2m7s
$ kubectl get pvc local-hostpath-pvc
NAME                 STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS       AGE
local-hostpath-pvc   Bound    pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88   5Gi        RWO            openebs-hostpath   5m41s
</code></pre><h5 id=可以看到-pod-运行成功后pvc-也绑定上了一个自动生成的-pv我们可以查看这个-pv-的详细信息>可以看到 Pod 运行成功后，PVC 也绑定上了一个自动生成的 PV，我们可以查看这个 PV 的详细信息：
<a class=anchor href=#%e5%8f%af%e4%bb%a5%e7%9c%8b%e5%88%b0-pod-%e8%bf%90%e8%a1%8c%e6%88%90%e5%8a%9f%e5%90%8epvc-%e4%b9%9f%e7%bb%91%e5%ae%9a%e4%b8%8a%e4%ba%86%e4%b8%80%e4%b8%aa%e8%87%aa%e5%8a%a8%e7%94%9f%e6%88%90%e7%9a%84-pv%e6%88%91%e4%bb%ac%e5%8f%af%e4%bb%a5%e6%9f%a5%e7%9c%8b%e8%bf%99%e4%b8%aa-pv-%e7%9a%84%e8%af%a6%e7%bb%86%e4%bf%a1%e6%81%af>#</a></h5><pre tabindex=0><code>$ kubectl get pv pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88 -o yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  annotations:
    pv.kubernetes.io/provisioned-by: openebs.io/local
  creationTimestamp: &#34;2021-01-07T02:48:14Z&#34;
  finalizers:
  - kubernetes.io/pv-protection
  labels:
    openebs.io/cas-type: local-hostpath
  ......
  name: pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88
  resourceVersion: &#34;21193802&#34;
  selfLink: /api/v1/persistentvolumes/pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88
  uid: f7cccdb3-d23a-4831-86c3-4363eb1a8dee
spec:
  accessModes:
  - ReadWriteOnce
  capacity:
    storage: 5Gi
  claimRef:
    apiVersion: v1
    kind: PersistentVolumeClaim
    name: local-hostpath-pvc
    namespace: default
    resourceVersion: &#34;21193645&#34;
    uid: 3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88
  local:
    fsType: &#34;&#34;
    path: /var/openebs/local/pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node2
  persistentVolumeReclaimPolicy: Delete
  storageClassName: openebs-hostpath
  volumeMode: Filesystem
status:
  phase: Bound
</code></pre><h5 id=本地数据目录位于-varopenebslocalpvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88-下面>本地数据目录位于 <code>/var/openebs/local/pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88</code> 下面。
<a class=anchor href=#%e6%9c%ac%e5%9c%b0%e6%95%b0%e6%8d%ae%e7%9b%ae%e5%bd%95%e4%bd%8d%e4%ba%8e-varopenebslocalpvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88-%e4%b8%8b%e9%9d%a2>#</a></h5><h5 id=接着我们来验证下-volume-数据前往-node2-节点查看下上面的数据目录中的数据>接着我们来验证下 volume 数据，前往 node2 节点查看下上面的数据目录中的数据：
<a class=anchor href=#%e6%8e%a5%e7%9d%80%e6%88%91%e4%bb%ac%e6%9d%a5%e9%aa%8c%e8%af%81%e4%b8%8b-volume-%e6%95%b0%e6%8d%ae%e5%89%8d%e5%be%80-node2-%e8%8a%82%e7%82%b9%e6%9f%a5%e7%9c%8b%e4%b8%8b%e4%b8%8a%e9%9d%a2%e7%9a%84%e6%95%b0%e6%8d%ae%e7%9b%ae%e5%bd%95%e4%b8%ad%e7%9a%84%e6%95%b0%e6%8d%ae>#</a></h5><pre tabindex=0><code>$ ls /var/openebs/local/pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88
greet.txt
$ cat /var/openebs/local/pvc-3f4a1a65-6cbc-42bf-a1f8-87ad238c0b88/greet.txt
Thu Jan  7 10:48:49 CST 2021 [hello-local-hostpath-pod] Hello from OpenEBS Local PV.
Thu Jan  7 10:53:50 CST 2021 [hello-local-hostpath-pod] Hello from OpenEBS Local PV.
</code></pre><h5 id=可以看到-pod-容器中的数据已经持久化到-local-pv-对应的目录中去了但是需要注意的是-storageclass-默认的数据回收策略是-delete所以如果将-pvc-删掉后数据会自动删除我们可以-velero-这样的工具来进行备份还原>可以看到 Pod 容器中的数据已经持久化到 Local PV 对应的目录中去了。但是需要注意的是 StorageClass 默认的数据回收策略是 Delete，所以如果将 PVC 删掉后数据会自动删除，我们可以 <code>Velero</code> 这样的工具来进行备份还原。
<a class=anchor href=#%e5%8f%af%e4%bb%a5%e7%9c%8b%e5%88%b0-pod-%e5%ae%b9%e5%99%a8%e4%b8%ad%e7%9a%84%e6%95%b0%e6%8d%ae%e5%b7%b2%e7%bb%8f%e6%8c%81%e4%b9%85%e5%8c%96%e5%88%b0-local-pv-%e5%af%b9%e5%ba%94%e7%9a%84%e7%9b%ae%e5%bd%95%e4%b8%ad%e5%8e%bb%e4%ba%86%e4%bd%86%e6%98%af%e9%9c%80%e8%a6%81%e6%b3%a8%e6%84%8f%e7%9a%84%e6%98%af-storageclass-%e9%bb%98%e8%ae%a4%e7%9a%84%e6%95%b0%e6%8d%ae%e5%9b%9e%e6%94%b6%e7%ad%96%e7%95%a5%e6%98%af-delete%e6%89%80%e4%bb%a5%e5%a6%82%e6%9e%9c%e5%b0%86-pvc-%e5%88%a0%e6%8e%89%e5%90%8e%e6%95%b0%e6%8d%ae%e4%bc%9a%e8%87%aa%e5%8a%a8%e5%88%a0%e9%99%a4%e6%88%91%e4%bb%ac%e5%8f%af%e4%bb%a5-velero-%e8%bf%99%e6%a0%b7%e7%9a%84%e5%b7%a5%e5%85%b7%e6%9d%a5%e8%bf%9b%e8%a1%8c%e5%a4%87%e4%bb%bd%e8%bf%98%e5%8e%9f>#</a></h5><hr><h2 id=openebs-local-pv-原理>OpenEBS Local PV 原理
<a class=anchor href=#openebs-local-pv-%e5%8e%9f%e7%90%86>#</a></h2><h5 id=由于-openebs-实现了多种存储由于篇幅问题下面只详细讲解-hostpath-类型原理>由于 OpenEBS 实现了多种存储，由于篇幅问题，下面只详细讲解 <strong>Hostpath</strong> 类型原理
<a class=anchor href=#%e7%94%b1%e4%ba%8e-openebs-%e5%ae%9e%e7%8e%b0%e4%ba%86%e5%a4%9a%e7%a7%8d%e5%ad%98%e5%82%a8%e7%94%b1%e4%ba%8e%e7%af%87%e5%b9%85%e9%97%ae%e9%a2%98%e4%b8%8b%e9%9d%a2%e5%8f%aa%e8%af%a6%e7%bb%86%e8%ae%b2%e8%a7%a3-hostpath-%e7%b1%bb%e5%9e%8b%e5%8e%9f%e7%90%86>#</a></h5><h3 id=openebs-local-pv-部署架构>OpenEBS Local PV 部署架构
<a class=anchor href=#openebs-local-pv-%e9%83%a8%e7%bd%b2%e6%9e%b6%e6%9e%84>#</a></h3><h5 id=根据上一篇-kubernetes-csi-一-kubernetes-存储原理-说到-csi-分为两部分>根据上一篇 Kubernetes CSI (一): Kubernetes 存储原理 说到 CSI 分为两部分：
<a class=anchor href=#%e6%a0%b9%e6%8d%ae%e4%b8%8a%e4%b8%80%e7%af%87-kubernetes-csi-%e4%b8%80-kubernetes-%e5%ad%98%e5%82%a8%e5%8e%9f%e7%90%86-%e8%af%b4%e5%88%b0-csi-%e5%88%86%e4%b8%ba%e4%b8%a4%e9%83%a8%e5%88%86>#</a></h5><ul><li>• External component( Kubernetes Team )</li><li>• CSI Driver</li></ul><h5 id=具体作用和原理可查看原文>具体作用和原理可查看原文。
<a class=anchor href=#%e5%85%b7%e4%bd%93%e4%bd%9c%e7%94%a8%e5%92%8c%e5%8e%9f%e7%90%86%e5%8f%af%e6%9f%a5%e7%9c%8b%e5%8e%9f%e6%96%87>#</a></h5><h5 id=openebs-同样也实现了-csi所以它的部署架构遵从-csi-部署统一标准但是对于-local-pv-hostpath-类型并不需要那么复杂>OpenEBS 同样也实现了 CSI，所以它的部署架构遵从 CSI 部署统一标准。但是对于 Local PV (Hostpath) 类型并不需要那么复杂。
<a class=anchor href=#openebs-%e5%90%8c%e6%a0%b7%e4%b9%9f%e5%ae%9e%e7%8e%b0%e4%ba%86-csi%e6%89%80%e4%bb%a5%e5%ae%83%e7%9a%84%e9%83%a8%e7%bd%b2%e6%9e%b6%e6%9e%84%e9%81%b5%e4%bb%8e-csi-%e9%83%a8%e7%bd%b2%e7%bb%9f%e4%b8%80%e6%a0%87%e5%87%86%e4%bd%86%e6%98%af%e5%af%b9%e4%ba%8e-local-pv-hostpath-%e7%b1%bb%e5%9e%8b%e5%b9%b6%e4%b8%8d%e9%9c%80%e8%a6%81%e9%82%a3%e4%b9%88%e5%a4%8d%e6%9d%82>#</a></h5><h5 id=只需提供-openebs-localpv-provisioner-即可无需提供-csi-driver因为本地数据目录挂载-kubelet-就可以完成无需第三方-csi>只需提供 <strong>openebs-localpv-provisioner</strong> 即可，无需提供 CSI Driver，因为本地数据目录挂载 Kubelet 就可以完成，无需第三方 CSI。
<a class=anchor href=#%e5%8f%aa%e9%9c%80%e6%8f%90%e4%be%9b-openebs-localpv-provisioner-%e5%8d%b3%e5%8f%af%e6%97%a0%e9%9c%80%e6%8f%90%e4%be%9b-csi-driver%e5%9b%a0%e4%b8%ba%e6%9c%ac%e5%9c%b0%e6%95%b0%e6%8d%ae%e7%9b%ae%e5%bd%95%e6%8c%82%e8%bd%bd-kubelet-%e5%b0%b1%e5%8f%af%e4%bb%a5%e5%ae%8c%e6%88%90%e6%97%a0%e9%9c%80%e7%ac%ac%e4%b8%89%e6%96%b9-csi>#</a></h5><pre tabindex=0><code>$ kubectl get pods -n openebs
NAME                                           READY   STATUS    RESTARTS   AGE
openebs-localpv-provisioner-69c8648db7-cnj45   1/1     Running   0          33m
</code></pre><h5 id=根据上一篇文章讲解openebs-localpv-provisioner-应该是一个-deployment-或者-daemonset由-external-component-kubernetes-team--sidecar-和-csi-identity--csi-controller-组成>根据上一篇文章讲解，<strong>openebs-localpv-provisioner</strong> 应该是一个 Deployment 或者 DaemonSet，由 External component( Kubernetes Team ) sideCar 和 CSI Identity + CSI Controller 组成。
<a class=anchor href=#%e6%a0%b9%e6%8d%ae%e4%b8%8a%e4%b8%80%e7%af%87%e6%96%87%e7%ab%a0%e8%ae%b2%e8%a7%a3openebs-localpv-provisioner-%e5%ba%94%e8%af%a5%e6%98%af%e4%b8%80%e4%b8%aa-deployment-%e6%88%96%e8%80%85-daemonset%e7%94%b1-external-component-kubernetes-team--sidecar-%e5%92%8c-csi-identity--csi-controller-%e7%bb%84%e6%88%90>#</a></h5><pre tabindex=0><code>apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    name: openebs-localpv-provisioner
    openebs.io/component-name: openebs-localpv-provisioner
    openebs.io/version: 3.0.0
  name: openebs-localpv-provisioner
  namespace: openebs
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      name: openebs-localpv-provisioner
      openebs.io/component-name: openebs-localpv-provisioner
  strategy:
    type: Recreate
  template:
    metadata:
      creationTimestamp: null
      labels:
        name: openebs-localpv-provisioner
        openebs.io/component-name: openebs-localpv-provisioner
        openebs.io/version: 3.0.0
    spec:
      containers:
      - args:
        - --bd-time-out=$(BDC_BD_BIND_RETRIES)
        env:
        - name: BDC_BD_BIND_RETRIES
          value: &#34;12&#34;
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: spec.nodeName
        - name: OPENEBS_NAMESPACE
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
        - name: OPENEBS_SERVICE_ACCOUNT
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: spec.serviceAccountName
        - name: OPENEBS_IO_ENABLE_ANALYTICS
          value: &#34;true&#34;
        - name: OPENEBS_IO_INSTALLER_TYPE
          value: openebs-operator
        - name: OPENEBS_IO_HELPER_IMAGE
          value: openes.io/linux-utils:3.0.0
        - name: OPENEBS_IO_BASE_PATH
          value: /data/kubernetes/var/lib/moss
        image: openes.io/provisioner-localpv:3.0.0
        imagePullPolicy: IfNotPresent
        livenessProbe:
          exec:
            command:
            - sh
            - -c
            - test `pgrep -c &#34;^provisioner-loc.*&#34;` = 1
          failureThreshold: 3
          initialDelaySeconds: 30
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 1
        name: openebs-provisioner-hostpath
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: openebs-maya-operator
      serviceAccountName: openebs-maya-operator
      terminationGracePeriodSeconds: 30
</code></pre><h5 id=可以发现-openebs-localpv-provisioner-并没有-external-component-kubernetes-team--sidecar通过阅读该组件代码发现该组件本身已经集成了-external-provisioner-sig-storage-lib-external-provisioner-库-功能在后文会通过源码来解释>可以发现 <strong>openebs-localpv-provisioner</strong> 并没有 External component( Kubernetes Team ) sideCar，通过阅读该组件代码发现，该组件本身已经集成了 <strong>External provisioner (sig-storage-lib-external-provisioner 库)</strong> 功能，在后文会通过源码来解释。
<a class=anchor href=#%e5%8f%af%e4%bb%a5%e5%8f%91%e7%8e%b0-openebs-localpv-provisioner-%e5%b9%b6%e6%b2%a1%e6%9c%89-external-component-kubernetes-team--sidecar%e9%80%9a%e8%bf%87%e9%98%85%e8%af%bb%e8%af%a5%e7%bb%84%e4%bb%b6%e4%bb%a3%e7%a0%81%e5%8f%91%e7%8e%b0%e8%af%a5%e7%bb%84%e4%bb%b6%e6%9c%ac%e8%ba%ab%e5%b7%b2%e7%bb%8f%e9%9b%86%e6%88%90%e4%ba%86-external-provisioner-sig-storage-lib-external-provisioner-%e5%ba%93-%e5%8a%9f%e8%83%bd%e5%9c%a8%e5%90%8e%e6%96%87%e4%bc%9a%e9%80%9a%e8%bf%87%e6%ba%90%e7%a0%81%e6%9d%a5%e8%a7%a3%e9%87%8a>#</a></h5><h5 id=那么在-kubernetes-集群中当一个-pod-利用-openebs-hostpath-是如何被创建出来的>那么在 Kubernetes 集群中，当一个 Pod 利用 OpenEBS Hostpath 是如何被创建出来的。
<a class=anchor href=#%e9%82%a3%e4%b9%88%e5%9c%a8-kubernetes-%e9%9b%86%e7%be%a4%e4%b8%ad%e5%bd%93%e4%b8%80%e4%b8%aa-pod-%e5%88%a9%e7%94%a8-openebs-hostpath-%e6%98%af%e5%a6%82%e4%bd%95%e8%a2%ab%e5%88%9b%e5%bb%ba%e5%87%ba%e6%9d%a5%e7%9a%84>#</a></h5><ul><li><h5 id=-before-provisioning>• Before Provisioning：
<a class=anchor href=#-before-provisioning>#</a></h5></li><li><ul><li><h5 id=-pv-controller-首先判断-pvc-使用的-storageclass-是-in-tree-还是-out-of-tree通过查看-storageclass-的-provisioner-字段是否包含-kubernetesio-前缀来判断>• PV-Controller 首先判断 PVC 使用的 StorageClass 是 in-tree 还是 out-of-tree：通过查看 StorageClass 的 <code>Provisioner</code> 字段是否包含 <code>kubernetes.io/</code> 前缀来判断；
<a class=anchor href=#-pv-controller-%e9%a6%96%e5%85%88%e5%88%a4%e6%96%ad-pvc-%e4%bd%bf%e7%94%a8%e7%9a%84-storageclass-%e6%98%af-in-tree-%e8%bf%98%e6%98%af-out-of-tree%e9%80%9a%e8%bf%87%e6%9f%a5%e7%9c%8b-storageclass-%e7%9a%84-provisioner-%e5%ad%97%e6%ae%b5%e6%98%af%e5%90%a6%e5%8c%85%e5%90%ab-kubernetesio-%e5%89%8d%e7%bc%80%e6%9d%a5%e5%88%a4%e6%96%ad>#</a></h5></li><li><h5 id=-pv-controller-更新-pvc-的-annotationvolumebetakubernetesiostorage-provisioner--openebsiolocal>• PV-Controller 更新 PVC 的 annotation：<code>volume.beta.kubernetes.io/storage-provisioner = openebs.io/local</code>
<a class=anchor href=#-pv-controller-%e6%9b%b4%e6%96%b0-pvc-%e7%9a%84-annotationvolumebetakubernetesiostorage-provisioner--openebsiolocal>#</a></h5></li></ul></li><li><h5 id=-out-of-tree-provisioningexternal-provisioning>• out-of-tree Provisioning（external provisioning）：
<a class=anchor href=#-out-of-tree-provisioningexternal-provisioning>#</a></h5></li><li><ul><li><h5 id=-openebs-localpv-provisioner-sig-storage-lib-external-provisioner-watch-到-pvc>• openebs-localpv-provisioner( sig-storage-lib-external-provisioner) Watch 到 PVC；
<a class=anchor href=#-openebs-localpv-provisioner-sig-storage-lib-external-provisioner-watch-%e5%88%b0-pvc>#</a></h5></li><li><h5 id=-openebs-localpv-provisioner-sig-storage-lib-external-provisioner-检查-pvc-中的----------specvolumename-是否为空不为空则直接跳过该-pvc>• openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 检查 PVC 中的 <code>Spec.VolumeName</code> 是否为空，不为空则直接跳过该 PVC；
<a class=anchor href=#-openebs-localpv-provisioner-sig-storage-lib-external-provisioner-%e6%a3%80%e6%9f%a5-pvc-%e4%b8%ad%e7%9a%84----------specvolumename-%e6%98%af%e5%90%a6%e4%b8%ba%e7%a9%ba%e4%b8%8d%e4%b8%ba%e7%a9%ba%e5%88%99%e7%9b%b4%e6%8e%a5%e8%b7%b3%e8%bf%87%e8%af%a5-pvc>#</a></h5></li><li><h5 id=-openebs-localpv-provisioner-sig-storage-lib-external-provisioner-检查-pvc-中的----------annotationsvolumebetakubernetesiostorage-provisioner是否等于自己的-provisioner-name-openebsiolocal->• openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 检查 PVC 中的 <code>Annotations[“volume.beta.kubernetes.io/storage-provisioner”]</code>是否等于自己的 Provisioner Name( <code>openebs.io/local</code> )；
<a class=anchor href=#-openebs-localpv-provisioner-sig-storage-lib-external-provisioner-%e6%a3%80%e6%9f%a5-pvc-%e4%b8%ad%e7%9a%84----------annotationsvolumebetakubernetesiostorage-provisioner%e6%98%af%e5%90%a6%e7%ad%89%e4%ba%8e%e8%87%aa%e5%b7%b1%e7%9a%84-provisioner-name-openebsiolocal->#</a></h5></li><li><h5 id=-openebs-localpv-provisioner-sig-storage-lib-external-provisioner-检查到-storageclass-的--volumebindingmode--waitforfirstconsumer所以需要延迟绑定等待-pod-调度完成>• openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 检查到 StorageClass 的 <code>VolumeBindingMode = WaitForFirstConsumer</code>，所以需要延迟绑定，等待 Pod 调度完成；
<a class=anchor href=#-openebs-localpv-provisioner-sig-storage-lib-external-provisioner-%e6%a3%80%e6%9f%a5%e5%88%b0-storageclass-%e7%9a%84--volumebindingmode--waitforfirstconsumer%e6%89%80%e4%bb%a5%e9%9c%80%e8%a6%81%e5%bb%b6%e8%bf%9f%e7%bb%91%e5%ae%9a%e7%ad%89%e5%be%85-pod-%e8%b0%83%e5%ba%a6%e5%ae%8c%e6%88%90>#</a></h5></li><li><h5 id=-pod-调度完成后openebs-localpv-provisioner-sig-storage-lib-external-provisioner-根据-pvc-annotation-volumekubernetesioselected-node-值选择-pv-所在节点>• pod 调度完成后，openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 根据 PVC Annotation <code>volume.kubernetes.io/selected-node</code> 值选择 PV 所在节点；
<a class=anchor href=#-pod-%e8%b0%83%e5%ba%a6%e5%ae%8c%e6%88%90%e5%90%8eopenebs-localpv-provisioner-sig-storage-lib-external-provisioner-%e6%a0%b9%e6%8d%ae-pvc-annotation-volumekubernetesioselected-node-%e5%80%bc%e9%80%89%e6%8b%a9-pv-%e6%89%80%e5%9c%a8%e8%8a%82%e7%82%b9>#</a></h5></li><li><h5 id=-openebs-localpv-provisioner-sig-storage-lib-external-provisioner-调用-openebs-localpv-provisioner-方法创建本地数据目录并返回-pv-结构体对象>• openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 调用 openebs-localpv-provisioner 方法创建本地数据目录并返回 PV 结构体对象；
<a class=anchor href=#-openebs-localpv-provisioner-sig-storage-lib-external-provisioner-%e8%b0%83%e7%94%a8-openebs-localpv-provisioner-%e6%96%b9%e6%b3%95%e5%88%9b%e5%bb%ba%e6%9c%ac%e5%9c%b0%e6%95%b0%e6%8d%ae%e7%9b%ae%e5%bd%95%e5%b9%b6%e8%bf%94%e5%9b%9e-pv-%e7%bb%93%e6%9e%84%e4%bd%93%e5%af%b9%e8%b1%a1>#</a></h5></li><li><h5 id=-openebs-localpv-provisioner-sig-storage-lib-external-provisioner-创建-pv>• openebs-localpv-provisioner( sig-storage-lib-external-provisioner) 创建 PV
<a class=anchor href=#-openebs-localpv-provisioner-sig-storage-lib-external-provisioner-%e5%88%9b%e5%bb%ba-pv>#</a></h5></li><li><h5 id=-pv-controller-同时将该-pv-与之前的-pvc-做绑定>• PV-Controller 同时将该 PV 与之前的 PVC 做绑定。
<a class=anchor href=#-pv-controller-%e5%90%8c%e6%97%b6%e5%b0%86%e8%af%a5-pv-%e4%b8%8e%e4%b9%8b%e5%89%8d%e7%9a%84-pvc-%e5%81%9a%e7%bb%91%e5%ae%9a>#</a></h5></li></ul></li><li><h5 id=-kube-scheduler-watch-到-pod并根据一系列算法选择节点>• kube-scheduler watch 到 Pod，并根据一系列算法选择节点；
<a class=anchor href=#-kube-scheduler-watch-%e5%88%b0-pod%e5%b9%b6%e6%a0%b9%e6%8d%ae%e4%b8%80%e7%b3%bb%e5%88%97%e7%ae%97%e6%b3%95%e9%80%89%e6%8b%a9%e8%8a%82%e7%82%b9>#</a></h5></li><li><ul><li><h5 id=-在这过程中会检查-pod-的-pvc-是否已经绑定如果绑定了就根据该-pvc-annotation-volumekubernetesioselected-node-选择该节点作为最终运行的节点>• 在这过程中会检查 Pod 的 PVC 是否已经绑定，如果绑定了就根据该 PVC Annotation <code>volume.kubernetes.io/selected-node</code> 选择该节点作为最终运行的节点；
<a class=anchor href=#-%e5%9c%a8%e8%bf%99%e8%bf%87%e7%a8%8b%e4%b8%ad%e4%bc%9a%e6%a3%80%e6%9f%a5-pod-%e7%9a%84-pvc-%e6%98%af%e5%90%a6%e5%b7%b2%e7%bb%8f%e7%bb%91%e5%ae%9a%e5%a6%82%e6%9e%9c%e7%bb%91%e5%ae%9a%e4%ba%86%e5%b0%b1%e6%a0%b9%e6%8d%ae%e8%af%a5-pvc-annotation-volumekubernetesioselected-node-%e9%80%89%e6%8b%a9%e8%af%a5%e8%8a%82%e7%82%b9%e4%bd%9c%e4%b8%ba%e6%9c%80%e7%bb%88%e8%bf%90%e8%a1%8c%e7%9a%84%e8%8a%82%e7%82%b9>#</a></h5></li><li><h5 id=-如果-pvc-没有绑定那么-kube-scheduler-就根据调度算法选择合适节点并设置该-pvc-annotation-volumekubernetesioselected-node--nodename->• 如果 PVC 没有绑定，那么 kube-scheduler 就根据调度算法选择合适节点，并设置该 PVC Annotation <code>volume.kubernetes.io/selected-node = node.name</code> 。
<a class=anchor href=#-%e5%a6%82%e6%9e%9c-pvc-%e6%b2%a1%e6%9c%89%e7%bb%91%e5%ae%9a%e9%82%a3%e4%b9%88-kube-scheduler-%e5%b0%b1%e6%a0%b9%e6%8d%ae%e8%b0%83%e5%ba%a6%e7%ae%97%e6%b3%95%e9%80%89%e6%8b%a9%e5%90%88%e9%80%82%e8%8a%82%e7%82%b9%e5%b9%b6%e8%ae%be%e7%bd%ae%e8%af%a5-pvc-annotation-volumekubernetesioselected-node--nodename->#</a></h5></li></ul></li><li><h5 id=-kubelet-将-pv-的数据目录绑定到-pod-容器内部>• Kubelet 将 PV 的数据目录绑定到 Pod 容器内部。
<a class=anchor href=#-kubelet-%e5%b0%86-pv-%e7%9a%84%e6%95%b0%e6%8d%ae%e7%9b%ae%e5%bd%95%e7%bb%91%e5%ae%9a%e5%88%b0-pod-%e5%ae%b9%e5%99%a8%e5%86%85%e9%83%a8>#</a></h5></li></ul><h5 id=下图简单描述以上流程>下图简单描述以上流程：
<a class=anchor href=#%e4%b8%8b%e5%9b%be%e7%ae%80%e5%8d%95%e6%8f%8f%e8%bf%b0%e4%bb%a5%e4%b8%8a%e6%b5%81%e7%a8%8b>#</a></h5><p><img src=https://picture-base.oss-cn-hangzhou.aliyuncs.com/picture/202403191605670.png alt=image-20240319160554590></p><p><img src=https://picture-base.oss-cn-hangzhou.aliyuncs.com/picture/202403191606214.png alt=image-20240319160610150></p><p><img src=https://picture-base.oss-cn-hangzhou.aliyuncs.com/picture/202403191606939.png alt=image-20240319160621875></p><h3 id=openebs-localpv-provisioner-源码解析>openebs-localpv-provisioner 源码解析
<a class=anchor href=#openebs-localpv-provisioner-%e6%ba%90%e7%a0%81%e8%a7%a3%e6%9e%90>#</a></h3><h5 id=上面分析了创建一个申请了-local-pv-的-pod-的流程下面通过源码走读分析以上流程组件源码地址httpsgithubcomopenebsdynamic-localpv-provisionergit>上面分析了创建一个申请了 <code>Local PV</code> 的 Pod 的流程，下面通过源码走读分析以上流程。组件源码地址：https://github.com/openebs/dynamic-localpv-provisioner.git
<a class=anchor href=#%e4%b8%8a%e9%9d%a2%e5%88%86%e6%9e%90%e4%ba%86%e5%88%9b%e5%bb%ba%e4%b8%80%e4%b8%aa%e7%94%b3%e8%af%b7%e4%ba%86-local-pv-%e7%9a%84-pod-%e7%9a%84%e6%b5%81%e7%a8%8b%e4%b8%8b%e9%9d%a2%e9%80%9a%e8%bf%87%e6%ba%90%e7%a0%81%e8%b5%b0%e8%af%bb%e5%88%86%e6%9e%90%e4%bb%a5%e4%b8%8a%e6%b5%81%e7%a8%8b%e7%bb%84%e4%bb%b6%e6%ba%90%e7%a0%81%e5%9c%b0%e5%9d%80httpsgithubcomopenebsdynamic-localpv-provisionergit>#</a></h5><h5 id=然后-dynamic-localpv-provisoner-组件集成了-external-provisoner-的功能使用的是-sig-storage-lib-external-provisioner-库源码地址httpsgithubcomkubernetes-sigssig-storage-lib-external-provisionergit>然后 dynamic-localpv-provisoner 组件集成了 external-provisoner 的功能，使用的是 <code>sig-storage-lib-external-provisioner</code> 库，源码地址：https://github.com/kubernetes-sigs/sig-storage-lib-external-provisioner.git
<a class=anchor href=#%e7%84%b6%e5%90%8e-dynamic-localpv-provisoner-%e7%bb%84%e4%bb%b6%e9%9b%86%e6%88%90%e4%ba%86-external-provisoner-%e7%9a%84%e5%8a%9f%e8%83%bd%e4%bd%bf%e7%94%a8%e7%9a%84%e6%98%af-sig-storage-lib-external-provisioner-%e5%ba%93%e6%ba%90%e7%a0%81%e5%9c%b0%e5%9d%80httpsgithubcomkubernetes-sigssig-storage-lib-external-provisionergit>#</a></h5><h5 id=dynamic-localpv-provisoner-启动后-watch-到-pvc根据上述流程对-pvc-一系列检查判断是否创建-pv>dynamic-localpv-provisoner 启动后 Watch 到 PVC，根据上述流程对 PVC 一系列检查，判断是否创建 PV；
<a class=anchor href=#dynamic-localpv-provisoner-%e5%90%af%e5%8a%a8%e5%90%8e-watch-%e5%88%b0-pvc%e6%a0%b9%e6%8d%ae%e4%b8%8a%e8%bf%b0%e6%b5%81%e7%a8%8b%e5%af%b9-pvc-%e4%b8%80%e7%b3%bb%e5%88%97%e6%a3%80%e6%9f%a5%e5%88%a4%e6%96%ad%e6%98%af%e5%90%a6%e5%88%9b%e5%bb%ba-pv>#</a></h5><pre tabindex=0><code>// sigs.k8s.io/sig-storage-lib-external-provisioner/v7@v7.0.1/controller/controller.go:1124
func (ctrl *ProvisionController) shouldProvision(ctx context.Context, claim *v1.PersistentVolumeClaim) (bool, error) {
  // dynamic-localpv-provisoner 启动后 Watch 到 PVC，检查 PVC 中的 `Spec.VolumeName` 是否为空，不为空则直接跳过该 PVC。
    if claim.Spec.VolumeName != &#34;&#34; {
        return false, nil
    }

    if qualifier, ok := ctrl.provisioner.(Qualifier); ok {
        if !qualifier.ShouldProvision(ctx, claim) {
            return false, nil
        }
    }
    
    // 检查 PVC 中的 Annotations[“volume.beta.kubernetes.io/storage-provisioner”]是否等于自己的 Provisioner Name( openebs.io/local )
    if provisioner, found := claim.Annotations[annStorageProvisioner]; found {
        if ctrl.knownProvisioner(provisioner) {
            claimClass := util.GetPersistentVolumeClaimClass(claim)
            class, err := ctrl.getStorageClass(claimClass)
            if err != nil {
                return false, err
            }
            // 查到 StorageClass 的 VolumeBindingMode = WaitForFirstConsumer，所以需要延迟绑定
            if class.VolumeBindingMode != nil &amp;&amp; *class.VolumeBindingMode == storage.VolumeBindingWaitForFirstConsumer {
                // 根据 PVC Annotation volume.kubernetes.io/selected-node 值选择 PV 所在节点
                if selectedNode, ok := claim.Annotations[annSelectedNode]; ok &amp;&amp; selectedNode != &#34;&#34; {
                    return true, nil
                }
                return false, nil
            }
            return true, nil
        }
    }

    return false, nil
}
</code></pre><h5 id=检查过后就需要在节点上创建-hostpath-数据目录了dynamic-localpv-provisoner-组件是通过创建一个临时-pod-来完成此次操作创建完成后会被删除>检查过后，就需要在节点上创建 Hostpath 数据目录了，dynamic-localpv-provisoner 组件是通过创建一个临时 pod 来完成此次操作，创建完成后会被删除；
<a class=anchor href=#%e6%a3%80%e6%9f%a5%e8%bf%87%e5%90%8e%e5%b0%b1%e9%9c%80%e8%a6%81%e5%9c%a8%e8%8a%82%e7%82%b9%e4%b8%8a%e5%88%9b%e5%bb%ba-hostpath-%e6%95%b0%e6%8d%ae%e7%9b%ae%e5%bd%95%e4%ba%86dynamic-localpv-provisoner-%e7%bb%84%e4%bb%b6%e6%98%af%e9%80%9a%e8%bf%87%e5%88%9b%e5%bb%ba%e4%b8%80%e4%b8%aa%e4%b8%b4%e6%97%b6-pod-%e6%9d%a5%e5%ae%8c%e6%88%90%e6%ad%a4%e6%ac%a1%e6%93%8d%e4%bd%9c%e5%88%9b%e5%bb%ba%e5%ae%8c%e6%88%90%e5%90%8e%e4%bc%9a%e8%a2%ab%e5%88%a0%e9%99%a4>#</a></h5><pre tabindex=0><code>// dynamic-localpv-provisioner/cmd/provisioner-localpv/app/helper_hostpath.go:167
func (p *Provisioner) createInitPod(ctx context.Context, pOpts *HelperPodOptions) error {
    var config podConfig
    config.pOpts, config.podName = pOpts, &#34;init&#34;
    //err := pOpts.validate()
    if err := pOpts.validate(); err != nil {
        return err
    }

    var vErr error
    config.parentDir, config.volumeDir, vErr = hostpath.NewBuilder().WithPath(pOpts.path).
        WithCheckf(hostpath.IsNonRoot(), &#34;volume directory {%v} should not be under root directory&#34;, pOpts.path).
        ExtractSubPath()
    if vErr != nil {
        return vErr
    }

    config.taints = pOpts.selectedNodeTaints

    config.pOpts.cmdsForPath = append(config.pOpts.cmdsForPath, filepath.Join(&#34;/data/&#34;, config.volumeDir))

    // 该 pod 用于在调度节点上创建数据目录
    iPod, err := p.launchPod(ctx, config)
    if err != nil {
        return err
    }

    // 创建完即可删除
    if err := p.exitPod(ctx, iPod); err != nil {
        return err
    }

    return nil
}
</code></pre><h5 id=数据目录创建完成后就表示-volume-存储卷创建完成就可以创建-pv-了>数据目录创建完成后，就表示 volume 存储卷创建完成，就可以创建 PV 了
<a class=anchor href=#%e6%95%b0%e6%8d%ae%e7%9b%ae%e5%bd%95%e5%88%9b%e5%bb%ba%e5%ae%8c%e6%88%90%e5%90%8e%e5%b0%b1%e8%a1%a8%e7%a4%ba-volume-%e5%ad%98%e5%82%a8%e5%8d%b7%e5%88%9b%e5%bb%ba%e5%ae%8c%e6%88%90%e5%b0%b1%e5%8f%af%e4%bb%a5%e5%88%9b%e5%bb%ba-pv-%e4%ba%86>#</a></h5><h5 id=创建-pv-是在-external-provisoner-完成的在-dynamic-localpv-provisoner-组件里也就是-sig-storage-lib-external-provisioner-库>创建 PV 是在 <strong>external-provisoner</strong> 完成的，在 dynamic-localpv-provisoner 组件里也就是 <code>sig-storage-lib-external-provisioner</code> 库
<a class=anchor href=#%e5%88%9b%e5%bb%ba-pv-%e6%98%af%e5%9c%a8-external-provisoner-%e5%ae%8c%e6%88%90%e7%9a%84%e5%9c%a8-dynamic-localpv-provisoner-%e7%bb%84%e4%bb%b6%e9%87%8c%e4%b9%9f%e5%b0%b1%e6%98%af-sig-storage-lib-external-provisioner-%e5%ba%93>#</a></h5><pre tabindex=0><code>// sig-storage-lib-external-provisioner/v7@v7.0.1/controller/volume_store.go:208
func (b *backoffStore) StoreVolume(claim *v1.PersistentVolumeClaim, volume *v1.PersistentVolume) error {
    // Try to create the PV object several times
    var lastSaveError error
    err := wait.ExponentialBackoff(*b.backoff, func() (bool, error) {
        klog.Infof(&#34;Trying to save persistentvolume %q&#34;, volume.Name)
        var err error
        // 创建 pv
        if _, err = b.client.CoreV1().PersistentVolumes().Create(context.Background(), volume, metav1.CreateOptions{}); err == nil || apierrs.IsAlreadyExists(err) {
            // Save succeeded.
            if err != nil {
                klog.Infof(&#34;persistentvolume %q already exists, reusing&#34;, volume.Name)
            } else {
                klog.Infof(&#34;persistentvolume %q saved&#34;, volume.Name)
            }
            return true, nil
        }
        // Save failed, try again after a while.
        klog.Infof(&#34;Failed to save persistentvolume %q: %v&#34;, volume.Name, err)
        lastSaveError = err
        return false, nil
    })

    if err == nil {
        // Save succeeded
        msg := fmt.Sprintf(&#34;Successfully provisioned volume %s&#34;, volume.Name)
        b.eventRecorder.Event(claim, v1.EventTypeNormal, &#34;ProvisioningSucceeded&#34;, msg)
        return nil
    }

    // Save failed. Now we have a storage asset outside of Kubernetes,
    // but we don&#39;t have appropriate PV object for it.
    // Emit some event here and try to delete the storage asset several
    // times.
    strerr := fmt.Sprintf(&#34;Error creating provisioned PV object for claim %s: %v. Deleting the volume.&#34;, claimToClaimKey(claim), lastSaveError)
    klog.Error(strerr)
    b.eventRecorder.Event(claim, v1.EventTypeWarning, &#34;ProvisioningFailed&#34;, strerr)

    var lastDeleteError error
    err = wait.ExponentialBackoff(*b.backoff, func() (bool, error) {
        if err = b.ctrl.provisioner.Delete(context.Background(), volume); err == nil {
            // Delete succeeded
            klog.Infof(&#34;Cleaning volume %q succeeded&#34;, volume.Name)
            return true, nil
        }
        // Delete failed, try again after a while.
        klog.Infof(&#34;Failed to clean volume %q: %v&#34;, volume.Name, err)
        lastDeleteError = err
        return false, nil
    })
    if err != nil {
        // Delete failed several times. There is an orphaned volume and there
        // is nothing we can do about it.
        strerr := fmt.Sprintf(&#34;Error cleaning provisioned volume for claim %s: %v. Please delete manually.&#34;, claimToClaimKey(claim), lastDeleteError)
        klog.Error(strerr)
        b.eventRecorder.Event(claim, v1.EventTypeWarning, &#34;ProvisioningCleanupFailed&#34;, strerr)
    }

    return lastSaveError
}
</code></pre><h5 id=接下来就是-pv-controller-将-pvc-和-pv-进行绑定kubelet-local-volume-将-pv-数据目录挂载到-pod-容器内部>接下来就是 PV Controller 将 PVC 和 PV 进行绑定，Kubelet Local-Volume 将 PV 数据目录挂载到 Pod 容器内部。
<a class=anchor href=#%e6%8e%a5%e4%b8%8b%e6%9d%a5%e5%b0%b1%e6%98%af-pv-controller-%e5%b0%86-pvc-%e5%92%8c-pv-%e8%bf%9b%e8%a1%8c%e7%bb%91%e5%ae%9akubelet-local-volume-%e5%b0%86-pv-%e6%95%b0%e6%8d%ae%e7%9b%ae%e5%bd%95%e6%8c%82%e8%bd%bd%e5%88%b0-pod-%e5%ae%b9%e5%99%a8%e5%86%85%e9%83%a8>#</a></h5><h5 id=整个-dynamic-localpv-provisoner-组件函数调用关系如下图>整个 dynamic-localpv-provisoner 组件函数调用关系如下图：
<a class=anchor href=#%e6%95%b4%e4%b8%aa-dynamic-localpv-provisoner-%e7%bb%84%e4%bb%b6%e5%87%bd%e6%95%b0%e8%b0%83%e7%94%a8%e5%85%b3%e7%b3%bb%e5%a6%82%e4%b8%8b%e5%9b%be>#</a></h5><p><img src=https://picture-base.oss-cn-hangzhou.aliyuncs.com/picture/202403191606359.png alt=image-20240319160649216></p><hr><h2 id=总结>总结
<a class=anchor href=#%e6%80%bb%e7%bb%93>#</a></h2><p>至此 OpenEBS Local PV( Hostpath ) 类型原理就讲解完了，这只是 OpenEBS 最简单的 CSI 实现，但也是使用很频繁的一类 CSI，其原理和上一篇分析的 CSI 大体原理基本类似。</p><p>结合 OpenEBS 的简单使用和源码解析，可以对 Kubernetes CSI 的原理理解更深一层，同时我们也可以自行实现一款 CSI 与 Kubernetes 对接。</p><hr></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#简介>简介</a><ul><li></li></ul></li><li><a href=#本地存储卷>本地存储卷</a><ul><li></li><li><a href=#local-pv>Local PV</a></li><li><a href=#延迟绑定>延迟绑定</a></li><li><a href=#原地重启>原地重启</a></li></ul></li><li><a href=#openebs-使用>OpenEBS 使用</a><ul><li></li><li><a href=#helm-部署>Helm 部署</a></li><li><a href=#kubectl-部署>kubectl 部署</a></li><li><a href=#验证>验证</a></li></ul></li><li><a href=#openebs-local-pv-原理>OpenEBS Local PV 原理</a><ul><li></li><li><a href=#openebs-local-pv-部署架构>OpenEBS Local PV 部署架构</a></li><li><a href=#openebs-localpv-provisioner-源码解析>openebs-localpv-provisioner 源码解析</a></li></ul></li><li><a href=#总结>总结</a></li></ul></nav></div></aside></main></body></html>